{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Background","text":""},{"location":"#background","title":"Background","text":"<p>I created this repository as a response to people requesting I share my setup notes for services I run in my home. These notes have been made generic enough so that you can implement these services and setups with relative ease. Be sure to check the glossary if you see unknown symbols.</p> <p>This has expanded over the years to also include other setup and configuration for technology I have run into and needed to make notes for.</p>"},{"location":"#assumptions","title":"Assumptions","text":"<p>These notes make the following assumptions:</p> <ul> <li>You have a advanced to expert competency in Windows, OSX, and Linux.</li> <li>You are comfortable with the following shells/languages: bash, go, cmd,   powershell.</li> <li>You are familiar with how services work on all three platforms.</li> <li>You are comfortable writing scripts.</li> <li>You can take a generalized command and figure out the specifics (e.g.   permissions).</li> <li>You can read man pages, and Google if you need to.</li> </ul>"},{"location":"#fit-purpose","title":"Fit &amp; Purpose","text":"<p>I do not consider these setups to be secure in any way shape or form, these simply get you started off on the right foot. Don't make the assumption that since this is setup, it is secure. It most definitely is not so. These are not setup to be massive services either -- don't use these scripts to setup your business or corporate environment -- you're doing it wrong. For the home gamer, proceed.</p> <p>Although I haven't done anything malicious, you should never blindly run scripts &amp; commands from the internet.</p>"},{"location":"#bugs-security-concerns","title":"Bugs &amp; Security Concerns","text":"<p>Use Let's Encrypt for free SSL/TLS certs. There's NO REASON to run self-signed certs anymore for hosting anything. Don't do it. Get a Let's Encrypt Cert.</p> <p>If you find any bugs or security concerns, file a bug against this project on git hub, or submit a CL \ud83d\ude43</p>"},{"location":"app/bash/","title":"BASH","text":""},{"location":"app/bash/#bash","title":"BASH","text":"<p>Bourne Again Shell snippets.</p>"},{"location":"app/bash/#require-pip-to-use-virtual-environment","title":"Require PIP to use Virtual Environment","text":"<p>~/.bashrc </p><pre><code>export PIP_REQUIRE_VIRTUALENV=true</code></pre><p></p> <p>Create a virtual environment </p><pre><code>python3 -m venv /var/venv/{ENV}\nsource /var/venv/{ENV}/bin/activate  # 'deactivate' will exit.</code></pre><p></p>"},{"location":"app/bash/#rename-all-file-extensions-to-lowercase","title":"Rename All File Extensions to Lowercase","text":"<pre><code>find . -type d -execdir rename 's/(\\.[A-Z]+$)/lc($1)/ge' *.*[A-Z]* \\;\n\n# Alternatively use rename binary.\nrename 'y/A-Z/a-z/' *</code></pre>"},{"location":"app/bash/#find-binary-in-all-files","title":"Find Binary in All Files","text":"<pre><code># Sed for a signal file.\nsed -n 's/.*[,\"\\[&gt;[:space:]]\\(.*\\.exe\\).*/\\1/p'\n\n# For all files.\nfind . -name \"*.txt\" -exec sed -n 's/.*[+,\"\\[&gt;[:space:]]\\(.*\\.exe\\).*/\\1/p' {} \\; &gt; result-list\n\n# Using grep is faster.\ngrep -iroh \"\\(.*\\.exe\\)\" . | tee result-list</code></pre>"},{"location":"app/bash/#prompt-to-require-a-specific-keypress-or-die","title":"Prompt to require a specific keypress or die","text":"<pre><code>echo 'This will cut a production release by overwriting prod with dev.'\nread -n 1 -p 'Press Y to continue, any other key to abort: ' READ_CONTINUE\n\nif [ \"${READ_CONTINUE}\" != 'Y' ]; then\n  echo -e '\\nAborting.'\n  exit 1\nfi</code></pre>"},{"location":"app/bash/#last-cli-argument","title":"Last CLI Argument","text":"<p>Use last argument in current command.</p> <pre><code>!$\n$_\n\n# Alternatively 'alt + .' will copy the string.</code></pre>"},{"location":"app/bash/#switch-to-a-user-with-no-login-shell","title":"Switch to a User with no login shell","text":"<pre><code>su - -s /bin/bash {USER}</code></pre>"},{"location":"app/bash/#parse-ini-value-from-file","title":"Parse INI value from file","text":"<pre><code>#!/bin/sh\nif [ \"$1\" != \"${1#*[0-9].[0-9]}\" ]; then\n  echo IPv4\nelif [ \"$1\" != \"${1#*:[0-9a-fA-F]}\" ]; then\n  echo IPv6\nelse\n  echo \"Unrecognized IP format '$1'\"\nfi</code></pre>"},{"location":"app/chrome/","title":"Chrome","text":""},{"location":"app/chrome/#chrome","title":"Chrome","text":"<p>See Auto Select Client Certificate to auto select certificate for matched sites.</p>"},{"location":"app/chrome/#block-location-tracking","title":"Block location tracking","text":"<p>chrome://settings/content/location</p> <ul> <li>Ask before accessing (Recommended): Disabled</li> </ul> <p>chrome://settings/content/notifications</p> <ul> <li>Ask before sending (Recommended): Disabled</li> </ul> ManjaroWindows <p>Install via GUI or CLI</p> <p>\u2318 \u2794 Add/Remove Software \u2794 Search \u2794 AUR \u2794 google-chrome</p> <p>CLI </p><pre><code>pamac install google-chrome</code></pre><p></p> <p>chrome://settings/appearance</p> <ul> <li>Use system title bar and borders: \u2714</li> </ul>"},{"location":"app/chrome/#disable-software-reporting","title":"Disable Software Reporting","text":"<p>Disable Chrome running software reporting tool</p> <p><code>HKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Google\\Chrome</code></p> <p>Key: ChromeCleanupEnabled</p> <p>Type: DWORD</p> <p>Values: 0</p> <p>Disable reporting results to Google</p> <p><code>HKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Google\\Chrome</code></p> <p>Key: ChromeCleanupReportingEnabled</p> <p>Type: DWORD</p> <p>Value: 0</p>"},{"location":"app/chrome/#disable-background-services","title":"Disable Background Services","text":"<p>Chrome background services will cause \"failed to restore properly\" messages on startup.</p> <p>chrome://settings/system</p> <ul> <li>Continue running background apps when google chrome is closed: \u2718</li> </ul>"},{"location":"app/chrome/#chrome-remote-desktop","title":"Chrome Remote Desktop","text":"<p>Install CRD.</p>"},{"location":"app/chrome/#hiding-local-desktop-for-chrome-remote-desktop-windows","title":"Hiding Local Desktop for Chrome Remote Desktop (Windows)","text":"<p>By default Chrome Remote Desktop will always show locally what is happening when you remotely connect. This disables this feature and presents a login screen instead, allowing you to work privately remotely. CRD will open a connection, then locally connect to remote desktop to hide your current session.</p> <p>Enable remote access curtain for CRD</p> <p><code>HKEY_LOCAL_MACHINE\\Software\\Policies\\Google\\Chrome</code></p> <p>Key: RemoteAccessHostRequireCurtain</p> <p>Type: DWORD</p> <p>Value: 1</p> <p>Enable RDP security</p> <p><code>HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\\WinStations\\RDP-Tcp</code></p> <p>Key: SecurityLayer</p> <p>Type: DWORD</p> <p>Value: 1</p> <p>\u2318 + r \u2794 control \u2794 System and Security \u2794 System \u2794 Remote Settings \u2794 Remote</p> <ul> <li>Allow remote connections to this computer: \u2714</li> <li>Allow connections only from computers running Remote Desktop with   NetworkLevel Authentication: \u2718</li> </ul> <p>\u2318 \u2794 Control Panel \u2794 System and Security \u2794 Windows Defender Firewall \u2794 Advanced Settings \u2794 Inbound Rules</p> <ul> <li>Remote Desktop - Shadow (TCP-in): Block</li> <li>Remote Desktop - User Mode (TCP-in): Block</li> <li>Remote Desktop - User Mode (UDP-in): Block</li> </ul>"},{"location":"app/freecad/","title":"FreeCAD","text":""},{"location":"app/freecad/#freecad","title":"FreeCAD","text":"<p>Tip</p> <p>Always calculate parametric values in the sheet; values calculated in the sketch will be resolved at creation however the formula will not be stored.</p> <p>Preferences</p> <ul> <li>General:<ul> <li>Units:<ul> <li>Unit System: Standard (mm/kg/s/degree)</li> </ul> </li> <li>Output Window:<ul> <li>Show report view on error: \u2718</li> </ul> </li> </ul> </li> <li>Display \u2794 3D View:<ul> <li>Anti-Aliasing: MSAA 8x</li> </ul> </li> <li>Addon Manager \u2794 Addon Manager options:<ul> <li>Automatically check for updates at start (requires GPython): \u2714</li> <li>Download Macro metadata (approximately 10MB): \u2714</li> </ul> </li> </ul> <p>Tools \u2794 Edit parameters \u2794 BaseApp \u2794 Preferences \u2794 Mod \u2794 PartDesign</p> <ul> <li>SwitchToTask: \u2718</li> </ul> <p>Install freecad.gears workbench via the Addon manager. Requires restart.</p>"},{"location":"app/movie_studio/","title":"Movie Studio","text":""},{"location":"app/movie_studio/#movie-studio","title":"Movie Studio","text":"<p>Steam Movie Studio 13 Platinum Release.</p>"},{"location":"app/movie_studio/#encoding-templates","title":"Encoding Templates","text":"<p>Templates below work well with shadowplay videos and youtube uploads.</p> <p>Custom templates are saved to %appdata%\\Sony\\Render Templates.</p>"},{"location":"app/movie_studio/#avc135mbpscuda60","title":"AVC/135mbps/cuda/60","text":"<p>Project \u2794 Make Movie \u2794 Save it to my Hard Drive \u2794 MP4 \u2794 Advanced Options \u2794 MainConcept AVC/AAC \u2794 Customize Template</p> <ul> <li>Template: AVC/135mbps/cuda/60</li> <li>Notes: 135mbps @ 60fps using CUDA</li> </ul> <p>Customize Template \u2794 Video</p> <ul> <li>Frame rate: 60.000000</li> <li>Allow source to adjust frame rate: \u2718</li> <li>Constant bit rate: \u2714<ul> <li>135000000</li> </ul> </li> <li>Encode mode: Render using CUDA if available</li> </ul>"},{"location":"app/movie_studio/#avc135mbpscuda","title":"AVC/135mbps/cuda","text":"<p>Project \u2794 Make Movie \u2794 Save it to my Hard Drive \u2794 MP4 \u2794 Advanced Options \u2794 MainConcept AVC/AAC \u2794 Customize Template</p> <ul> <li>Template: AVC/135mbps/cuda</li> <li>Notes: 135mbps @ 59.683fps using CUDA</li> </ul> <p>Template \u2794 Video</p> <ul> <li>Frame rate: 59.683000</li> <li>Allow source to adjust frame rate: \u2714</li> <li>Constant bit rate: \u2714<ul> <li>135000000</li> </ul> </li> <li>Encode mode: Render using CUDA if available</li> </ul>"},{"location":"app/movie_studio/#avc50mbpscuda","title":"AVC/50mbps/cuda","text":"<p>Project \u2794 Make Movie \u2794 Save it to my Hard Drive \u2794 MP4 \u2794 Advanced Options \u2794 MainConcept AVC/AAC \u2794 Customize Template</p> <ul> <li>Template: AVC/50mbps/cuda</li> <li>Notes: 50mbps @ 60fps using CUDA</li> </ul> <p>Template \u2794 Video</p> <ul> <li>Frame rate: 60.000000</li> <li>Allow source to adjust frame rate: \u2714</li> <li>Constant bit rate: \u2714<ul> <li>50000000</li> </ul> </li> <li>Encode mode: Render using CUDA if available</li> </ul>"},{"location":"app/movie_studio/#avc50mbps","title":"AVC/50mbps","text":"<p>Project \u2794 Make Movie \u2794 Save it to my Hard Drive \u2794 MP4 \u2794 Advanced Options \u2794 MainConcept AVC/AAC \u2794 Customize Template</p> <ul> <li>Template: AVC/50mbps</li> <li>Notes: 50mbps @ 60fps using CPU</li> </ul> <p>Template \u2794 Video</p> <ul> <li>Frame rate: 60.000000</li> <li>Allow source to adjust frame rate: \u2714</li> <li>Constant bit rate: \u2714<ul> <li>50000000</li> </ul> </li> <li>Encode mode: Render using CPU only</li> </ul>"},{"location":"app/movie_studio/#avc","title":"AVC","text":"<p>Project \u2794 Make Movie \u2794 Save it to my Hard Drive \u2794 MP4 \u2794 Advanced Options \u2794 MainConcept AVC/AAC \u2794 Customize Template</p> <ul> <li>Template: AVC</li> <li>Notes: 12mbps VBR to 24mbps @ 60fps using CPU</li> </ul> <p>Template \u2794 Video</p> <ul> <li>Frame rate: 60.000000</li> <li>Allow source to adjust frame rate: \u2714</li> <li>Variable bit rate: \u2714<ul> <li>Maximum (bps): 24000000</li> <li>Average (bps): 12000000</li> </ul> </li> <li>Encode mode: Render using CPU only</li> </ul>"},{"location":"app/movie_studio/#all-profiles","title":"All profiles","text":"<p>All profiles use these settings.</p> <p>Customize Template \u2794 Video</p> <ul> <li>Include video: \u2714</li> <li>Frame size: Custom Frame Size</li> <li>Width: 2560</li> <li>Height: 1440</li> <li>Allow source to adjust frame size: \u2718</li> <li>Profile: Main</li> <li>Field order: None (progressive scan)</li> <li>Pixel aspect ratio: 1.0000</li> <li>Number of reference frames: 2</li> <li>Use deblocking filter: \u2718</li> <li>Number of slices: 4</li> <li>Enable progressive download: \u2714</li> </ul> <p>Customize Template \u2794 Audio</p> <ul> <li>Include audio: \u2714</li> <li>Sample rate (Hz): 48000</li> <li>Bit rate (bps): 192000</li> </ul> <p>Customize Template \u2794 System</p> <ul> <li>Format: MP4 file format (.mp4)</li> </ul> <p>Customize Template \u2794 Project</p> <ul> <li>Video rendering quality: Best</li> <li>Sterescopic 3D mode: Use Project Settings</li> <li>Swap Left/Right: \u2718</li> </ul>"},{"location":"app/mutt/","title":"Mutt","text":""},{"location":"app/mutt/#mutt","title":"Mutt","text":"<p>Local terminal texted based email client.</p>"},{"location":"app/mutt/#setup","title":"Setup","text":"<pre><code>apt install mutt</code></pre> <p>~/.muttrc</p> <p>0600 {USER}:{USER}</p> <pre><code>set mbox_type=Maildir\nset spoolfile=\"~/Maildir/\"\nset folder=\"~/Maildir/\"\nset mask=\".*\"\nset record=\"+.Sent\"\nset postponed=\"+.Drafts\"\n\n# Generate mailboxes for each maildir subdir\nmailboxes ! + `\\\nfor file in ~/Maildir/.*; do \\\n  box=$(basename \"$file\"); \\\n  if [ ! \"$box\" = '.' -a ! \"$box\" = '..' -a ! \"$box\" = '.customflags' \\\n      -a ! \"$box\" = '.subscriptions' ]; then \\\n   echo -n \"\\\"+$box\\\" \"; \\\n  fi; \\\ndone`\n\n# Marcos to display folder list when changing maildir folders\nmacro index c \"&lt;change-folder&gt;?&lt;toggle-mailboxes&gt;\" \"open a different folder\"\nmacro pager c \"&lt;change-folder&gt;?&lt;toggle-mailboxes&gt;\" \"open a different folder\"\n\n# Macros to display folder list when copying/moving messages\nmacro index C \"&lt;copy-message&gt;?&lt;toggle-mailboxes&gt;\" \"copy a message to a mailbox\"\nmacro index M \"&lt;save-message&gt;?&lt;toggle-mailboxes&gt;\" \"move a message to a mailbox\"</code></pre> <p>This will setup mutt for use with Maildir, as well as subscribe to all folders in Maildir.</p>"},{"location":"app/mutt/#reference","title":"Reference<sup>1</sup><sup>2</sup>","text":"<ol> <li> <p>https://gitlab.com/muttmua/mutt/-/wikis/MuttFaq/Maildir \u21a9</p> </li> <li> <p>http://www.elho.net/mutt/maildir \u21a9</p> </li> </ol>"},{"location":"app/putty/","title":"Putty","text":""},{"location":"app/putty/#putty","title":"Putty","text":""},{"location":"app/putty/#enable-keepalives","title":"Enable Keepalives","text":"<p>putty \u2794 connection \u2794 enable tcp keepalives</p> <p>putty \u2794 connection \u2794 seconds between keepalives \u2794 5</p>"},{"location":"app/putty/#export-settings","title":"Export Settings","text":"<pre><code>regedit /e \"%userprofile%\\Desktop\\putty.reg\" HKEY_CURRENT_USER\\Software\\SimonTatham</code></pre>"},{"location":"app/putty/#launch-putty-with-specific-profile","title":"Launch Putty with Specific Profile","text":"<pre><code>putty.exe -load \"{SESSION}\"  # Use from CLI or add to Windows shortcut.</code></pre>"},{"location":"app/putty/#changing-escape-characters","title":"Changing Escape Characters","text":"<p>Sometimes the terminal escape sequences that are sent are changed if you are running through multiple screen sessions.</p> <pre><code>stty -a  # Determine the current escape sequences.\n\n# Determine the actual control sequence sent.\nctrl + v,  # {DESIRED KEY PRESS}. Prints sequence to terminal.\n\n# Set the correct escape sequence.\nstty erase ^H</code></pre>"},{"location":"app/putty/#forwarding-x-windows","title":"Forwarding X Windows","text":"<p>Use VcXsrv instead of xming. This is fully functional and does not have copy/paste or resizing disabled. Install as normal.</p> <p>c:\\Program Files\\VcXsrv\\config.xlaunch</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;XLaunch WindowMode=\"MultiWindow\" ClientMode=\"NoClient\" LocalClient=\"False\" Display=\"-1\" LocalProgram=\"xcalc\" RemoteProgram=\"xterm\" RemotePassword=\"\" PrivateKey=\"\" RemoteHost=\"\" RemoteUser=\"\" XDMCPHost=\"\" XDMCPBroadcast=\"False\" XDMCPIndirect=\"False\" Clipboard=\"True\" ClipboardPrimary=\"True\" ExtraParams=\"\" Wgl=\"True\" DisableAC=\"False\" XDMCPTerminate=\"False\"/&gt;</code></pre> <p>Set xlaunch shortcut to use config. </p><pre><code>\"c:\\Program Files\\VcXsrv\\xlaunch.exe\" -run config.xlaunch</code></pre><p></p>"},{"location":"app/git/","title":"GIT","text":""},{"location":"app/git/#git","title":"GIT","text":"<p>GIT version management snippets.</p>"},{"location":"app/git/#global-settings","title":"Global Settings","text":"<p>Rebasing when pulling makes the branch history cleaner, avoiding pull merge commits. Prune on fetch automatically clean Git objects in your repository locally whenever you fetch changes from remote, minimizes the number of branches on your local machine. Highlight moved code block sections.</p> <pre><code>git config --global pull.rebase true\ngit config --global fetch.prune true\ngit config --global diff.colorMoved zebra</code></pre>"},{"location":"app/git/#use-gpg-keys-with-git-tools-for-commit-signing","title":"Use GPG keys with GIT tools for Commit Signing","text":"<pre><code># Get keys to use\ngpg --list-keys\n\ngit config --global commit.gpgsign true\ngit config --global gpg.program /usr/bin/gpg\ngit config --global user.signingkey {KEY}\n\n# Manually sign without settings above.\ngit tag -s {TAG}{COMMIT}</code></pre>"},{"location":"app/git/#revert-changes-and-keep-commit-history","title":"Revert Changes and Keep Commit History","text":"<pre><code>git revert --no-edit {LAST GOOD COMMIT}..{LAST BAD COMMIT}</code></pre>"},{"location":"app/git/#force-repository-to-previous-commit","title":"Force Repository to Previous Commit","text":"<p>Danger</p> <pre><code>git reset --hard {COMMIT ID}\ngit push --force origin master</code></pre> <p>This is data destructive. Ensure any files are cleaned up before committing.</p> <p>Currently checked out versions of this repository will break.</p>"},{"location":"app/git/#force-pull-from-master-repository","title":"Force Pull from Master Repository","text":"<p>Forces local repository to be in sync with master, discarding all local changes and un-pushed commits.</p> <pre><code>git fetch --all\ngit reset --hard origin/master\n\n# Apply to a branch only\ngit checkout {BRANCH}\ngit fetch --all\ngit branch {BRANCH}-backup\ngit reset --hard origin/{BRANCH}</code></pre>"},{"location":"app/git/#revert-entire-directory-to-head","title":"Revert Entire Directory to HEAD","text":"<pre><code>git checkout -- {DIR}  # {DIR}/.. target everything in directory.\ngit clean -fd {DIR}  # {DIR}/.. target everything in directory.</code></pre>"},{"location":"app/git/#add-tag-to-previous-commit","title":"Add Tag to Previous Commit","text":"<pre><code>git pull --tags\ngit tag {TAG} {COMMIT}\ngit push --tags</code></pre>"},{"location":"app/git/#squash-commits-to-a-single-commit-rebase","title":"Squash Commits to a Single Commit (Rebase)","text":"<p>This will squash a series of commits into a single commit, which is useful to cleanup multiple commits before pushing upstream.</p> <p>Note</p> <pre><code>git rebase --interactive {COMMIT}</code></pre> <p>The COMMIT is the last commit that should be collapsed (e.g. rolled into a single commit).</p> <p>Editor will appear with rebase configuration. Generally use pick for the first commit and squash for the remaining commits.</p> <p>Note</p> <pre><code>git rebase --continue</code></pre> <p>If done correctly, this will show all commit messages that were rolled up. Update as needed and commit as normal.</p>"},{"location":"app/git/#modify-specific-historical-commit","title":"Modify Specific Historical Commit","text":"<p>Warning</p> <p>This will re-write commit history from the changed commit. Tags and releases will need to be deleted and re-created. Existing clones will break. Be careful.</p> <pre><code>git rebase --interactive '{COMMIT}^'  # Rebase one commit **before** change.</code></pre> <p>Note</p> <p>Set edit for the desired commit; save and exit. Make desired changes.</p> <pre><code>git commit --all --amend --no-edit  # Finish rebasing to HEAD\ngit rebase --continue\n\n# Reset affected tags\ngit tag -l\ngit rev-list -n 1 {TAG}\ngit tag -d {TAG}\ngit push --delete origin {TAG}\ngit tag {TAG} {NEW COMMIT HASH}\ngit push --tags</code></pre> <p>Warning</p> <p>Ensure affected releases, tags are removed before pushing the changed repo.</p>"},{"location":"app/git/#remove-tracked-files-without-deleting-them","title":"Remove Tracked Files without Deleting Them","text":"<pre><code>git rm --cached {FILE TO REMOVE FROM COMMIT}  # Single file.\ngit rm --cached {FILE1} {FILEN}  # Multiple files.\ngit rm -r --cached {DIR}  # All contents of a directory.</code></pre>"},{"location":"app/git/#highlight-changes-in-long-single-lines","title":"Highlight Changes in Long Single Lines","text":"<pre><code>git diff --word-diff {FILE} {FILE}</code></pre>"},{"location":"app/git/#migrate-git-stash-to-another-machine","title":"Migrate git stash to another machine","text":"<p>Export a stash as a patch to import in another git client.</p> <pre><code>git stash show \"stash@{0}\" -p &gt; changes.patch  # Export stash 0 to a patch.\ngit apply changes.patch  # Import patch to client.\ngit apply changes.patch --reverse  # Patch can be reverted if there are issues.</code></pre>"},{"location":"app/git/#repo-git-hooks","title":"Repo git hooks","text":"<p>Hooks are located in .git/hooks but are not versioned. This enables repository tracked hooks. See .git/hooks for examples. Hooks must have exact names.</p> <p>Ensure ansible vault files are encrypted on commit.</p> <p>.githooks</p> <p>0644 {USER}:{USER}</p> <pre><code>#!/usr/bin/env bash\n#\n# Called by \"git commit\" with no arguments.  The hook should\n# exit with non-zero status after issuing an appropriate message if\n# it wants to stop the commit. See .git/hooks for examples.\n\n# Unset variables produce errors\nset -u\n\nif git rev-parse --verify HEAD &gt;/dev/null 2&gt;&amp;1\nthen\n    against=HEAD\nelse\n    # Initial commit: diff against an empty tree object\n    against=4b825dc642cb6eb9a060e54bf8d69288fbee4904\nfi\n\n# Redirect output to stderr.\nexec 1&gt;&amp;2\n\nEXIT_STATUS=0\n\n# Check that vault files are encrypted.\n# read: -r do not allow backslashes to escape characters; -d delimiter\nwhile IFS= read -r -d $'\\0' file; do\n    [[ \"$file\" != *.vault &amp;&amp;\n         \"$file\" != *.vault.yml &amp;&amp;\n         \"$file\" != *vault ]] &amp;&amp; continue\n    # cut gets symbols 1-2\n    file_status=$(git status --porcelain -- \"$file\" 2&gt;&amp;1 | cut -c1-2)\n    file_status_index=${file_status:0:1}\n    file_status_worktree=${file_status:1:1}\n    [[ \"$file_status_worktree\" != ' ' ]] &amp;&amp; {\n        echo \"ERROR: *.vault file is modified in worktree but not added to the index: $file\"\n        echo \"Can not check if it is properly encrypted. Use git add or git stash to fix this.\"\n        EXIT_STATUS=1\n    }\n    # check is neither required nor possible for deleted files\n    [[ \"$file_status_index\" = 'D' ]] &amp;&amp; continue\n    head -1 \"$file\" | grep --quiet '^\\$ANSIBLE_VAULT;' || {\n        echo \"ERROR: non-encrypted *.vault file: $file\"\n        EXIT_STATUS=1\n    }\ndone &lt; &lt;(git diff --cached --name-only -z \"$against\")\n\nexit $EXIT_STATUS</code></pre> <pre><code>mkdir {REPO}/.githooks\n# Set local gitconfig hookspath to custom location.\ngit config -f .gitconfig core.hooksPath .githooks\n\n.. literalinclude:: source/pre-commit\n  :caption: **0755 {USER}:{USER}** **.githooks/pre-commit``\n\n# Use a Makefile or manually run on repo checkout to setup.\ngit config --local include.path ../.gitconfig</code></pre> <p>Note</p> <p>Command executes from .git directory, hence going up a directory to read the config.</p>"},{"location":"app/git/#list-all-repositories-for-an-organizationuser","title":"List All Repositories for An Organization/User","text":"<p>Useful for determining if there are new repositories to sync.</p> <pre><code># List all repositories for an organzation.\ncurl \"https://api.github.com/orgs/{ORGANIZATION NAME}/repos?per_page=1000&amp;page=1\" | jq -r '.[] | .name' | sort\n\n# List all repositories for a user.\ncurl \"https://api.github.com/users/{USER}/repos?per_page=1000&amp;page=1\" | jq -r '.[] | .name' | sort</code></pre>"},{"location":"app/git/branches/","title":"Branches","text":""},{"location":"app/git/branches/#branches","title":"Branches","text":"<p>Multiple branches can be made to focus changes on specific efforts. These are cut from the current branch; most cases this should be master.</p>"},{"location":"app/git/branches/#create-a-branch","title":"Create a Branch","text":"<pre><code># List, create, and move to new branch.\ngit branch -a\ngit checkout -b {NEW BRANCH}</code></pre> Use git normally."},{"location":"app/git/branches/#merging-branches","title":"Merging Branches","text":"<p>Completed branches can be merged back into any branch, typically master.</p> <pre><code># List branches, switch to master, and merge.\ngit branch -a\ngit checkout master\ngit merge {BRANCH} --no-ff</code></pre> <p>Note</p> <p>--no-ff retains all commit messages from the branch. Leave this off to squish the commit (it may be helpful to get branch log for merge message git --no-pager log &gt; /tmp/git.log).</p> <p>You may reset the merge before committing with no data loss with *get merge --abort.</p>"},{"location":"app/git/branches/#deleting-branches","title":"Deleting Branches","text":"<p>Tip</p> <p>Git will throw an error if deleting a branch with commits that has not been merged.</p> <pre><code># Delete merged branch.\ngit branch -a\ngit branch -d {BRANCH}</code></pre>"},{"location":"app/git/branches/#create-worktree","title":"Create Worktree","text":"<p>Allows the use of multiple branches simultaneously.</p> <pre><code># Create a new worktree from a branch\ngit branch -a\ngit checkout -b {NEW BRANCH}\ngit checkout master\ngit worktree add ../{WORKTREE NAME} {BRANCH}</code></pre>"},{"location":"app/git/branches/#merge-worktree","title":"Merge Worktree","text":"<p>Works like normal branch merging. Execute merge from master worktree.</p>"},{"location":"app/git/branches/#removing-worktree","title":"Removing Worktree","text":"<p>After the branch is merged worktree can be removed.</p> <pre><code># Remove worktree.\ncd {MASTER WORKTREE}\ngit worktree remove {WORKTREE}</code></pre> <p>Then delete branch as normal. See Deleting Branches.</p>"},{"location":"app/git/troubleshooting/","title":"Troubleshooting","text":""},{"location":"app/git/troubleshooting/#troubleshooting","title":"Troubleshooting","text":""},{"location":"app/git/troubleshooting/#reduce-repository-size-prune","title":"Reduce Repository Size (Prune)","text":"<p>Prune repository and reduce size or remove sensitive material. More complicated clean ups may require git-filter-repo tool.</p> <p>Warning</p> <p>All branches will need to be force pushed to clear entire history. Any checked out versions will need to be force synced.</p> <pre><code># Clone target repo to a clean state.\ngit clone {REPO}\n\n# Note all tags and commits.\ngit tag --list\n\n# Note origin URL.\ngit config --get remote.origin.url\n\n# Remove all files with path molecule/files.\ngit filter-repo --invert-paths --path-glob 'molecule/files'\n\n# Re-add origin origin URL.\ngit remote add origin {ORIGIN}\n\n# Retag all tags with new commit ID's (from above).\ngit tag -d {TAG}\ngit tag {TAG} {COMMIT}\n\n# Force push all commits and tags.\ngit push --all --force\ngit push --tags --force</code></pre>"},{"location":"app/gpg/","title":"GPG with Yubikey","text":""},{"location":"app/gpg/#gpg-with-yubikey","title":"GPG with Yubikey","text":"<p>Details creating a GPG Master Key &amp; subkeys, with an embedded photo and exporting subkeys to multiple Yubikeys. Additional documents provide setup for using Yubikeys for SSH authentication on different client operating systems.</p> <p>Subkeys are issued from the master key and are used for specific actions essentially 'on behalf of' the master identity. These subkeys are loaded onto Yubikeys for everyday use. As they are subkeys, these can be revoked as needed or the master key can be revoked/changed to invalidate all subkeys at once. The master key should be kept offline and encrypted and only the subkeys used in day to day usage.</p>"},{"location":"app/gpg/#reference","title":"Reference<sup>1</sup><sup>2</sup><sup>3</sup><sup>4</sup><sup>5</sup>","text":"<ol> <li> <p>https://github.com/drduh/YubiKey-Guide \u21a9</p> </li> <li> <p>https://zacharyvoase.com/2009/08/20/openpgp/ \u21a9</p> </li> <li> <p>https://zeos.ca/post/2015/gpg-smartcard/ \u21a9</p> </li> <li> <p>https://support.yubico.com/hc/en-us/articles/360013790259-Using-Your-YubiKey-with-OpenPGP \u21a9</p> </li> <li> <p>https://www.linode.com/docs/guides/gpg-key-for-ssh-authentication/ \u21a9</p> </li> </ol>"},{"location":"app/gpg/operations/","title":"Operations","text":""},{"location":"app/gpg/operations/#operations","title":"Operations","text":"<p>Note</p> <p>If you are encrypting files for yourself, use your email address associated with your public key as the recipient.</p>"},{"location":"app/gpg/operations/#import","title":"Import","text":"<p>If the public key is not your own and cannot be found on key servers, it must be manually imported.</p> <pre><code>#Import a public key from a file.\ngpg --import {KEY FILE}\n\n# Import a public key from a key server.\ngpg --recv {KEYID}</code></pre>"},{"location":"app/gpg/operations/#export","title":"Export","text":"<p>The public key can be exported as well for others to encrypt data for you.</p> <p>Export public key for signing data. </p><pre><code>gpg --homedir /some/custom/.gnupg --armor --export &gt; my_public_key.gpg</code></pre><p></p>"},{"location":"app/gpg/operations/#encrypt","title":"Encrypt","text":"<p>Encrypt a file for a given recipient. </p><pre><code># Trust model always prevents GPG warnings about untrusted key recipients.\ngpg --armor --batch --trust-model always --encrypt --recipient {GPGID} {FILE}\n\n# Encrypt some text\necho -n \"super_secret_server_stuff\" | gpg --armor --batch --trust-model always --encrypt --recipient {GPGID}</code></pre><p></p>"},{"location":"app/gpg/operations/#create-a-detached-signature","title":"Create a Detached Signature","text":"<p>This is used to validate that the GPG encrypted file has not been changed.</p> <p>Create a detached signature for a given file. </p><pre><code>gpg --detach-sign {FILE}.gpg</code></pre><p></p>"},{"location":"app/gpg/operations/#validate-file-using-detached-signature","title":"Validate File Using Detached Signature","text":"<pre><code># Import the public key if needed.\ngpg --import {PUBLIC KEY}\n\n# Verify the GPG encrypted file.\ngpg --verify {FILE}.sig</code></pre>"},{"location":"app/gpg/troubleshooting/","title":"Troubleshooting","text":""},{"location":"app/gpg/troubleshooting/#troubleshooting","title":"Troubleshooting","text":""},{"location":"app/gpg/troubleshooting/#no-agent-running-error","title":"No agent running error","text":"<p>gpg-agent can sometimes die in the background, just restart it.</p> <pre><code>gpg-agent --daemon</code></pre>"},{"location":"app/gpg/troubleshooting/#agent_genkey-failed-permission-denied","title":"agent_genkey failed: permission denied","text":"<p>Security measure; this means that the terminal you are using is not owned by you and therefore GPG has aborted instead of continuing. Frequently happens if running over SSH.</p> <p>Set proper terminal ownership. </p><pre><code>ls -la $(tty)\n&gt; crw-rw----. 1 otheruser tty 4, 1 Jan 19 18:47 /dev/pts/9\n\nsudo chown {USER} /dev/pts/9</code></pre><p></p>"},{"location":"app/gpg/troubleshooting/#yubikey-not-appearing","title":"Yubikey Not Appearing","text":"<p>gpg-agent can lose the key if the daemon was restarted in the background or if the Yubikey is not seated properly.</p> <pre><code># Re-insert the Yubikey, then run command to verify key returns data.\ngpg --card-status</code></pre>"},{"location":"app/gpg/troubleshooting/#ssh-connection-failed-server-sent-publickey","title":"SSH connection failed, Server sent: publickey","text":"<p>SSH public key not provided or was not matched on the server.</p> <ol> <li>SSH public key is not loaded on the SSH server. Confirm your GPG public SSH    key (see GPG Export Keys) is added to ~/.ssh/authorized_keys for    the user you are attempting to login with.</li> <li>GPG agent configuration is not reloaded. Ensure SSH and Putty support in    configuration is set, gpg-agent, and gpg-connect-agent are both    restarted. See Configure GPG Agent.</li> </ol>"},{"location":"app/gpg/troubleshooting/#please-insert-card-with-serial-number","title":"Please insert card with serial number","text":"<p>Original key used for authentication is not the key being used now.</p> <p></p> <p>GPG Agent caches the serial number of the card for the KeyStub used. This just needs to be removed.</p> <pre><code># Show all keygrips in GPG, these will be used to match cache in private store.\ngpg --with-keygrip --list-keys\n\n# Identify keygrip in private-keys-v1.d and delete it, or you can just remove\n# all keys in that directory.\nrm %appdata%\\gnupg\\private-keys-v1.d\\{KEY}  # Windows.\nrm ~/.gnupg/private-keys-v1.d  # Linux.</code></pre>"},{"location":"app/gpg/troubleshooting/#hard-reset-locked-yubikey-devices","title":"Hard Reset Locked Yubikey Devices","text":"<p>This will wipe device and unlock it for use again.</p> <pre><code>gpg-connect-agent --hex\nscd apdu 00 20 00 81 08 40 40 40 40 40 40 40 40\nscd apdu 00 20 00 83 08 40 40 40 40 40 40 40 40\nscd apdu 00 e6 00 00\nscd apdu 00 44 00 00</code></pre>"},{"location":"app/gpg/os/linux/","title":"Linux","text":""},{"location":"app/gpg/os/linux/#linux","title":"Linux","text":"<p>Tip</p> <p>See Trust GPG Key Locally for importing your public key and assigning ultimate trust for use.</p> <p>Requires ~/.ssh/authorized_keys on target machine with your exported GPG SSH RSA Public Key. See GPG Export Keys. See SSH for remote SSH configuration.</p>"},{"location":"app/gpg/os/linux/#install-packages","title":"Install Packages","text":"<p>Install GPG and security card agents on machine.</p> ManjaroDebianUbuntu <pre><code>pamac install gnupg pcsclite ccid hopenpgp-tools stoken\npamac install yubikey-personalization\nsystemctl enable pcscd.service\nsystemctl start pcscd.service</code></pre> <pre><code>apt update &amp;&amp; apt upgrade\napt install wget gnupg2 gnupg-agent dirmngr cryptsetup scdaemon pcscd\napt install secure-delete hopenpgp-tools yubikey-personalization\n\n# Optionally install yubikey manager to manage yubikeys.\napt install python3-pip python3-pyscard\npip3 install PyOpenSSL\npip3 install yubikey-manager\nservice pcscd start\n~/.local/bin/ykman openpgp info</code></pre> <pre><code># Requires universe multiverse APT sources.\napt update &amp;&amp; apt upgrade\napt install wget gnupg2 gnupg-agent dirmngr cryptsetup scdaemon pcscd\napt install secure-delete hopenpgp-tools yubikey-personalization\n\napt install libssl-dev swig libpcsclite-dev</code></pre>"},{"location":"app/gpg/os/linux/#configure-sshgpg-agent","title":"Configure SSH/GPG Agent","text":"<p>This will enable SSH usage with the gpg-agent.</p> <p>~/.gnupg/gpg-agent.conf</p> <p>0600 {USER}:{USER}</p> <pre><code># https://github.com/drduh/config/blob/master/gpg-agent.conf\n# https://www.gnupg.org/documentation/manuals/gnupg/Agent-Options.html\nenable-ssh-support\nttyname $GPG_TTY\ndefault-cache-ttl 60\nmax-cache-ttl 120\npinentry-program /usr/bin/pinentry-curses\n#pinentry-program /usr/bin/pinentry-tty\n#pinentry-program /usr/bin/pinentry-gtk-2\n#pinentry-program /usr/bin/pinentry-x11\n#pinentry-program /usr/bin/pinentry-gnome3\n#pinentry-program /usr/local/bin/pinentry-curses\n#pinentry-program /usr/local/bin/pinentry-mac</code></pre> <p>~/.gnupg/gpg.conf</p> <p>0600 {USER}:{USER}</p> <pre><code># https://github.com/drduh/config/blob/master/gpg.conf\n# https://www.gnupg.org/documentation/manuals/gnupg/GPG-Configuration-Options.html\n# https://www.gnupg.org/documentation/manuals/gnupg/GPG-Esoteric-Options.html\n# Use AES256, 192, or 128 as cipher\npersonal-cipher-preferences AES256 AES192 AES\n# Use SHA512, 384, or 256 as digest\npersonal-digest-preferences SHA512 SHA384 SHA256\n# Use ZLIB, BZIP2, ZIP, or no compression\npersonal-compress-preferences ZLIB BZIP2 ZIP Uncompressed\n# Default preferences for new keys\ndefault-preference-list SHA512 SHA384 SHA256 AES256 AES192 AES ZLIB BZIP2 ZIP Uncompressed\n# SHA512 as digest to sign keys\ncert-digest-algo SHA512\n# SHA512 as digest for symmetric ops\ns2k-digest-algo SHA512\n# AES256 as cipher for symmetric ops\ns2k-cipher-algo AES256\n# UTF-8 support for compatibility\ncharset utf-8\n# Show Unix timestamps\nfixed-list-mode\n# No comments in signature\nno-comments\n# No version in output\nno-emit-version\n# Disable banner\nno-greeting\n# Long hexidecimal key format\nkeyid-format 0xlong\n# Display UID validity\nlist-options show-uid-validity\nverify-options show-uid-validity\n# Display all keys and their fingerprints\nwith-fingerprint\n# Display key origins and updates\n#with-key-origin\n# Cross-certify subkeys are present and valid\nrequire-cross-certification\n# Disable caching of passphrase for symmetrical ops\nno-symkey-cache\n# Enable smartcard\nuse-agent\n# Disable recipient key ID in messages\nthrow-keyids\n# Default/trusted key ID to use (helpful with throw-keyids)\n#default-key 0xFF3E7D88647EBCDB\n#trusted-key 0xFF3E7D88647EBCDB\n# Group recipient keys (preferred ID last)\n#group keygroup = 0xFF00000000000001 0xFF00000000000002 0xFF3E7D88647EBCDB\n# Keyserver URL\n#keyserver hkps://keys.openpgp.org\n#keyserver hkps://keyserver.ubuntu.com:443\n#keyserver hkps://hkps.pool.sks-keyservers.net\n#keyserver hkps://pgp.ocf.berkeley.edu\n# Proxy to use for keyservers\n#keyserver-options http-proxy=http://127.0.0.1:8118\n#keyserver-options http-proxy=socks5-hostname://127.0.0.1:9050\n# Verbose output\n#verbose\n# Show expired subkeys\n#list-options show-unusable-subkeys</code></pre> <p>~/.bashrc</p> <p>0644 {USER}:{USER}</p> <pre><code># Direct SSH to use GPG for authentication.\nexport GPG_TTY=\"$(tty)\"\nexport SSH_AUTH_SOCK=$(gpgconf --list-dirs agent-ssh-socket)\ngpgconf --launch gpg-agent\n# Detect correct terminal on login.\ngpg-connect-agent updatestartuptty /bye &gt; /dev/null</code></pre>"},{"location":"app/gpg/os/linux/#verify-ssh-works","title":"Verify SSH Works","text":"<ol> <li>Connect with SSH as normal.</li> <li>A Pin Entry pop-up window should appear. It may not be in focus. Enter    your user PIN.</li> <li>Touch key to confirm (key will blink during wait for password).</li> </ol>"},{"location":"app/gpg/os/linux/#ssh-through-a-bastion","title":"SSH Through a Bastion","text":"<p>All latest versions of SCP and SSH support multiple jump proxies for transfers. GPG agent will be forwarded automatically (two authentication touches) if agent forwarding is enabled.</p> <pre><code># Modern SSH uses -J.\nssh -J {USER}@{BASTION} {STANDARD SSH COMMAND}\n\n# Equivalent.\nssh -o ProxyJump={USER}@{BASTION} {STANDARD SCP COMMAND}</code></pre> <p>This may also be setup to auto proxy via the config file.</p> <p>~/.ssh/config</p> <p>0644 {USER}:{USER}</p> <pre><code>Host {HOST}\nUser {USER}\nHostName {HOST}\nProxyJump {USER}@{BASTION}</code></pre>"},{"location":"app/gpg/os/linux/#scp-transfer-file-through-a-bastion","title":"SCP Transfer File Through a Bastion","text":"<p>All latest versions of SCP and SSH support multiple jump proxies for transfers. GPG agent will be forwarded automatically (two authentication touches) if agent forwarding is enabled.</p> <pre><code># Modern SSH uses -J.\nscp -J {USER}@{BASTION} {STANDARD SCP COMMAND}\n\n# Equivalent.\nscp -o ProxyJump={USER}@{BASTION} {STANDARD SCP COMMAND}</code></pre>"},{"location":"app/gpg/os/windows/","title":"Windows","text":""},{"location":"app/gpg/os/windows/#windows","title":"Windows","text":"<p>Tip</p> <p>See Trust GPG Key Locallyfor importing your public key and assigning ultimate trust for use.</p> <p>Requires ~/.ssh/authorized_keys on target machine with your exported GPG SSH RSA Public Key. See GPG Export Keys. See SSH for remote SSH configuration.</p>"},{"location":"app/gpg/os/windows/#configure-gpg4win","title":"Configure GPG4win","text":"<p>GPG4Win provides middleware to enable Yubikey GPG use. Download gpg4win and verify integrity.</p> <p>\u2318 \u2794 sysdm.cpl \u2794 Advanced \u2794 Environment Variables \u2794 User variables for {USER} \u2794 Path \u2794 Edit \u2794 New</p> <ul> <li>Path: c:\\Program Files (x86)\\GnuPG\\bin</li> </ul> <p>Add GPG path to end of list for global user profile access.</p>"},{"location":"app/gpg/os/windows/#configure-gpg-agent","title":"Configure GPG Agent","text":"<p>\u2318 \u2794 Device Manager \u2794 Software Devices</p> <p>Get Yubico device name as listed. Show Hidden Devices may be necessary.</p> <p>Use the full name in scdaemon.conf.</p> <p>%appdata%\\gnupg\\scdaemon.conf</p> <pre><code># Prevent Windows Hello from acting as an pagent device.\n# Results in no key found errors.\n\n# Device Manager Yubico full name.\nreader-port Yubico YubiKey OTP+FIDO+CCID 0</code></pre> <p>%appdata%\\gnupg\\gpg-agent.conf</p> <pre><code>enable-ssh-support\nenable-putty-support</code></pre> <p>Restart GPG Agent and Connect Agent to apply changes. </p><pre><code>gpgconf --kill gpg-agent\n\n# Once path is set: gpg-connect-agent.exe /bye\n\"c:\\Program Files (x86)\\GnuPG\\bin\\gpg-connect-agent.exe\" /bye</code></pre><p></p>"},{"location":"app/gpg/os/windows/#configure-putty","title":"Configure Putty","text":"<p>Download Putty.</p> <p>Putty \u2794 Connection \u2794 SSH \u2794 Auth</p> <ul> <li>Attempt authentication using Pageant: \u2714<ul> <li>Private key file for authentication: {EMPTY}</li> </ul> </li> </ul> <p>Save host changes.</p>"},{"location":"app/gpg/os/windows/#verify-putty-works","title":"Verify Putty Works","text":"<ol> <li>Connect with Putty as normal.</li> <li> <p>A Pin Entry pop-up window should appear. It may not be in focus. Enter    your user PIN.</p> <p></p> </li> <li> <p>Touch key to confirm (key will blink during wait for password).</p> </li> </ol>"},{"location":"app/gpg/os/windows/#winscp-transfer-file-through-a-bastion","title":"WinSCP Transfer File Through a Bastion","text":"<p>Import a working GPG Putty configuration into WinSCP. Create a copy of the working configuration and edit it.</p>"},{"location":"app/gpg/os/windows/#enable-gpg-agent-forwarding-in-putty","title":"Enable GPG Agent Forwarding in Putty","text":"<p>WinSCP \u2794 Site</p> <ul> <li>Host name: {Internal IP}</li> <li>Port number: {Internal Port}</li> <li>User name: {USER}</li> <li>Password: Empty</li> <li>Private key file: Empty</li> </ul>"},{"location":"app/gpg/os/windows/#define-bastion-tunnel","title":"Define Bastion Tunnel","text":"<p>WinSCP \u2794 Site \u2794 Advanced Site Settings \u2794 Connection \u2794 Tunnel</p> <ul> <li>Connect through SSH Tunnel: \u2714</li> <li>Host name: {Bastion External Address}</li> <li>Port number: {Bastion External Port}</li> <li>User name: {USER}</li> <li>Password: {EMPTY}</li> <li>Private key file: {EMPTY}</li> </ul>"},{"location":"app/gpg/os/windows/#enable-ssh-agent-forwarding","title":"Enable SSH Agent Forwarding","text":"<p>WinSCP \u2794 Site \u2794 Advanced Site Settings \u2794 SSH \u2794 Authentication</p> <ul> <li>Attempt authentication using Pageant: \u2714</li> <li>Allow agent forwarding: \u2714</li> </ul> <p>Save the configuration and connect. May be prompted for two authentication touches, one for each system.</p>"},{"location":"app/gpg/os/windows/#run-gpg-agent-on-login","title":"Run GPG Agent on Login","text":"<p>Scheduled Tasks are inconsistently applied and therefore you will run into issues if you depend on the scheduled tasks to always run at login to refresh your GPG agent. This is compounded by GPG agent occasionally hanging and needing to be force restarted. Resolve by triggering GPG agent refresh on screen unlock events, ensuring that the agent is always ready.</p>"},{"location":"app/gpg/os/windows/#enable-loginlogoff-events","title":"Enable Login/Logoff Events","text":"<p>Computer Configuration \u2794 Windows Settings \u2794 Security Settings \u2794 Advanced Audit Policy Configuration \u2794 System Audit Policies - Local Group Policy Object \u2794 Logon/Logoff \u2794 Audit Other Login/Logoff Events</p> <ul> <li>Configure the following audit events: \u2714</li> <li>Success: \u2714</li> <li>Failure: \u2714</li> </ul>"},{"location":"app/gpg/os/windows/#trigger-gpg-agent-refresh-on-loginlogoff-event","title":"Trigger GPG agent refresh on Login/Logoff Event","text":"<p>\u2318 \u2794 Task Scheduler \u2794 Task Scheduler Library \u2794 Action \u2794 Create Task</p> <ul> <li>General:<ul> <li>Name: GpgAgentRefreshUnlock</li> <li>Description: Restarts GPG agent on windows unlock</li> <li>Check: Run only when user is logged on</li> <li>Configure for: Windows {VERSION}</li> <li>Hidden: \u2714</li> </ul> </li> <li>Triggers:<ul> <li>Begin the task: On an event</li> <li>Check: Basic</li> <li>Log: Security</li> <li>Source: Microsoft Windows security auditing</li> <li>Event ID: 4801</li> <li>Hidden: \u2714</li> </ul> </li> <li>Actions:<ul> <li>First Action (Always execute first)<ul> <li>Action: Start a program</li> <li>Program/Script: gpgconf</li> <li>Add arguments: \u2013kill gpg-agent</li> </ul> </li> <li>Second Action (Always execute last)<ul> <li>Action: Start a program</li> <li>Program/Script: gpg-connect-agent</li> <li>Add arguments: /bye</li> </ul> </li> </ul> </li> <li>Conditions: \u2718</li> <li>Settings:<ul> <li>Allow task to be run on demand: \u2714</li> <li>Stop the task if it runs longer than: \u2714</li> <li>Stop the task if it runs longer than: 3 days</li> <li>All Remaining: \u2718</li> </ul> </li> </ul>"},{"location":"app/gpg/os/windows/#forward-gpg-agent-through-multiple-servers","title":"Forward GPG Agent Through Multiple Servers","text":"<p>Warning</p> <p>While the connection is active it is possible for others to use them as you while you are connected even though your private credential are on your local machine.</p> <p>Machines are referred to as putty for your client machine, bastion for the machine you will be SSH'ing through and target for remote SSH targets.</p> <p></p>"},{"location":"app/gpg/os/windows/#enable-gpg-agent-forwarding-in-putty_1","title":"Enable GPG Agent Forwarding in Putty","text":"<p>Putty \u2794 Connection \u2794 SSH \u2794 Auth</p> <ul> <li>Allow agent forwarding: \u2714</li> </ul>"},{"location":"app/gpg/os/windows/#bastion-configuration","title":"Bastion Configuration","text":"<p>/etc/ssh/sshd_config</p> <p>0644 root:root</p> <pre><code># Remove current socket file for forwarding before creating a new one.\nStreamLocalBindUnlink yes\n\n# Enable forwarding your credentials again to the next server.\nAllowAgentForwarding yes</code></pre> <p>Confirm new settings are loaded on Bastion. </p><pre><code>sshd -T | grep -i allowagent</code></pre><p></p>"},{"location":"app/gpg/os/windows/#target-configuration","title":"Target Configuration","text":"<p>Target does not need to enable outbound agent forwarding.</p> <p>/etc/ssh/sshd_config</p> <p>0644 root:root</p> <pre><code>AllowAgentForwarding no</code></pre>"},{"location":"app/gpg/os/windows/#reference","title":"Reference<sup>1</sup><sup>2</sup><sup>3</sup><sup>4</sup><sup>5</sup><sup>6</sup>","text":"<ol> <li> <p>https://developers.yubico.com/PGP/SSH_authentication/Windows.html \u21a9</p> </li> <li> <p>https://www.linode.com/docs/guides/gpg-key-for-ssh-authentication/ \u21a9</p> </li> <li> <p>https://codingnest.com/how-to-use-gpg-with-yubikey-wsl/ \u21a9</p> </li> <li> <p>https://ttmm.io/tech/yubikey/ \u21a9</p> </li> <li> <p>https://occamy.chemistry.jhu.edu/references/pubsoft/YubikeySSH/index.php \u21a9</p> </li> <li> <p>https://superuser.com/questions/161973/how-can-i-forward-a-gpg-key-via-ssh-agent \u21a9</p> </li> </ol>"},{"location":"app/gpg/setup/","title":"Setup","text":""},{"location":"app/gpg/setup/#setup","title":"Setup","text":"<p>Carefully follow these instructions before setting up GPG and Yubikeys to remain in a secure state. Failure to follow these instructions may expose private key material to bad actors.</p>"},{"location":"app/gpg/setup/#required-materials","title":"Required Materials","text":"<ol> <li>Live USB OS, with persistent storage to setup additional packages. Tails    Live USB setup instructions is preferred (most secure), other    live USB will work but be less secure. Instructions assume Debian-based    system.</li> <li>Hardware-backed Encrypted USB drive Ironkey (most secure), or USB drive    with software encryption using VeraCrypt (less secure).</li> <li>Yubikey 5 (or other hardware security key support 4096bit RSA    certificates).</li> <li>A complete copy of these instructions or secondary device Internet access.</li> <li>A photo to associate with your GPG master key.</li> </ol> <p>This assumes usage of an Ironkey with Yubikeys on a Debian-base system for configuration.</p>"},{"location":"app/gpg/setup/#prep-live-usb","title":"Prep Live USB","text":"<p>GPG generation should be done on a air-gapped, temporal, encrypted OS to minimize secret key exposure. Persistent disk should be created so that packages may be installed / updated as needed (e.g. Yubikey manager). All GPG operations should be done offline with the exception of uploading public keys to services.</p> <p>Set a root password.</p> <p>Danger</p> <p>Do not store secret material directly on live USB filesystems.</p> <p>Network is required for this step. Disable after packages are installed.</p> <pre><code># Update and install Yubikey management.\napt update &amp;&amp; apt upgrade\napt-add-repository ppa:yubico/stable\napt update\napt install software-properties-common scdaemon hopenpgp-tools gpg\napt install yubikey-manager yubikey-manager-qt</code></pre> <p>Note</p> <p>yubikey-manager-qt is a GUI frontend which has limited functionality but does provide easy ways to ensure specific applets are enabled. scdaemon enables smartcard support for GPG.</p>"},{"location":"app/gpg/setup/#prep-ironkey","title":"Prep Ironkey","text":"<p>Tip</p> <p>Max 16 character password. Ironkey will wipe device after 10 failed attempts and force physical re-insertion after every 3 failed attempts.</p>"},{"location":"app/gpg/setup/#initialize-ironkey","title":"Initialize Ironkey","text":"<p>For a new Ironkey or creating a new master key.</p> <p>Danger</p> <p>This is data destructive.</p> <pre><code>/media/user/IRONKEY/linux/linux64/ikd300_initalize</code></pre>"},{"location":"app/gpg/setup/#reset-ironkey","title":"Reset Ironkey","text":"<p>Wipes a working Ironkey to a default state.</p> <p>Danger</p> <p>This is data destructive.</p> <pre><code>/media/user/IRONKEY/linux/linux64/ikd300_resetdevice</code></pre>"},{"location":"app/gpg/setup/#unlock-ironkey","title":"Unlock Ironkey","text":"<pre><code>sudo /media/user/IRONKEY/linux/linux64/ikd300_login</code></pre> <ul> <li>Run KINGSTON from file browser to mount to /media/user/KINGSTON.</li> </ul> <p>Safe for Secrete Key Material</p> <p>The Ironkey is the only safe location to store secret key material.</p> <p>Tip</p> <p>IronKey may mount readonly if it was previously unmounted dirty. Unlock drive and run a filesystem check.</p> <pre><code>dosfsck -a {IRONKEY_DEVICE}</code></pre>"},{"location":"app/gpg/setup/#prep-yubikey","title":"Prep Yubikey","text":"<p>Default Yubikey Passwords</p> <ul> <li>Default User Pin: 123456</li> <li>Default Admin Pin: 12345678</li> </ul> <p>Yubikey Password/PINs may be up to 127 ASCII characters long.</p>"},{"location":"app/gpg/setup/#verify-genuine-yubikey","title":"Verify Genuine Yubikey","text":"<p>Ensure Yubikey is genuine and has not been tampered with during any step of the supply chain.</p> <ol> <li>https://www.yubico.com/genuine</li> <li>Verify Device.</li> <li>Touch Yubikey when prompted.</li> </ol> <p>Note</p> <p>Yubico must be able to see the make and model of the device during the verification process.</p> <p>Verification Complete is displayed for genuine keys. Failure means potential compromise and should be thrown out after it is confirmed to fail again.</p>"},{"location":"app/gpg/setup/#reset-yubikey","title":"Reset Yubikey","text":"<p>This will destroy any openpgp material on the key and reset to the default key state.</p> <p>Do this even if the Yubikey is new</p> <pre><code>ykman openpgp reset</code></pre> <p>Existing 2FA configurations will be deleted.</p> <p>Alternatively using the Yubikey Personalization Tool will provide options to do this via a GUI.</p> <pre><code>### Show current Yubikey card shows with default values.\ngpg --card-status</code></pre> <ul> <li>If not found, re-insert the key. There is a known race condition that may   occur with older GPG libraries.</li> <li>Ensure latest firmware version using Yubikey Manager.</li> <li>Ensure device has CCID mode enabled using Yubikey Manager. Most   firmware past 3.1.8 will have this permanently enabled and not listed.</li> </ul>"},{"location":"app/gpg/setup/#configure-yubikey","title":"Configure Yubikey","text":"<p>Configure behavior of Yubikey so short touches will provide GPG material, while long touches will provide Yubico OTP. This prevents accidental touches spewing keystrokes into whatever is open. NFC is also disabled to force physical touch to use key.</p>"},{"location":"app/gpg/setup/#swap-slots","title":"Swap slots","text":"<ol> <li>Yubikey Manager \u2794 Applications \u2794 OTP</li> <li>Delete Slot 1.</li> <li>Configure Slot 2 to use Yubico OTP.</li> </ol> <p>Tip</p> <p>Newer keys can just use the swap button.</p>"},{"location":"app/gpg/setup/#disable-nfc","title":"Disable NFC","text":"<ol> <li>Yubikey Manager \u2794 Interfaces \u2794 NFC \u2794 Disable All</li> <li>Save Interfaces.</li> </ol> <p>Tip</p> <p>All NFC options are disabled to require physical presence.</p>"},{"location":"app/gpg/setup/#setup-openpgp-on-yubikey","title":"Setup OpenPGP on Yubikey","text":"<p>Prepare Yubikey to load GPG key material.</p> <pre><code># Edit openpgp application on Yubikey.\ngpg --card-edit\n&gt; Reader ...........: Yubico YubiKey OTP FIDO CCID 0\n&gt; Application ID ...: XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n&gt; Version ..........: 3.4\n&gt; Manufacturer .....: Yubico\n&gt; Serial number ....: XXXXXXXXXX\n&gt; Name of cardholder: [not set]\n&gt; Language prefs ...: [not set]\n&gt; Sex ..............: unspecified\n&gt; URL of public key : [not set]\n&gt; Login data .......: [not set]\n&gt; Signature PIN ....: forced\n&gt; Key attributes ...: rsa4096 rsa4096 rsa4096\n&gt; Max. PIN lengths .: 127 127 127\n&gt; PIN retry counter : 3 3 3\n&gt; Signature counter : 0\n\n# Set admin password (Remember to use the Default PIN if needed).\ngpg/card&gt; admin\n&gt; Admin commands are allowed\n\ngpg/card&gt; passwd\n&gt; gpg: OpenPGP card no. XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX detected\n&gt;\n&gt; 1 - change PIN\n&gt; 2 - unblock PIN\n&gt; 3 - change Admin PIN\n&gt; 4 - set the Reset Code\n&gt; Q - quit\n\nYour selection? 3\n&gt; PIN changed.\n\nYour selection? Q\n\n# Set user password (Remember to use the Default PIN if needed).\ngpg/card&gt; admin\n&gt; Admin commands are allowed\n\ngpg/card&gt; passwd\n&gt; gpg: OpenPGP card no. XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX detected\n&gt;\n&gt; 1 - change PIN\n&gt; 2 - unblock PIN\n&gt; 3 - change Admin PIN\n&gt; 4 - set the Reset Code\n&gt; Q - quit\n\nYour selection? 1\n&gt; PIN changed.\n\nYour selection? Q\n\n# Set name used in the GPG credentials to load.\ngpg/card&gt; name\nCardholders surname: {USER LAST NAME}\nCardholders given name: {USER FIRST NAME}\n\n# Set language for GPG user.\ngpg/card&gt; lang\nLanguage preferences: en\n\n#  Set URL to location of user's GPG public key.\ngpg/card&gt; url\nURL to retrieve public key: https://keys.openpgp.org/vks/v1/by-fingerprint/{KEYID}\n\n# Set login to GPG email account used.\ngpg/card&gt; login\nLogin data (account name): {GPG USER EMAIL ADDRESS}\n\n# Set forcesig to always require PIN to access GPG key material.\ngpg/card&gt; forcesig\n\n# Verify configuration and quit to save.\ngpg/card&gt; {PRESS ENTER}\n&gt; Reader ...........: Yubico YubiKey OTP FIDO CCID 0\n&gt; Application ID ...: XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n&gt; Version ..........: 3.4\n&gt; Manufacturer .....: Yubico\n&gt; Serial number ....: XXXXXXXXXX\n&gt; Name of cardholder: {USER FIRST NAME} {USER LAST NAME}\n&gt; Language prefs ...: en\n&gt; Sex ..............: unspecified\n&gt; URL of public key : https://keys.openpgp.org/vks/v1/by-fingerprint/{KEYID}\n&gt; Login data .......: {GPG USER EMAIL ADDRESS}\n&gt; Signature PIN ....: forced\n&gt; Key attributes ...: rsa4096 rsa4096 rsa4096\n&gt; Max. PIN lengths .: 127 127 127\n&gt; PIN retry counter : 3 3 3\n&gt; Signature counter : 0\n\ngpg/card&gt; quit</code></pre>"},{"location":"app/gpg/setup/#require-touch-for-each-authentication-encryption-or-signing-request","title":"Require touch for each Authentication, Encryption, or Signing Request","text":"<pre><code>ykman openpgp keys set-touch aut fixed\nykman openpgp keys set-touch sig fixed\nykman openpgp keys set-touch enc fixed</code></pre> <p>Tip</p> <p>Fixed is the same as on but requires a new certificate to be loaded if this option is ever disabled.</p>"},{"location":"app/gpg/setup/#reference","title":"Reference<sup>1</sup><sup>2</sup><sup>3</sup><sup>4</sup>","text":"<ol> <li> <p>https://developers.yubico.com/PIV/Guides/Device_setup.html \u21a9</p> </li> <li> <p>https://zeos.ca/post/2018/gpg-yubikey5/ \u21a9</p> </li> <li> <p>https://www.gnupg.org/howtos/card-howto/en/ch03.html \u21a9</p> </li> <li> <p>https://suchsecurity.com/gpg-and-ssh-with-yubikey-on-windows.html \u21a9</p> </li> </ol>"},{"location":"app/gpg/setup/backup/","title":"Backup","text":""},{"location":"app/gpg/setup/backup/#backup","title":"Backup","text":"<p>Exporting subkeys will delete the key locally. Backing up $GNUPGHOME before exporting enables exporting subkeys to multiple Yubikeys. Make your own determination on if this security practice is acceptable to you.</p> <p>Danger</p> <p>Ensure machine is air-gapped (no transmission devices on) during this step.</p> <p>Store on a (hardware) encrypted device.</p>"},{"location":"app/gpg/setup/backup/#confirm-key-state","title":"Confirm Key State","text":"<p>Ensure master and subkeys are created and locally stored before exporting.</p> <p>Info</p> <p>The master and subkeys should be listed with no modifiers if properly setup to export to a key.</p> <pre><code>gpg --list-keys\n\n# &gt; - indicates a key is exported to card already (ssb&gt;).\n# sec# - indicates only stubs created (a private cert on different machine).</code></pre>"},{"location":"app/gpg/setup/backup/#export-gpg-keys","title":"Export GPG Keys","text":"<p>Master and Subkeys will be encrypted with your passphrase when exported.</p> <p>GPG Public key export can be used to manually import into other GPG clients if you do not want to use key servers.</p> <p>Export master, subkeys, and public key. </p><pre><code>gpg --armor --export-secret-keys $KEYID &gt; $GPGBACKUP/private/$KEYID.master.asc\ngpg --armor --export-secret-subkeys $KEYID &gt; $GPGBACKUP/private/$KEYID.subkeys.asc\ngpg --armor --export $KEYID &gt; $GPGBACKUP/public/$KEYID.asc\ncp $GNUPGHOME/openpgp-revocs.d/* $GPGBACKUP/private</code></pre><p></p> <p>Export SSH RSA public key. </p><pre><code>gpg --export-ssh-key $KEYID &gt; $GPGBACKUP/public/$KEYID.ssh.pub</code></pre><p></p> <p>Note</p> <p>The SSH RSA Public Key comment will use the authentication short key ID (openpgp:0xXXXXXXXX). See Linux or Windows for importing keys.</p> <p>Backup GNUPG state for multiple Yubikey initializations. </p><pre><code>sudo cp -avi $GNUPGHOME $GPGBACKUP</code></pre><p></p>"},{"location":"app/gpg/setup/backup/#publish-public-key","title":"Publish Public Key","text":"<p>Export the public key to public key servers for GPG encrypt/decrypt/signing. Without publishing you can still use SSH.</p> <p>Danger</p> <p>Network is required for this step. Disable network immediately afterwards.</p> <p>Export public key to https://keys.openpgp.org. </p><pre><code>gpg --keyserver hkps://keys.openpgp.org --send-key $KEYID</code></pre><p></p>"},{"location":"app/gpg/setup/cleanup/","title":"Cleanup","text":""},{"location":"app/gpg/setup/cleanup/#cleanup","title":"Cleanup","text":"<p>Manually verify this information to ensure you do not accidentally lose data or access/control to your GPG identity.</p>"},{"location":"app/gpg/setup/cleanup/#verify","title":"Verify","text":"<ol> <li> <p>Encrypted Media has the following:</p> <ul> <li>$GPGBACKUP/private/$KEYID.master.asc</li> <li>$GPGBACKUP/private/$KEYID.subkeys.asc</li> <li>$GPGBACKUP/private/$KEYID.rev</li> <li>$GPGBACKUP/public/$KEYID.asc</li> <li>$GPGBACKUP/public/$KEYID.ssh.pub</li> </ul> </li> <li> <p>A backup of GPG Master Key (with all keys locally present):</p> <p>$GPGBACKUP/gnupghome</p> </li> <li> <p>Your Master Key password is stored away from your encrypted media in a    controlled space.</p> </li> <li>Your Encrypted Media password is stored away from your encrypted media    in a controlled space.</li> <li>The encrypted media is stored offline in a controlled space.</li> <li> <p>The public keys are stored or published and are readily accessible.</p> <p>$GPGBACKUP/public/*</p> </li> <li> <p>It is generally a good idea to print a copy of the revocation certificate and    give it to a trusted third-party.</p> </li> </ol>"},{"location":"app/gpg/setup/cleanup/#secure-delete-secret-material","title":"Secure Delete Secret Material","text":"<p>Securely remove any secret GPG material.</p> <p>If you are using a Live OS, just reboot. If you're paranoid, wipe the live OS drive.</p> <p>If not using a live OS, wipe private key material after you confirm it is backed up.</p> <pre><code>sudo srm -r $GNUPGHOME || sudo rm -rf $GNUPGHOME\nsudo srm -r $GPGBACKUP || sudo rm -rf $GPGBACKUP\ngpg --delete-secret-key $KEYID</code></pre>"},{"location":"app/gpg/setup/export_to_yubikey/","title":"Export to Yubikey","text":""},{"location":"app/gpg/setup/export_to_yubikey/#export-to-yubikey","title":"Export to Yubikey","text":"<p>Exports GPG subkeys to Yubikey so master key can remain offline while still using GPG keys.</p>"},{"location":"app/gpg/setup/export_to_yubikey/#understanding-how-yubikeys-work","title":"Understanding How Yubikeys Work","text":"<p>Read the technical manual to understand how Yubikeys work. This will setup the Yubikey to use the CCID interface to setup openpgp on the key.</p> <p>Yubikey manager is an application that is used to manage the Yubikey itself (ykman) and sets how applets are used on the key. The configuration of the applets themselves are managed by respective apps, in this case GPG.</p> <p></p> <p>ykman will set preferences like number of applet PIN attempts, PINs, and touch preferences.</p> <p>gpg --edit-card will set openpgp configuration, like PGP name, login, url.</p>"},{"location":"app/gpg/setup/export_to_yubikey/#export-subkeys-to-yubikeys","title":"Export Subkeys to Yubikeys","text":"<p>Danger</p> <p>Exporting keys to Yubikey will destroy the local key. Ensure a backup has been made so original state can be restored. See Backup and Restore Original GPG State respectively.</p> <p>Tip</p> <p>Key selection is a toggle, ensure to only export one key at a time; this is denoted by a *.</p> <p>First Password: GPG private key password.</p> <p>Second Password: Yubikey user PIN.</p>"},{"location":"app/gpg/setup/export_to_yubikey/#load-signing-key-to-yubikey","title":"Load signing key to Yubikey","text":"<pre><code>gpg --edit-key $KEYID\ngpg&gt; key 1\n\n&gt; sec  rsa4096/################\n&gt;      created: 2019-01-01  expires: never       usage: C\n&gt;      trust: ultimate      validity: ultimate\n&gt; ssb* rsa4096/################\n&gt;      created: 2019-01-01  expires: never       usage: S\n&gt; ssb  rsa4096/################\n&gt;      created: 2019-01-01  expires: never       usage: E\n&gt; ssb  rsa4096/################\n&gt;      created: 2019-01-01  expires: never       usage: A\n&gt; [ultimate] (1). FIRST LAST &lt;EMAIL&gt;\n\ngpg&gt; keytocard\n\n&gt; Please select where to store the key:\n&gt;    (1) Signature key\n&gt;    (3) Authentication key\n\nYour selection? 1\n\n&gt; You need a passphrase to unlock the secret key for user: \"FIRST LAST &lt;EMAIL&gt;\"\n&gt; 4096-bit RSA key, ID ################, created 2019-01-01\n\ngpg&gt; save</code></pre>"},{"location":"app/gpg/setup/export_to_yubikey/#load-encryption-key-to-yubikey","title":"Load encryption key to Yubikey","text":"<pre><code>gpg --edit-key $KEYID\ngpg&gt; key 2\n\n&gt; sec  rsa4096/################\n&gt;      created: 2019-01-01  expires: never       usage: C\n&gt;      trust: ultimate      validity: ultimate\n&gt; ssb  rsa4096/################\n&gt;      created: 2019-01-01  expires: never       usage: S\n&gt; ssb* rsa4096/################\n&gt;      created: 2019-01-01  expires: never       usage: E\n&gt; ssb  rsa4096/################\n&gt;      created: 2019-01-01  expires: never       usage: A\n&gt; [ultimate] (1). FIRST LAST &lt;EMAIL&gt;\n\ngpg&gt; keytocard\n\n&gt; Please select where to store the key:\n&gt;    (2) Encryption key\n\nYour selection? 2\n\n&gt; You need a passphrase to unlock the secret key for user: \"FIRST LAST &lt;EMAIL&gt;\"\n&gt; 4096-bit RSA key, ID ################, created 2019-01-01\n\ngpg&gt; save</code></pre>"},{"location":"app/gpg/setup/export_to_yubikey/#load-authentication-key-to-yubikey","title":"Load authentication key to Yubikey","text":"<pre><code>gpg --edit-key $KEYID\ngpg&gt; key 3\n\n&gt; sec  rsa4096/################\n&gt;      created: 2019-01-01  expires: never       usage: C\n&gt;      trust: ultimate      validity: ultimate\n&gt; ssb  rsa4096/################\n&gt;      created: 2019-01-01  expires: never       usage: S\n&gt; ssb  rsa4096/################\n&gt;      created: 2019-01-01  expires: never       usage: E\n&gt; ssb* rsa4096/################\n&gt;      created: 2019-01-01  expires: never       usage: A\n&gt; [ultimate] (1). FIRST LAST &lt;EMAIL&gt;\n\ngpg&gt; keytocard\n\n&gt; Please select where to store the key:\n&gt;    (3) Authentication key\n\nYour selection? 3\n\n&gt; You need a passphrase to unlock the secret key for user: \"FIRST LAST &lt;EMAIL&gt;\"\n&gt; 4096-bit RSA key, ID ################, created 2019-01-01\n\ngpg&gt; save</code></pre>"},{"location":"app/gpg/setup/export_to_yubikey/#verify-subkeys-are-offloaded","title":"Verify subkeys are Offloaded","text":"<pre><code>gpg --list-secret-keys\n\n# &gt; - Offloaded keys will have &gt; next to the key (key is on card).</code></pre>"},{"location":"app/gpg/setup/export_to_yubikey/#restore-original-gpg-state","title":"Restore Original GPG State","text":"<p>The original GPG state needs to be reloaded to export Subkeys to additional Yubikeys, or to keep a pristine copy of GPG key data on encrypted storage.</p> <pre><code>cp -avi $GPGBACKUP/* $GNUPGHOME</code></pre>"},{"location":"app/gpg/setup/import/","title":"Import Public Key","text":""},{"location":"app/gpg/setup/import/#import-public-key","title":"Import Public Key","text":"<p>This will set ultimate trust for the GPG Master Public Key certificate you created when backing up GPG state. Any of one these options below can be used.</p> <p>Tip</p> <p>Besides the locally exported public key file option, both other options assume that the public key has been published to key servers. Yubikey can automatically import the correct certificate assuming the key was setup correctly. See GPG Publish Key.</p>"},{"location":"app/gpg/setup/import/#gpg-public-key-from-file","title":"GPG Public Key from File","text":"<pre><code>gpg --import YOUR_PUBLIC_GPG_KEY.asc\n\n&gt; gpg: key 0x################: public key \"FIRST LAST &lt;EMAIL&gt;\" imported\n&gt; gpg: Total number processed: 1\n&gt; gpg:               imported: 1\n\nGPG Public Key from Keyserver.\n``` bash\ngpg --receive-keys $KEYID  --keyserver hkps://keys.openpgp.org\n\n&gt; gpg: requesting key 0x################ from hkps server pgp.mit.edu\n&gt; [...]\n&gt; gpg: key 0x################: public key \"FIRST LAST &lt;EMAIL&gt;\" imported\n&gt; gpg: Total number processed: 1\n&gt; gpg:               imported: 1</code></pre>"},{"location":"app/gpg/setup/import/#gpg-public-key-from-yubikey-url","title":"GPG Public Key from Yubikey URL","text":"<pre><code>gpg --card-edit\ngpg/card&gt; fetch\n\n&gt; gpg: requesting key from 'https://keys.openpgp.org/vks/v1/by-fingerprint/{KEYID}'\n&gt; gpg: key ################: public key \"FIRST LAST &lt;EMAIL&gt;\" imported\n&gt; gpg: Total number processed: 1\n&gt; gpg:               imported: 1</code></pre>"},{"location":"app/gpg/setup/import/#trust-gpg-public-key-locally","title":"Trust GPG Public Key Locally","text":"<p>Each machine on which the signing, encryption and authentication certificates are used must trust the GPG Master Public key to prevent errors.</p> <p>Set Ultimate Trust for GPG Master Public Key. </p><pre><code>gpg --edit-key $KEYID  # Use imported public key ID.\ngpg&gt; trust\n\n&gt; pub# rsa4096/################\n&gt;      created: 2019-01-01  expires: never       usage: C\n&gt;      trust: unknown       validity: unknown\n&gt; sub&gt; rsa4096/################\n&gt;      created: 2019-01-01  expires: never       usage: S\n&gt; sub&gt; rsa4096/################\n&gt;      created: 2019-01-01  expires: never       usage: E\n&gt; sub&gt; rsa4096/################\n&gt;      created: 2019-01-01  expires: never       usage: A\n&gt;\n&gt; Please decide how far you trust this user to correctly verify other users keys\n&gt; (by looking at passports, checking fingerprints from different sources, etc.)\n&gt;\n&gt;   1 = I don't know or won't say\n&gt;   2 = I do NOT trust\n&gt;   3 = I trust marginally\n&gt;   4 = I trust fully\n&gt;   5 = I trust ultimately\n&gt;   m = back to the main menu\n\nYour decision? 5\nDo you really want to set this key to ultimate trust? (y/N) y\n\n&gt; pub# rsa4096/################\n&gt;      created: 2019-01-01  expires: never       usage: C\n&gt;      trust: ultimate      validity: ultimate\n&gt; sub&gt; rsa4096/################\n&gt;      created: 2019-01-01  expires: never       usage: S\n&gt; sub&gt; rsa4096/################\n&gt;      created: 2019-01-01  expires: never       usage: E\n&gt; sub&gt; rsa4096/################\n&gt;      created: 2019-01-01  expires: never       usage: A\n\ngpg&gt; save\n\n# # - Certificate not on machine.\n# &gt; - Certificate on Yubikey.\ngpg --list-secret-keys\n\n&gt; /home/{USER}/.gnupg/pubring.kbx\n&gt; -------------------------------\n&gt; sec#  rsa4096 2019-01-01 [C]\n&gt;       ########################################\n&gt; uid           [ultimate] FIRST LAST &lt;EMAIL&gt;\n&gt; uid           [ultimate] [jpeg image of size 5877]\n&gt; ssb&gt;  rsa4096 2019-01-01 [S]\n&gt; ssb&gt;  rsa4096 2019-01-01 [E]\n&gt; ssb&gt;  rsa4096 2019-01-01 [A]</code></pre><p></p>"},{"location":"app/gpg/setup/master/","title":"Master Key","text":""},{"location":"app/gpg/setup/master/#master-key","title":"Master Key","text":"<p>The GPG Master Key is your digital identity and should be kept offline and encrypted per setup.</p> <p>Danger</p> <p>Ensure machine is air-gapped (no transmission devices on) during this setup.</p>"},{"location":"app/gpg/setup/master/#prepare-environment","title":"Prepare Environment","text":"<p>Setup GPG to store configuration on encrypted storage and setup secure cross-platform preferences.</p> <p>Create directories on encrypted drive and setup environment variables. </p><pre><code>mkdir /media/user/KINGSTON/gnupghome\n\n# Store respective key material in these folders.\nmkdir -p /media/user/KINGSTON/backup/public /media/user/KINGSTON/backup/private\n\n# Directs GPG where to find material.\nexport GNUPGHOME=/media/user/KINGSTON/gnupghome\n\n# Directs GPG where to backup material.\nexport GPGBACKUP=/media/user/KINGSTON/backup</code></pre><p></p> <p>/media/user/KINGSTON/gnupghome/gpg.conf</p> <p>0600 {USER}:{USER}</p> <pre><code>personal-cipher-preferences AES256 AES192 AES  # Require cipher AES 256, 192, 128.\npersonal-digest-preferences SHA512 SHA384 SHA256  # Require digest SHA 512, 384, 256.\ndefault-preference-list SHA512 SHA384 SHA256 AES256 AES192 AES ZLIB BZIP2 ZIP Uncompressed  # Public preferences for cipher/digest, compression.\ncert-digest-algo SHA512  # Force our digest creation to SHA512.\ns2k-digest-algo SHA512  # Force our cipher to AES256.\ns2k-cipher-algo AES256  # Enable UTF-8 support (for cross platform usage).\ncharset utf-8\nfixed-list-mode  # Fixed list - use unixtimestamps for all timestamps and do not merge id/key.\nno-comments  # Do not include comments in signature.\nno-emit-version  # Do not include version in signature.\nkeyid-format 0xlong  # Require long hexidecimal keys.\nlist-options show-uid-validity  # Show UID validity for listing and verification options.\nverify-options show-uid-validity  # List fingerprints with keys.\nwith-fingerprint\nrequire-cross-certification  # Ensure cross certification on subkey is present and valid (prevents attack).\nuse-agent  # Enable smartcard use.</code></pre>"},{"location":"app/gpg/setup/master/#generate-strong-password","title":"Generate Strong Password","text":"<p>Generate a strong random password for use with the GPG master key. Doing actions on the system will slowly increase the entropy pool.</p> <p>Warning</p> <p>Use this password when generating the Master GPG Key below. Store it in a physically separate location from where the offline Master Key is stored. This protects your digital identity.</p> <pre><code># Ensure entropy pool is larger than 3000.\ncat /proc/sys/kernel/random/entropy_avail\n\n# Generate a random 64 bit ACSII safe sequence for GPG password.\ngpg --gen-random --armor 0 64</code></pre>"},{"location":"app/gpg/setup/master/#create-master-key","title":"Create Master Key","text":"<p>Master key will only certify subkeys - it is not used directly to deal with encryption material. This enables subkeys to be replaced when compromised without needing to regenerate an entire GPG identity. Subkeys are for everyday use.</p> <p>Tip</p> <p>GPG 2.1 and higher will automatically create a revocation certificate in $GNUPGHOME/openpgp-revocs.d.</p> <p>Using the revocation certificate is better mechanism than an expiry date for protecting the master key.</p> <p>Comments are considered harmful</p> <p>Explicitly leave key comments blank. All required information is included within the key itself and muddles the human readability of the key.</p> <p>Generate a 4096bit RSA with authenticate (certify) abilities only. </p><pre><code>gpg --expert --full-generate-key\n&gt;\n&gt; Please select what kind of key you want:\n&gt;    (1) RSA and RSA (default)\n&gt;    (2) DSA and Elgamal\n&gt;    (3) DSA (sign only)\n&gt;    (4) RSA (sign only)\n&gt;    (7) DSA (set your own capabilities)\n&gt;    (8) RSA (set your own capabilities)\n&gt;    (9) ECC and ECC\n&gt;   (10) ECC (sign only)\n&gt;   (11) ECC (set your own capabilities)\n&gt;   (13) Existing key\n\nYour selection? 8  # Create RSA 2096 bit key.\n\n&gt; Possible actions for a RSA key: Sign Certify Encrypt Authenticate\n&gt; Current allowed actions: Sign Certify Encrypt\n&gt;\n&gt;   (S) Toggle the sign capability\n&gt;   (E) Toggle the encrypt capability\n&gt;   (A) Toggle the authenticate capability\n&gt;   (Q) Finished\n\nYour selection? =c  # Force certify only.\n\n&gt; RSA keys may be between 1024 and 4096 bits long.\n\nWhat keysize do you want? (2048) 4096\n\n&gt; Requested keysize is 4096 bits\n&gt; Please specify how long the key should be valid.\n&gt;          0 = key does not expire\n&gt;       &lt;n&gt;  = key expires in n days\n&gt;       &lt;n&gt;w = key expires in n weeks\n&gt;       &lt;n&gt;m = key expires in n months\n&gt;       &lt;n&gt;y = key expires in n years\n\nKey is valid for? (0) 0  # Do not expire.\n\n&gt; Key does not expire at all\n\nIs this correct? (y/N) y\n\n# Set GPG identity.\n&gt; GnuPG needs to construct a user ID to identify your key.\n\nReal name: {USER FIRST NAME} {USER LAST NAME}\nEmail address: {GPG USER EMAIL ADDRESS}\nComment: {PRESS ENTER}\n\n&gt; You selected this USER-ID:\n&gt;     \"FIRST LAST &lt;EMAIL&gt;\"\n\nChange (N)ame, (C)omment, (E)mail or (O)kay/(Q)uit? o\n\n# Password generated above.\n&gt; You need a Passphrase to protect your secret key.\n\nEnter passphrase: {GPG PASSWORD}\nRepeat passphrase: {GPG PASSWORD}\n\n&gt; We need to generate a lot of random bytes. It is a good idea to perform\n&gt; some other action (type on the keyboard, move the mouse, utilize the\n&gt; disks) during the prime generation; this gives the random number\n&gt; generator a better chance to gain enough entropy.\n&gt;\n&gt; gpg: /media/user/KINGSTON/gnupghome/trustdb.gpg: trustdb created\n&gt; gpg: key ################ marked as ultimately trusted\n&gt; gpg: directory '/media/user/KINGSTON/gnupghome/openpgp-revocs.d' created\n&gt; gpg: revocation certificate stored as '/media/user/KINGSTON/gnupghome/openpgp-revocs.d/########################################.rev'\n&gt; public and secret key created and signed.\n&gt;\n&gt; pub   rsa4096/################ 2019-01-01 [C]\n&gt;       Key fingerprint = #### #### #### #### ####  #### #### #### #### ####\n&gt; uid                              FIRST LAST &lt;EMAIL&gt;\n\n# Revocation certificate will be listed in output.\n# Master Key ID will be listed under 'pub  rsa4096/################'.</code></pre>   * See Troubleshooting if an error occurs.<p></p> <p>Export master key ID to bash environment for easy reference later. </p><pre><code>export KEYID=################</code></pre><p></p>"},{"location":"app/gpg/setup/master/#add-photo-to-master-key-optional","title":"Add Photo to Master Key (Optional)","text":"<p>A photo to help confirm your identity (typically a head shot); this is added to your GPG key for additional verification in person.</p> <p>Create a 240x288 JPEG photo (max 6144 bytes) with metadata information removed.</p> <pre><code>gpg --edit-key $KEYID\ngpg&gt; addphoto\n\n&gt; Pick an image to use for your photo ID. The image must be a JPEG file.\n&gt; Remember that the image is stored within your public key. If you use a very\n&gt; large picture, your key will become very large as well! Keeping the image\n&gt; close to 240x288 is a good size to use.\n\nEnter JPEG filename for photo ID: photo.jpg\nIs this correct? (y/N) y\n\ngpg&gt; save</code></pre>"},{"location":"app/gpg/setup/master/#add-additional-identities-optional","title":"Add Additional Identities (Optional)","text":"<p>Associate additional metadata to GPG key, useful if you have multiple emails, etc. The primary ID is the main identity used for the GPG key. This can be any identity that has been configured, in this case 1.</p> <p>Comments are considered harmful</p> <p>Explicitly leave key comments blank. All required information is included within the key itself and muddles the human readability of the key.</p> <pre><code>$ gpg --edit-key $KEYID\ngpg&gt; adduid\n\nReal name: {USER FIRST NAME} {USER LAST NAME}\nEmail address: {GPG USER EMAIL ADDRESS}\nComment: {PRESS ENTER}\n\n&gt; You selected this USER-ID:\n&gt;     \"FIRST LAST &lt;EMAIL&gt;\"\n\nChange (N)ame, (C)omment, (E)mail or (O)kay/(Q)uit? o\n\ngpg&gt; uid 1\ngpg&gt; primary\ngpg&gt; save</code></pre>"},{"location":"app/gpg/setup/master/#sign-new-key-with-existing-key-optional","title":"Sign New Key with Existing Key (Optional)","text":"<p>This will extend the chain of trust and prove that the new key is controlled by your original key (you). Useful for when the master key is compromised or expired.</p> <p>The new key is exported and signed by the old key, then published. </p><pre><code>gpg --export-secret-keys --armor --output /tmp/new-gpg-key.asc\ngpg --default-key $OLDKEY --sign-key $KEYID</code></pre><p></p>"},{"location":"app/gpg/setup/subkey/","title":"Subkeys","text":""},{"location":"app/gpg/setup/subkey/#subkeys","title":"Subkeys","text":"<p>Subkeys are issued from the master key and are used for specific actions on behalf of the master identity. These are loaded onto Yubikeys for everyday use. They may be revoked as needed or the master key can be revoked/changed to invalidate all subkeys at once.</p> <p>Warning</p> <p>If subkeys are not stored on a self-destructing device when attacked (e.g. a Yubikey), then set an expiry date.</p>"},{"location":"app/gpg/setup/subkey/#create-signing-key","title":"Create Signing Key","text":"<pre><code>gpg --expert --edit-key $KEYID\ngpg&gt; addkey\n\n&gt; Please select what kind of key you want:\n&gt;    (3) DSA (sign only)\n&gt;    (4) RSA (sign only)\n&gt;    (5) Elgamal (encrypt only)\n&gt;    (6) RSA (encrypt only)\n&gt;    (7) DSA (set your own capabilities)\n&gt;    (8) RSA (set your own capabilities)\n&gt;   (10) ECC (sign only)\n&gt;   (11) ECC (set your own capabilities)\n&gt;   (12) ECC (encrypt only)\n&gt;   (13) Existing key\n\nYour selection? 4\n\n&gt; RSA keys may be between 1024 and 4096 bits long.\n\nWhat keysize do you want? (2048) 4096\n\n&gt; Requested keysize is 4096 bits\n&gt; Please specify how long the key should be valid.\n&gt;          0 = key does not expire\n&gt;       &lt;n&gt;  = key expires in n days\n&gt;       &lt;n&gt;w = key expires in n weeks\n&gt;       &lt;n&gt;m = key expires in n months\n&gt;       &lt;n&gt;y = key expires in n years\n\nKey is valid for? (0) 0\n\n&gt; Key does not expire at all\n\nIs this correct? (y/N) y\nReally create? (y/N) y\n\n&gt; We need to generate a lot of random bytes. It is a good idea to perform\n&gt; some other action (type on the keyboard, move the mouse, utilize the\n&gt; disks) during the prime generation; this gives the random number\n&gt; generator a better chance to gain enough entropy.\n&gt;\n&gt; sec  rsa4096/################\n&gt;     created: 2019-01-01  expires: never       usage: C\n&gt;     trust: ultimate      validity: ultimate\n&gt; ssb  rsa4096/################\n&gt;     created: 2019-01-01  expires: never       usage: S\n&gt; [ultimate] (1). FIRST LAST &lt;EMAIL&gt;\n\ngpg&gt; save</code></pre>"},{"location":"app/gpg/setup/subkey/#create-encryption-key","title":"Create Encryption Key","text":"<pre><code>gpg --expert --edit-key $KEYID\ngpg&gt; addkey\n\n&gt; Please select what kind of key you want:\n&gt;    (3) DSA (sign only)\n&gt;    (4) RSA (sign only)\n&gt;    (5) Elgamal (encrypt only)\n&gt;    (6) RSA (encrypt only)\n\nYour selection? 6\n\n&gt; RSA keys may be between 1024 and 4096 bits long.\n\nWhat keysize do you want? (2048) 4096\n\n&gt; Requested keysize is 4096 bits\n&gt; Please specify how long the key should be valid.\n&gt;          0 = key does not expire\n&gt;       &lt;n&gt;  = key expires in n days\n&gt;       &lt;n&gt;w = key expires in n weeks\n&gt;       &lt;n&gt;m = key expires in n months\n&gt;       &lt;n&gt;y = key expires in n years\n\nKey is valid for? (0) 0\n\n&gt; Key does not expire at all\n\nIs this correct? (y/N) y\nReally create? (y/N) y\n\n&gt; We need to generate a lot of random bytes. It is a good idea to perform\n&gt; some other action (type on the keyboard, move the mouse, utilize the\n&gt; disks) during the prime generation; this gives the random number\n&gt; generator a better chance to gain enough entropy.\n&gt;\n&gt; sec  rsa4096/################\n&gt;     created: 2019-01-01  expires: never       usage: C\n&gt;     trust: ultimate      validity: ultimate\n&gt; ssb  rsa4096/################\n&gt;     created: 2019-01-01  expires: never       usage: S\n&gt; ssb  rsa4096/################\n&gt;     created: 2019-01-01  expires: never       usage: E\n&gt; [ultimate] (1). FIRST LAST &lt;EMAIL&gt;\n\ngpg&gt; save</code></pre>"},{"location":"app/gpg/setup/subkey/#create-authentication-key","title":"Create Authentication Key","text":"<pre><code>gpg --expert --edit-key $KEYID\ngpg&gt; addkey\n\n&gt; Please select what kind of key you want:\n&gt;    (3) DSA (sign only)\n&gt;    (4) RSA (sign only)\n&gt;    (5) Elgamal (encrypt only)\n&gt;    (6) RSA (encrypt only)\n&gt;    (7) DSA (set your own capabilities)\n&gt;    (8) RSA (set your own capabilities)\n&gt;   (10) ECC (sign only)\n&gt;   (11) ECC (set your own capabilities)\n&gt;   (12) ECC (encrypt only)\n&gt;   (13) Existing key\n\nYour selection? 8\n\n&gt; Possible actions for a RSA key: Sign Encrypt Authenticate\n&gt; Current allowed actions: Sign Encrypt\n&gt;\n&gt;  (S) Toggle the sign capability\n&gt;  (E) Toggle the encrypt capability\n&gt;  (A) Toggle the authenticate capability\n&gt;  (Q) Finished\n\nY our selection? =a\n\n&gt; RSA keys may be between 1024 and 4096 bits long.\n\nWhat keysize do you want? (3072) 4096\n\n&gt; Requested keysize is 4096 bits\n&gt; Please specify how long the key should be valid.\n&gt;          0 = key does not expire\n&gt;       &lt;n&gt;  = key expires in n days\n&gt;       &lt;n&gt;w = key expires in n weeks\n&gt;       &lt;n&gt;m = key expires in n months\n&gt;       &lt;n&gt;y = key expires in n years\n\nKey is valid for? (0) 0\n\n&gt; Key does not expire at all\n\nIs this correct? (y/N) y\nReally create? (y/N) y\n\n&gt; We need to generate a lot of random bytes. It is a good idea to perform\n&gt; some other action (type on the keyboard, move the mouse, utilize the\n&gt; disks) during the prime generation; this gives the random number\n&gt; generator a better chance to gain enough entropy.\n&gt;\n&gt; sec  rsa4096/################\n&gt;      created: 2019-01-01  expires: never       usage: C\n&gt;      trust: ultimate      validity: ultimate\n&gt; ssb  rsa4096/################\n&gt;      created: 2019-01-01  expires: never       usage: S\n&gt; ssb  rsa4096/################\n&gt;      created: 2019-01-01  expires: never       usage: E\n&gt; ssb  rsa4096/################\n&gt;      created: 2019-01-01  expires: never       usage: A\n&gt; [ultimate] (1). FIRST LAST &lt;EMAIL&gt;\n\ngpg&gt; save</code></pre>"},{"location":"app/gpg/setup/subkey/#verify-keys-are-secure","title":"Verify Keys Are Secure","text":"<p>Highlight any potential concern areas with generated keys. These should appear green with exceptions for the authentication subkey.</p> <p>Red text indicates potential problems</p> <p>Non-expiring keys will be marked as red; setting expiry is based on your security decisions.</p> <p>Orange text indicates warnings</p> <p>This is typically seen as a missing embedded cross-certificate for the authentication subkey. The GPG authentication subkey does not sign and does not need to be cross-certified.</p> <pre><code>gpg --export $KEYID | hokey lint</code></pre>"},{"location":"app/gpg/setup/subkey/#verify-gpg-password","title":"Verify GPG Password","text":"<p>There is no built in method to confirm a GPG password is correct. Verification of password happens by checking the exit code and printing Correct if the command succeeded.</p> <pre><code>echo '{GPG PASSWORD}' | gpg --batch --passphrase-fd 1 -o /dev/null --local-user $KEYID -as - &amp;&amp; echo 'Correct.'</code></pre>"},{"location":"app/vim/","title":"Vim","text":""},{"location":"app/vim/#vim","title":"Vim","text":"<p>VI Improved.</p> <p>See vim adventure for a game to learn vim, and stackoverflow most useful vim shortcuts.</p> <p>Highly customized default configuration:</p> ~/.vimrc <p>0644 {USER}:{USER}</p> <pre><code>\"\" https://dougblack.io/words/a-good-vimrc.html#colors\nset nocompatible                             \" Do not use vi compatible settings\nset viminfo=%,'50,\\\"1000,/50,:0,h,f0,n~/.vim/.viminfo\n\"           | |   |      |   |  | |  + viminfo file path\n\"           | |   |      |   |  | + File marks 0-9,A-Z 0=NOT stored\n\"           | |   |      |   |  + Disable 'hlsearch' loading viminfo\n\"           | |   |      |   + Max command-line history saved\n\"           | |   |      + Max search history saved\n\"           | |   + Max register lines saved\n\"           | + lines saved for each register\n\"           + save/restore buffer list\n\"\" https://stackoverflow.com/questions/23012391/how-and-where-is-my-viminfo-option-set\n\n\"\" COLOR SCHEME:\n\"\" -------------\nset t_Co=256                                 \" Use 256 colors. termguicolors (24bit) doesn't work with tmux\ncolorscheme monokai                          \" Use custom monokai theme\nsyntax enable                                \" Use colorscheme syntax highlighting\nset printoptions+=syntax:y                   \" Use colorscheme syntax highlighting when printing to paper\nhighlight ColorColumn ctermbg=235 guibg=#2c2d27                              \" Vertical column highlighting\nhighlight VertSplit ctermfg=222 ctermbg=238 guifg=#ffd787 guibg=#444444      \" Vertical split highlighting\nhighlight User1 ctermfg=010 ctermbg=241 guifg=#00ff00 guibg=#626262          \" %1* color\nhighlight User6 ctermfg=241 ctermbg=239 guifg=#626262 guibg=#4e4e4e          \" %6* color (inverted %1*)\nhighlight User2 ctermfg=009 ctermbg=239 guifg=#ff0000 guibg=#4e4e4e          \" %2* color\nhighlight User7 ctermfg=239 ctermbg=237 guifg=#4e4e4e guibg=#3a3a3a          \" %7* color (inverted %7*)\nhighlight User3 ctermfg=222 ctermbg=237 guifg=#ffd787 guifg=#3a3a3a          \" %3* color\nhighlight User8 ctermfg=237 ctermbg=235 guifg=#3a3a3a guifg=#262626          \" %8* color (inverted %3*)\nhighlight User4 ctermfg=239 ctermbg=235 guifg=#4e4e4e guifg=#262626          \" %4* color\nhighlight User9 ctermfg=235 ctermbg=233 guifg=#262626 guifg=#121212          \" %9* color (inverted %4*)\n\n\"\" FILE OPTIONS:\n\"\" -------------\n\"\" If python (or any files) are tabbing incorrectly, modify the\n\"\" /usr/share/vim/vim74/ftplugin/(filetype).vim file and comment out the\n\"\" setlocal expandtab shiftwidth=4 softtabstop=4 tabstop=8\nfiletype on                                  \" Enable filetype detection\nfiletype indent on                           \" Load type specific indent files\n\n\"\" SEARCHING:\n\"\" ----------\nset incsearch                                \" Search as characters are entered\nset hlsearch                                 \" Highlight search matches\nset ignorecase                               \" Ignore case when searching\nset smartcase                                \" If search contains a captial letter, make search case-sensitive\nnnoremap &lt;silent&gt; \\ :nohlsearch&lt;CR&gt;          \" \\ clears search highlights\n\n\"\" GUI OPTIONS:\n\"\" ------------\nset guioptions=agirt                         \" No menu or toolbar in GUI\nset guifont=SF\\ Mono                         \" Use SF Mono font in GUI\n\n\"\" CONSOLE OPTIONS:\n\"\" ----------------\nset mouse=a                                  \" Mouse will be on all the time\nset belloff=all                              \" Turn off visual/audio bells\nset encoding=utf8                            \" Encode non-ASCII to UTF8\nset tabstop=2                                \" Tab control characters are rendered with 5 spaces\nset softtabstop=2                            \" Number of spaces inserted when inserting a tab control character\nset expandtab                                \" Expand tab control character to spaces\nset shiftwidth=2                             \" Shifting (&lt;&lt; &gt;&gt;) is 2 spaces\nset backspace=2                              \" Make backspace behave like other editors\nset textwidth=0                              \" Disable hard text wrapping\nset wrapmargin=0                             \" Disable soft text wrapping\nset wildmenu                                 \" Visual autocomplete for command menus\nset number                                   \" Enable lines numbers by default (nonumber disable)\nset showcmd                                  \" Continue to show last command until new one is entered\nset cursorline                               \" Highlight current cursor line\nset showmatch                                \" Showing matching closure\nset ruler                                    \" Display position information\nset autoread                                 \" Auto-reload files if they change on disk\nset autoindent                               \" Copy indentation from current line when starting new line\n\n\"\" SPLIT MANAGEMENT:\n\"\" -----------------\nset splitbelow                               \" Horizontal splits always created below\nset splitright                               \" Vertical splits always created on right\nnnoremap &lt;silent&gt; &lt;leader&gt;\\| :vsplit&lt;CR&gt;     \" \\| Create vertical split\nnnoremap &lt;silent&gt; &lt;leader&gt;- :split&lt;CR&gt;       \" - Create horizontal split\nnnoremap &lt;silent&gt; &lt;leader&gt;&lt;left&gt;  &lt;c-w&gt;&lt;c-h&gt; \" left arrow select split left\nnnoremap &lt;silent&gt; &lt;leader&gt;&lt;right&gt; &lt;c-w&gt;&lt;c-l&gt; \" right arrow select split right\nnnoremap &lt;silent&gt; &lt;leader&gt;&lt;up&gt;    &lt;c-w&gt;&lt;c-k&gt; \" up arrow select split up\nnnoremap &lt;silent&gt; &lt;leader&gt;&lt;down&gt;  &lt;c-w&gt;&lt;c-j&gt; \" down arrow select split down\nset fillchars+=vert:\u2502                        \" Use solid line for vertical split\n\n\"\" NETRW FILE BROWSER:\n\"\" -------------------\n\"\" https://shapeshed.com/vim-netrw/#netrw---the-unloved-directory-browser\nlet g:netrw_liststyle=3                      \" Tree view as default list view (i to rotate through)\nlet g:netrw_sort_sequence='[\\/]$,*'          \" List directories on top, files below\nlet g:netrw_browse_split=3                   \" Open files in previous window (was 3, tab)\nlet g:netrw_altv=1                           \" Open files in vertical split\nlet g:netrw_banner=0                         \" Disable the starting banner\nlet g:netrw_winsize=25                       \" Only use 25% of screen for netrw\n\n\"\" STATUSBAR:\n\"\" ---------\n\"\" Match coloring from tmux status bar\nset laststatus=2                             \" Always show the status bar\nset statusline=                              \" Clear status line\nset statusline+=%1*%f%6*\ue0b4                    \" File path\nset statusline+=%2*\\ %{&amp;encoding}%7*\ue0b4        \" File encoding\nset statusline+=%3*\\ %{&amp;fileformat}%8*\ue0b4      \" File format\nset statusline+=%4*\\ %m%r%9*\ue0b4                \" [+] (modified file), [RO] (readonly)\nset statusline+=%=                           \" Items before this are left-aligned, after right-aligned\nset statusline+=%9*\ue0b6%4*0x%B\\                 \" Hex code of character under cursor\nset statusline+=%8*\ue0b6%3*%c\\                   \" column number\nset statusline+=%7*\ue0b6%2*%p%%\\                 \" Percent through the file\nset statusline+=%6*\ue0b6%1*[%l/%L]               \" Show current line, total lines\n\n\"\" FOLDING:\n\"\" --------\nset foldenable                               \" Enable code folding\nset foldlevelstart=10                        \" Open 10 levels of folds by default\nset foldnestmax=10                           \" Max 10 nested fold level\nset foldmethod=indent                        \" Fold based on indentation level\n\n\"\" COMMENTING:\n\"\" ----------\nmap ,# :s/^/#/&lt;CR&gt;:nohlsearch&lt;CR&gt;            \" Add # comment start block\nmap ,/ :s/^/\\/\\//&lt;CR&gt;:nohlsearch&lt;CR&gt;         \" Add // comment start block\nmap ,&gt; :s/^/&gt; /&lt;CR&gt;:nohlsearch&lt;CR&gt;           \" Add &gt; comment start block\nmap ,\" :s/^/\\\"/&lt;CR&gt;:nohlsearch&lt;CR&gt;           \" Add \" comment start block\nmap ,% :s/^/%/&lt;CR&gt;:nohlsearch&lt;CR&gt;            \" Add % comment start block\nmap ,! :s/^/!/&lt;CR&gt;:nohlsearch&lt;CR&gt;            \" Add ! comment start block\nmap ,; :s/^/;/&lt;CR&gt;:nohlsearch&lt;CR&gt;            \" Add ; comment start block\nmap ,- :s/^/--/&lt;CR&gt;:nohlsearch&lt;CR&gt;           \" Add -- comment start block\nmap ,c :s/^\\/\\/\\\\|^--\\\\|^&gt; \\\\|^[#\"%!;]//&lt;CR&gt;:nohlsearch&lt;CR&gt;                  \" Clear comment start block\n\"\" Wrapping comments\nmap ,* :s/^\\(.*\\)$/\\/\\* \\1 \\*\\//&lt;CR&gt;:nohlsearch&lt;CR&gt;                          \" Insert /* */ for line\nmap ,( :s/^\\(.*\\)$/\\(\\* \\1 \\*\\)/&lt;CR&gt;:nohlsearch&lt;CR&gt;                          \" Insert (* *) for line\nmap ,&lt; :s/^\\(.*\\)$/&lt;!-- \\1 --&gt;/&lt;CR&gt;:nohlsearch&lt;CR&gt;                           \" Insert &lt;!-- --&gt; for line\nmap ,d :s/^\\([/(]\\*\\\\|&lt;!--\\) \\(.*\\) \\(\\*[/)]\\\\|--&gt;\\)$/\\2/&lt;CR&gt;:nohlsearch&lt;CR&gt; \" Clear wrapped comment\n\nlet mapleader=' '                            \" Use space instead of \\ for leader key\nnnoremap &lt;silent&gt; &lt;leader&gt;h :source ~/.vimrc&lt;CR&gt;                             \" h to reload .vimrc\nnnoremap &lt;silent&gt; &lt;leader&gt;r :set relativenumber!&lt;CR&gt;                         \" m Toggle relative line numbers\nnnoremap &lt;silent&gt; &lt;leader&gt;n :set number!&lt;CR&gt;                                 \" n Toggle line numbers on/off\nnnoremap &lt;silent&gt; &lt;leader&gt;s :call StripTrailingWhitespace()&lt;CR&gt;              \" s Strip EOL/EOF trailing whitespace\nnnoremap &lt;silent&gt; &lt;leader&gt;g :call ColorRightGutters()&lt;CR&gt;                    \" g Toggle right gutter highlighting\nnnoremap &lt;silent&gt; &lt;Leader&gt;&lt;Leader&gt; :e#&lt;CR&gt;                                   \"   Toggle between last opened file\nnnoremap &lt;silent&gt; &lt;leader&gt;f za                                               \" f open/closes fold\n\n\"\" Jump to last known position when opening file.\nautocmd BufReadPost *\n\\ if expand(\"&lt;afile&gt;:p:h\") !=? $TEMP |\n\\   if line(\"'\\\"\") &gt; 0 &amp;&amp; line(\"'\\\"\") &lt;= line(\"$\") |\n\\     exe \"normal g`\\\"\" |\n\\     let b:doopenfold = 1 |\n\\   endif |\n\\ endif\n\n\"\" When in GVIM don't do it when the position is invalid or when inside an event\n\"\" handler, delay using \"zv\" until after reading the modelines.\nautocmd BufWinEnter *\n\\ if exists(\"b:doopenfold\") |\n\\   unlet b:doopenfold |\n\\   exe \"normal zv\" |\n\\ endif\n\n\"\" Always do a full syntax refresh when loading\nautocmd BufEnter * syntax sync fromstart\n\n\"\" Strip EOL/EOF trailing whitespace\nfunction! StripTrailingWhitespace()\n  let save_cursor = getpos('.')\n  silent! %s/\\s\\+$//e                        \" EOL whitespace\n  silent! %s#\\($\\n\\)\\+\\%$##                  \" EOF whitespace\n  call setpos('.', save_cursor)\nendfunction\n\n\"\" Toggle right gutter highlighting\nfunction! ColorRightGutters()\n  if &amp;colorcolumn == \"\"\n    let &amp;colorcolumn=join(range(81,120),\",\").join(range(120,999),\",\")\n  else\n    set colorcolumn=\n  endif\nendfunction</code></pre>"},{"location":"app/vim/#quit-with-error","title":"Quit with Error","text":"<p>Useful for aborting mid-commit without submitting.</p> <pre><code>:cq</code></pre>"},{"location":"app/vim/#insert-unicode-characters","title":"Insert Unicode Characters","text":"<pre><code>i\nctrl+v\nu####</code></pre>"},{"location":"app/vim/#incrementdecrement-a-number","title":"Increment/Decrement A Number","text":"<pre><code>ctrl+A  # Increment.\nctrl+X  # Decrement.</code></pre>"},{"location":"app/vim/#visual-mode","title":"Visual Mode","text":"<pre><code>v       # Character.\nV       # Line.\nctrl+v  # Block.</code></pre>"},{"location":"app/vim/#indentation","title":"Indentation","text":"<pre><code>v\n&gt;\n&lt;</code></pre>"},{"location":"app/vim/#goto-last-edit","title":"Goto Last Edit","text":"<pre><code>gi</code></pre>"},{"location":"app/vim/#delete-to-end-of-line","title":"Delete to End of Line","text":"<pre><code>d$  # Delete only.\nc$  # Delete and enter insert mode.</code></pre>"},{"location":"app/vim/#macros","title":"Macros","text":"<pre><code>qq   # Start recording.\n{PERFORM ACTIONS}\nq    # Stop recording.\n@q   # Repeat recorded actions (first time).\n@@   # Report recorded actions (every time after).\n20@@ # Repeat 20 times.</code></pre>"},{"location":"app/vim/troubleshooting/","title":"Troubleshooting","text":""},{"location":"app/vim/troubleshooting/#troubleshooting","title":"Troubleshooting","text":""},{"location":"app/vim/troubleshooting/#vim-frozen","title":"VIM Frozen","text":"<p>Generally happens when stopping terminal output with control flow.</p> <pre><code>ctrl+s  # stops terminal output (causes freeze) (XON).\nctrl+q  # starts terminal output (XOFF).</code></pre>"},{"location":"app/vscodium/","title":"VSCodium (VSCode)","text":""},{"location":"app/vscodium/#vscodium-vscode","title":"VSCodium (VSCode)","text":"<p>VSCodium is VSCode without telemetry.</p> ManjaroWindows <p>\u2318 \u2794 Add/Remove Software \u2794 Search \u2794 AUR</p> <ul> <li>vscodium-bin</li> <li>vscodium-bin-marketplace</li> <li>vscodium-features</li> </ul> <p>Settings are located in: ~/.vscode-oss and ~/.config/VSCodium.</p> <pre><code>winget install vscodium</code></pre>"},{"location":"app/vscodium/#window-style","title":"Window Style","text":"<p>ctrl + , \u2794 Window</p> <ul> <li>Title bar style: native</li> <li>Dialog style: native</li> </ul>"},{"location":"app/vscodium/#disable-copilot","title":"Disable Copilot","text":"<p>ctrl + , \u2794 Features \u2794 Chat \u2794 Command Center: \u2718</p>"},{"location":"app/vscodium/#allow-no-verify-commits","title":"Allow No Verify Commits","text":"<p>ctrl + , \u2794 User \u2794 Extensions \u2794 Git \u2794 Allow No Verify Commit: \u2714</p>"},{"location":"app/vscodium/#enable-commit-signing","title":"Enable Commit Signing","text":"<p>ctrl + , \u2794 User \u2794 Extensions \u2794 Git \u2794 Enable Commit Signing: \u2714</p>"},{"location":"app/vscodium/#use-vscodium-as-commit-editor","title":"Use VSCodium as Commit Editor","text":"<p>ctrl + , \u2794 User \u2794 Extensions \u2794 Git</p> <ul> <li>Terminal Authentication: \u2714</li> <li>Use Editor As Commit Input: \u2714</li> </ul>"},{"location":"app/vscodium/#use-terminal-for-github-authentication","title":"Use Terminal for Github Authentication","text":"<p>ctrl + , \u2794 User \u2794 Extensions \u2794 Git \u2794 Terminal Authentication: \u2714</p> <p>ctrl + , \u2794 User \u2794 Extensions \u2794 GitHub \u2794 Git Authentication: \u2714</p>"},{"location":"app/vscodium/#exclude-files-in-file-explorer","title":"Exclude Files in File Explorer","text":"<p>ctrl + , \u2794 User \u2794 Explorer \u2794 Auto Reveal Exclude</p> <p>Add files with globbing to ignore.</p>"},{"location":"app/vscodium/#terminal-profiles","title":"Terminal Profiles","text":"<p>Set default shell and profile preferences.</p> <p>ctrl+, \u2794 Open Settings (JSON) (upper right)</p> <p>Set default shell profiles for each OS: </p><pre><code>\"terminal.integrated.defaultProfile.linux\": \"bash\",\n\"terminal.integrated.defaultProfile.osx\": \"bash\",\n\"terminal.integrated.defaultProfile.windows\": \"powershell\",</code></pre><p></p> <p>Set profile customization: </p><pre><code>\"terminal.integrated.profiles.linux\": {\n  \"bash\": {\n    \"path\": \"bash\",\n    \"args\": [\"-l\"],\n    \"icon\": \"terminal-bash\"\n  },\n  \"tmux\": {\n    \"path\": \"tmux\",\n    \"icon\": \"terminal-tmux\"\n  },\n},\n\"terminal.integrated.profiles.osx\": {\n  \"bash\": {\n    \"path\": \"bash\",\n    \"args\": [\"-l\"],\n    \"icon\": \"terminal-bash\"\n  },\n  \"tmux\": {\n    \"path\": \"tmux\",\n    \"icon\": \"terminal-tmux\"\n  },\n},\n\"terminal.integrated.profiles.windows\": {\n  \"PowerShell\": {\n    \"source\": \"PowerShell\",\n    \"icon\": \"terminal-powershell\"\n  },\n  \"Command Prompt\": {\n    \"path\": [\n      \"${env:windir}\\\\Sysnative\\\\cmd.exe\",\n      \"${env:windir}\\\\System32\\\\cmd.exe\"\n    ],\n    \"args\": [],\n    \"icon\": \"terminal-cmd\"\n  },\n  \"Git Bash\": {\n    \"source\": \"Git Bash\"\n  }\n},</code></pre><p></p> <p>Restart.</p>"},{"location":"app/vscodium/#suggested-extensions","title":"Suggested Extensions","text":"<ul> <li>Ansible</li> <li>Better Align</li> <li>Code Runner</li> <li>Code Spell Checker</li> <li>ES7+ React/Redux/React-Native snippets</li> <li>Even Better TOML</li> <li>Git Blame</li> <li>GitHub Markdown Preview</li> <li>Go</li> <li>Go Coverage Viewer</li> <li>Go Doc</li> <li>Go Extension Pack</li> <li>Go Test Explorer</li> <li>Gremlins tracker for Visual Studio Code</li> <li>isort</li> <li>jinja</li> <li>Markdown Checkboxes</li> <li>Markdown Emoji</li> <li>Markdown Footnotes</li> <li>Markdown Preview Github Styling</li> <li>Markdown Preview Mermaid Support</li> <li>Markdown Table Formatter</li> <li>Markdown yaml Preamble</li> <li>NGINX Configuration Language Support</li> <li>PascalCase/camelCase to snake_case</li> <li>Paste JSON as Code</li> <li>Pylance</li> <li>Pylint</li> <li>Python</li> <li>Python Debugger</li> <li>Python Environments</li> <li>REG</li> <li>reStructuredText Syntax Highlighting</li> <li>Rewrap</li> <li>Scientific Terms - Code Spell Checker</li> <li>Sort lines</li> <li>Trailing Spaces</li> <li>vscode-go-syntax</li> <li>vscode-proto3</li> <li>YAML</li> <li>YAML to JSON</li> </ul>"},{"location":"app/vscodium/troubleshooting/","title":"Troubleshooting","text":""},{"location":"app/vscodium/troubleshooting/#troubleshooting","title":"Troubleshooting","text":""},{"location":"app/vscodium/troubleshooting/#repository-does-not-automatically-open-all-submodules","title":"Repository does not automatically open all submodules","text":"<p>Default submodule load limit is low.</p> <p>repository has XX submodules which won't be opened automatically. You can still open each one individually by opening a file within.</p> <p>ctrl + , \u2794 User \u2794 Extensions \u2794 Git</p> <ul> <li>Detect Submodules: \u2714</li> <li>Detect Submodules Limit: 50</li> <li>Repository Scan Max Dept: -1</li> </ul>"},{"location":"app/vscodium/troubleshooting/#unlock-login-keyring-always-prompted","title":"Unlock Login Keyring Always Prompted","text":"<p>KDE Wallet is used to securely store GitHub credentials.</p> <p>May be prompted on every open if KDE Wallet is not enabled.</p> <p>\u2318 \u2794 System Settings \u2794 Security &amp; Privacy \u2794 KDE Wallet</p> <ul> <li>Enable the KDE Wallet Subsystem: \u2714</li> <li>Use KDE Wallet for the Secret Service interface: \u2714</li> </ul>"},{"location":"arr/deluge/","title":"Deluge","text":""},{"location":"arr/deluge/#deluge","title":"Deluge","text":"<p>Bittorrent downloader.</p> <p>Migrated to ansible collection</p> <p>Use r_pufky.arr.deluge.</p> <p>Tip</p> <ul> <li>The UID/GID should be set to a user/group that has access to your media.   All media clients should run under the same user to run correctly.</li> <li>Your downloader will report the download path mapped in the downloader   service. You need to map this exact path in Deluge for it to be able to   post-process downloads properly.</li> <li>Deluge must be connected to the Daemon to write configuration   changes. Select Connection Manager \u2794 Connect when logging in.</li> <li>max_upload_speed should be set to a non-zero number to enable   downloads.</li> </ul>"},{"location":"arr/deluge/#reverse-proxy","title":"Reverse Proxy","text":"<p>Deluge should be run via a Reverse Proxy, allowing you to isolate and wrap connections in SSL. See NGINX for more details. See Base Proxy Control for basic proxy configuration.</p> <p>/etc/nginx/conf.d/reverse_proxy.conf</p> <p>0644 root:root</p> <pre><code># Subdomain\nserver {\n  listen                       443 ssl http2;\n  server_name                  deluge.{DOMAIN} deluge;\n\n  location / {\n    proxy_pass                 http://deluge:8112;\n    include                    /etc/nginx/conf.d/proxy-control.conf;\n    add_header X-Frame-Options SAMEORIGIN;\n  }\n}</code></pre> <p>/etc/nginx/conf.d/reverse_proxy.conf</p> <p>0644 root:root</p> <pre><code># Subpath\nserver {\n  location /deluge {\n    proxy_pass                     http://deluge:8112/;\n    include                        /etc/nginx/conf.d/proxy-control.conf;\n    proxy_set_header X-Deluge-Base '/deluge/';\n    add_header X-Frame-Options     SAMEORIGIN;\n  }\n}</code></pre>"},{"location":"arr/lidarr/","title":"Lidarr","text":""},{"location":"arr/lidarr/#lidarr","title":"Lidarr","text":"<p>Lidarr Server.</p> <p>Migrated to ansible collection</p> <p>Use r_pufky.arr.lidarr.</p> <p>Tip</p> <ul> <li>The UID/GID should be set to a user/group that has access to your media.   All media clients should run under the same user to run correctly.</li> <li>Your downloader will report the download path mapped in the downloader   service. You need to map this exact path in Radarr for it to be able to   post-process downloads properly.</li> </ul>"},{"location":"arr/lidarr/#reverse-proxy","title":"Reverse Proxy","text":"<p>Lidarr should be run via a Reverse Proxy, allowing you to isolate and wrap connections in SSL. See NGINX for more details. See Base Proxy Control for basic proxy configuration.</p> <p>/etc/nginx/conf.d/reverse_proxy.conf</p> <p>0644 root:root</p> <pre><code># Subdomain\nserver {\n  listen       443 ssl http2;\n  server_name  lidarr.{DOMAIN} lidarr;\n\n  location / {\n    proxy_pass http://lidarr:8686;\n    include    /etc/nginx/conf.d/proxy_control.conf;\n  }\n}</code></pre> <p>/etc/nginx/conf.d/reverse_proxy.conf</p> <p>0644 root:root</p> <pre><code># Subpath\nserver {\n  location /lidarr {\n    proxy_pass http://lidarr:8686/lidarr;\n    include    /etc/nginx/conf.d/proxy_control.conf;\n  }\n}</code></pre>"},{"location":"arr/nzbget/","title":"NZBGet","text":""},{"location":"arr/nzbget/#nzbget","title":"NZBGet","text":"<p>NZBGet Server.</p> <p>Migrated to ansible collection</p> <p>Use r_pufky.arr.nzbget.</p> <p>Tip</p> <ul> <li>The UID/GID should be set to a user/group that has access to your media.   All media clients should run under the same user to run correctly.</li> <li>Your downloader will report the download path mapped in the downloader   service. You need to map this exact path in NZBGet for it to be able to   post-process downloads properly.</li> </ul>"},{"location":"arr/nzbget/#reverse-proxy","title":"Reverse Proxy","text":"<p>NZBGet should be run via a Reverse Proxy, allowing you to isolate and wrap connections in SSL. See NGINX for more details. See Base Proxy Control for basic proxy configuration.</p> <p>/etc/nginx/conf.d/reverse_proxy.conf</p> <p>0644 root:root</p> <pre><code>server {\n  listen                  443 ssl http2;\n  server_name             nzbget.{DOMAIN} nzbget;\n\n  location / {\n    proxy_pass            http://nzbget:6791;\n    include               /etc/nginx/conf.d/proxy-control.conf;\n    proxy_set_header Host $host;\n  }\n}</code></pre> <p>/etc/nginx/conf.d/reverse_proxy.conf</p> <p>0644 root:root</p> <pre><code>server {\n  location /nzbget/ {\n    proxy_pass            https://nzbget:6791/;\n    include               /etc/nginx/conf.d/proxy-control.conf;\n    proxy_set_header Host $host;\n  }\n}</code></pre>"},{"location":"arr/playon/","title":"PlayOn","text":""},{"location":"arr/playon/#playon","title":"PlayOn","text":"<p>Steaming service recorder.</p> <p>Tip</p> <p>Port 57331 is only used if you use PlayOn to stream recordings / provide a media library; by default this can be safely disabled.</p>"},{"location":"arr/playon/#setup","title":"Setup","text":"<p>Minimum requirements.</p> <p>Note</p> <p>Any option not listed is left on default setting.</p> <ol> <li>Install PlayOn Desktop but do not launch immediately.</li> <li>Launch and skip through helper setup screens.</li> </ol> <p>PlayOn \u2794 \u2699</p> <ul> <li>Video Performance\"<ul> <li>Quality: HD</li> <li>Allow resumable playback: \u2714</li> <li>Advanced options:<ul> <li>H.264 Recording Profile: High</li> </ul> </li> </ul> </li> <li>System Check:<ul> <li>Notify Automatically: \u2714</li> </ul> </li> <li>Channels:<ul> <li>Disable all channels not used.</li> <li>Login to used channels.</li> </ul> </li> </ul>"},{"location":"arr/playon/#convert-playon-recording-to-mkv-containers","title":"Convert PlayOn Recording to MKV Containers","text":"<pre><code>#!/bin/bash\n#\n# Converts playon videos to mkv format, preserving encoding and stripping metadata.\n# For multiple: find -type f -exec ~/bin/playon-to-mkv netflix|amazon|playon|custom {}\n#\n\n# playon-to-mkv [netflix|amazon|playon] file\n# playon-to-mkv custom pre-trim post-trim file\n\n# Playon adds a 4 second pre-roll video with account/IP address, strip this.\n# Playon adds a 5 second post-roll video with account/IP address, strip this.\n# Playon adds metadata pertaining to account for video, strip this.\nPLAYON_PRE=4\nPLAYON_POST=5\n\n# Netflix adds a 6.5 second netflix video, strip this.\n# Netflix can inject a blank screen at the end, but it is not consistent.\nNETFLIX_PRE=6\nNETFLIX_POST=0\n\n# Amazon adds a 1.5 second post-roll video for series, strip this.\nAMAZON_PRE=0\nAMAZON_POST=1.5\n\necho 'Calculating distances ...'\nFILE=\"$2\"\ncase \"$1\" in\n  \"netflix\")\n    echo 'Processing NETFLIX'\n    PRE=$(awk '{print $1+$2}' &lt;&lt;&lt; \"${PLAYON_PRE} ${NETFLIX_PRE}\")\n    POST=$(awk '{print $1+$2}' &lt;&lt;&lt; \"${PLAYON_POST} ${NETFLIX_POST}\")\n    ;;\n  \"amazon\")\n    echo 'Processing AMAZON'\n    PRE=$(awk '{print $1+$2}' &lt;&lt;&lt; \"${PLAYON_PRE} ${AMAZON_PRE}\")\n    POST=$(awk '{print $1+$2}' &lt;&lt;&lt; \"${PLAYON_POST} ${AMAZON_POST}\")\n    ;;\n  \"custom\")\n    echo 'Processing CUSTOM'\n    PRE=$2\n    POST=$3\n    FILE=\"$4\"\n    ;;\n  *)\n    echo 'Prcessing PLAYON'\n    PRE=${PLAYON_PRE}\n    POST=${PLAYON_POST}\n    ;;\nesac\nfilename=$(basename \"${FILE}\")\ndir=$(dirname \"${FILE}\")\nextension=\"${filename##*.}\"\nbasename=\"${filename%.*}\"\n\nORIGINAL_LENGTH=$(ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 \"${FILE}\" | cut -d\\. -f1)\nTRIM_LENGTH=$(awk '{print $1-$2-$3}' &lt;&lt;&lt; \"${ORIGINAL_LENGTH} ${PRE} ${POST}\")\necho -e \"Distances: \\nLength: ${ORIGINAL_LENGTH}\\nPre Offset: ${PRE}\\nPost Offset: ${POST}\\nTrim: ${TRIM_LENGTH}\"\n\necho 'Stripping metadata and trimming ...'\nffmpeg -i \"${FILE}\" -ss ${PRE} -acodec copy -vcodec copy -map_metadata -1 -t ${TRIM_LENGTH} \"${dir}/${basename}.stripped.${extension}\"\necho 'Packing into mkv ...'\nmkvmerge -o \"$-{basename}.mkv\" \"${basename}.stripped.${extension}\"\necho 'Setting media permssions ...'\nchown ${USER}:${USER} \"${basename}.mkv\"\nchmod 0640 \"${basename}.mkv\"</code></pre>"},{"location":"arr/playon/#references","title":"References<sup>1</sup><sup>2</sup><sup>3</sup>","text":"<ol> <li> <p>https://www.playon.tv/support/minreqs \u21a9</p> </li> <li> <p>https://www.playon.tv/user-guide/intro \u21a9</p> </li> <li> <p>https://forums.webosnation.com/webos-apps-games/297294-port-forwarding-playon.html \u21a9</p> </li> </ol>"},{"location":"arr/radarr/","title":"Radarr","text":""},{"location":"arr/radarr/#radarr","title":"Radarr","text":"<p>Radarr Server.</p> <p>Migrated to ansible collection</p> <p>Use r_pufky.arr.radarr.</p> <p>Tip</p> <ul> <li>The UID/GID should be set to a user/group that has access to your media.   All media clients should run under the same user to run correctly.</li> <li>Your downloader will report the download path mapped in the downloader   service. You need to map this exact path in Radarr for it to be able to   post-process downloads properly.</li> </ul>"},{"location":"arr/radarr/#reverse-proxy","title":"Reverse Proxy","text":"<p>Radarr should be run via a Reverse Proxy, allowing you to isolate and wrap connections in SSL. See NGINX for more details. See Base Proxy Control for basic proxy configuration.</p> <p>/etc/nginx/conf.d/reverse_proxy.conf</p> <p>0644 root:root</p> <pre><code># Subdomain\nserver {\n  listen       443 ssl http2;\n  server_name  radarr.{DOMAIN} radarr;\n\n  location / {\n    proxy_pass http://radarr:7878;\n    include    /etc/nginx/conf.d/proxy-control.conf;\n  }\n}</code></pre> <p>/etc/nginx/conf.d/reverse_proxy.conf</p> <p>0644 root:root</p> <pre><code># Subpath\nserver {\n  location /radarr {\n    proxy_pass http://radarr:7878/radarr;\n    include    /etc/nginx/conf.d/proxy-control.conf;\n  }\n}</code></pre>"},{"location":"arr/radarr/troubleshooting/","title":"Troubleshooting","text":""},{"location":"arr/radarr/troubleshooting/#troubleshooting","title":"Troubleshooting","text":""},{"location":"arr/radarr/troubleshooting/#add-pre-existing-series-to-radarr","title":"Add Pre-existing Series to Radarr","text":"<ol> <li>Existing files should be in a folder for each movie.</li> <li>Movie \u2794 Bulk Import Movies \u2794 /data/movies</li> <li>Be sure to set appropriate import behavior.</li> <li>Be sure to search for correct match for episode if needed.</li> <li>Import may timeout if initial import library is large. Restart import.</li> </ol> <p>Movies \u2794 Update Library</p>"},{"location":"arr/radarr/troubleshooting/#ensure-no-duplicate-plex-updates","title":"Ensure no Duplicate Plex Updates","text":"<p>Plex will trigger updates on inotify events if configured to do so. If that is the case:</p> <p>Connect \u2794 Plex \u2794 Update Library \u2794 Disable</p> <p>Otherwise duplicate items will appear on single files.</p>"},{"location":"arr/radarr/troubleshooting/#failures-with-tmdb","title":"Failures with TMdb","text":"<p>These are DNS resolution failures. Generally these happened because of rate limiting due to large number of changes at one time. Upgrade system packages or re-apply role to ensure the latest mono project certificates are installed as well.</p> <pre><code>apt update &amp;&amp; apt upgrade</code></pre>"},{"location":"arr/sonarr/","title":"Sonarr","text":""},{"location":"arr/sonarr/#sonarr","title":"Sonarr","text":"<p>Sonarr Server.</p> <p>Migrated to ansible collection</p> <p>Use r_pufky.arr.sonarr.</p> <p>Tip</p> <ul> <li>The UID/GID should be set to a user/group that has access to your media.   All media clients should run under the same user to run correctly.</li> <li>Your downloader will report the download path mapped in the downloader   service. You need to map this exact path in Sonarr for it to be able to   post-process downloads properly.</li> </ul>"},{"location":"arr/sonarr/#reverse-proxy","title":"Reverse Proxy","text":"<p>Sonarr should be run via a Reverse Proxy, allowing you to isolate and wrap connections in SSL. See NGINX for more details. See Base Proxy Control for basic proxy configuration.</p> <p>/etc/nginx/conf.d/reverse_proxy.conf</p> <p>0644 root:root</p> <pre><code># Subdomain\nserver {\n  listen       443 ssl http2;\n  server_name  sonarr.{DOMAIN} sonarr;\n\n  location / {\n    proxy_pass http://sonarr:8989;\n    include    /etc/nginx/conf.d/proxy-control.conf;\n  }\n}</code></pre> <p>/etc/nginx/conf.d/reverse_proxy.conf</p> <p>0644 root:root</p> <pre><code># Subpath\nserver {\n  location /sonarr {\n    proxy_pass http://sonarr:8989/sonarr;\n    include    /etc/nginx/conf.d/proxy-control.conf;\n  }\n}</code></pre>"},{"location":"arr/sonarr/troubleshooting/","title":"Troubleshooting","text":""},{"location":"arr/sonarr/troubleshooting/#troubleshooting","title":"Troubleshooting","text":""},{"location":"arr/sonarr/troubleshooting/#add-pre-existing-series-to-sonarr","title":"Add Pre-existing Series to Sonarr","text":"<ol> <li>Existing files should be in a folder for each movie.</li> <li>Movie \u2794 Bulk Import Movies \u2794 /data/tv</li> <li>Set appropriate import behavior.</li> <li>Search for correct match for episode if needed.</li> <li>Add all existing shows (even no longer aired), these are all scanned when    adding shows and will be crufty if not set.</li> </ol>"},{"location":"arr/sonarr/troubleshooting/#changing-media-location-in-series","title":"Changing Media Location in Series","text":"<p>If series were imported under a different directory initially, these can be updated.</p> <ol> <li>Series \u2794 Series Editor</li> <li>Select all series that had location changes.</li> <li>Root Folder (lower right) and enter new folder location.</li> <li>Save.</li> </ol>"},{"location":"arr/sonarr/troubleshooting/#ensure-no-duplicate-plex-updates","title":"Ensure no Duplicate Plex Updates","text":"<p>Plex will trigger updates on inotify events if configured to do so. If that is the case:</p> <p>Connect \u2794 Plex \u2794 Update Library \u2794 Disable.</p> <p>Otherwise duplicate items will appear on single files.</p>"},{"location":"arr/sonarr/troubleshooting/#failures-with-searches","title":"Failures with Searches","text":"<p>These are DNS resolution failures. Generally these happened because of rate limiting due to large number of changes at one time. Upgrade system packages or re-apply role to ensure the latest mono project certificates are installed as well.</p> <pre><code>apt update &amp;&amp; apt upgrade</code></pre>"},{"location":"games/conan_exiles/","title":"Conan Exiles","text":""},{"location":"games/conan_exiles/#conan-exiles","title":"Conan Exiles","text":"<p>Migrated to ansible collection</p> <p>Use r_pufky.games.conan_exiles.</p> <p>Tip</p> <ul> <li>If connecting on local network, use the private IP of the server, not the   public IP address.</li> <li>conan_exiles_srv_root/ConanSandbox/Saved contains server state   information.</li> </ul>"},{"location":"games/elden_ring/","title":"Elden Ring","text":""},{"location":"games/elden_ring/#elden-ring","title":"Elden Ring","text":""},{"location":"games/elden_ring/#linux-install","title":"Linux Install","text":"<p>Tip</p> <p>You can just install directly from steam if you haven't downloaded the game already, or don't mind downloading again.</p> <pre><code># Copy from windows partition to linux\ncp -av /mnt/win/Program Files (x86)/Steam/steamapps/common/ELDEN RING \\\n  ~/.steam/steam/steamapps/common/ELDEN RING</code></pre> <p>From steam install Elden Ring - it should validate files instead and download Proton.</p>"},{"location":"games/elden_ring/#install-seemless-co-op","title":"Install Seemless Co-Op","text":"<p>Download Seemless Coop and extract to Elden Ring location (Steam \u2794 Elden Ring \u2794 RMB \u2794 Manage \u2794 Browse Local Files).</p> <p>Modify settings to taste.</p> <p>Game/SeamlessCoop/ersc_settings.ini</p> <p>0644 {USER}:{USER}</p> <pre><code>[GAMEPLAY]\n\n; Invaders are other players that will join your world uninvited and try to\n; kill you and your party.  0=FALSE  1=TRUE\nallow_invaders = 0\n\n; Debuffs (Rot Essence) will be acquired when you die, and will only be\n; cured when you sit at a bonfire.  0=FALSE  1=TRUE\ndeath_debuffs = 0\n\n; Spirit summons can aid you in multiplayer.  0=FALSE  1=TRUE\nallow_summons = 1\n\n; 0 = Normal | 1 = None | 2 = Display player ping | 3 = Display player soul\n; level | 4 = Display player death count | 5 = Soul level AND ping\noverhead_player_display = 4\n\n; Whether to skip the intro logos when booting the game. 0 = FALSE 1 = TRUE\nskip_splash_screens = 1\n\n; Game volume before initial save load. 0 = MUTE 10 = MAX\ndefault_boot_master_volume = 2\n\n[SCALING]\n\n; Amount of enemy health (%) per player for each enemy. (Default: 35 = 35%\n; more enemy health per player)\nenemy_health_scaling = 35\n\n; Amount of enemy damage (%) per player for each enemy. (Default: 0 = 0%\n; more enemy damage per player)\nenemy_damage_scaling = 0\n\n; Amount of enemy posture absorption (%) per player for each enemy.\n; (Default: 15 = 15% more per player)\nenemy_posture_scaling = 15\n\n; Amount of boss health (%) per player for bosses. (Default: 100 = 100%\n; more boss health per player)\nboss_health_scaling = 100\n\n; Amount of enemy damage (%) per player for bosses. (Default: 0 = 0% more\n; enemy damage towards players, per player)\nboss_damage_scaling = 0\n\n; Amount of boss posture absorption (%) per player for bosses. (Default:\n; 20 = 20% more boss posture per player)\nboss_posture_scaling = 20\n\n[PASSWORD]\n\n; Session password\ncooppassword = {SESSION_PASSED}\n\n[SAVE]\n\n;Your save file extension (in the vanilla game this is .sl2). Use any\n; alphanumeric characters (limit = 120)\nsave_file_extension = co2\n\n[LANGUAGE]\n\n;Leave this blank unless you want to load a custom locale file. The mod\n; will default to your game language.\nmod_language_override = (docs)</code></pre>"},{"location":"games/elden_ring/#create-co-op-shortcut","title":"Create Co-Op Shortcut","text":"<p>Tip</p> <p>Existing Elden Ring library covers are located at: ~/.steam/steam/appcache/librarycache/1245620/</p> <p>Steam \u2192 Games \u2192 Add a non-steam game</p> <ul> <li>Executable: ~/.steam/steam/steamapps/common/ELDEN RING/Game/ersc_launcher.exe</li> <li>shortcut: ELDEN RING (coop)</li> <li>compatibility:<ul> <li>Force use of specific steam play compatibility tool: Proton (hotfix)</li> </ul> </li> <li>Controller: Setup your controller device</li> <li>Customization:<ul> <li>Cover: Library_600x900.jpg</li> <li>Background: Library_hero.jpg</li> <li>Logo: logo.png</li> <li>Wide cover: header.jpg</li> <li>Custom sort name: ELDEN RING (coop)</li> </ul> </li> </ul> <p>Launch new game shortcut, accept TOS, and quit (saves not loaded yet).</p>"},{"location":"games/elden_ring/#transfer-window-saves","title":"Transfer Window Saves","text":"<p>Copy profile information from Windows and place in both Steam and Proton directories.</p> <pre><code># Copy to Steam Profile.\ncp -av /mnt/win/Users/{USER}/AppData/Roaming/EldenRing/ \\\n  ~/.local/share/Steam/steamapps/compatdata/1245620/pfx/drive_c/users/steamuser/AppData/Roaming/EldenRing/{STEAMID64}/\n\n# Copy to Proton Profile.\ncp -av /mnt/win/Users/{USER}/AppData/Roaming/EldenRing/ \\\n  ~/.local/share/Steam/steamapps/compatdata/{VERY_LARGE_NUMBER}/pfx/drive_c/users/steamuser/AppData/Roaming/EldenRing/{STEAMID64}</code></pre> <p>Info</p> <p>The new app id will be very large and mirror ELDEN RING app data.</p> <p>Relaunch custom game with coop saves.</p>"},{"location":"games/seven_days_to_die/","title":"Seven Days to Die","text":""},{"location":"games/seven_days_to_die/#seven-days-to-die","title":"Seven Days to Die","text":"<p>Migrated to ansible collection</p> <p>Use r_pufky.games.seven_days_to_die.</p> <p>Tip</p> <ul> <li>If connecting on local network, use the private IP of the server, not the   public IP address.</li> <li>Control Panel and Telnet are insecure. Disable and block ports.</li> <li>seven_days_to_die_srv_root/saves contains server state information.</li> </ul>"},{"location":"games/escape_from_tarkov/","title":"Escape from Tarkov","text":""},{"location":"games/escape_from_tarkov/#escape-from-tarkov","title":"Escape from Tarkov","text":""},{"location":"games/escape_from_tarkov/#fika-server","title":"FIKA Server","text":"<p>FIKA is a locally hosted multiplayer serve for Escape from Tarkov.</p> <p>Tip</p> <p>See FIKA Server to setup a dedicated server. This assumes a server is already configured.</p>"},{"location":"games/escape_from_tarkov/#windows","title":"Windows","text":"<p>Install EFT and disable automatic updates. Note the installed version.</p> <p>EFT Launcher \u2794 Profile \u2794 Settings \u2794 Updates: \u2718</p> <p>Updates are disabled to ensure mod always works.</p> <p>Install mod dependencies:</p> <ul> <li>Net Framework 4.7.2.</li> <li>.NET Runtime 6.</li> </ul>"},{"location":"games/escape_from_tarkov/#automatic-installation","title":"Automatic Installation","text":"<p>This is a user supported tool which automatically applies all patches required. Preferred.</p> <ol> <li>Download the installer.</li> <li> <p>Create an empty folder for SPT to be installed to and extract installer to     this location. Prefer same drive and root folder as EFT.</p> <p>Suggest: c:\\Battlestate Games\\SPT</p> </li> <li> <p>Run installer.</p> </li> </ol>"},{"location":"games/escape_from_tarkov/#manual-installation","title":"Manual Installation","text":"<p>Tip</p> <p>Only do this if you know what you are doing. This requires knowing what version of EFT you are running, then manually downgrading to the latest SPT-AKI supported version and applying the SPT-AKI patches.</p> <ol> <li>Copy c:\\Battlestate Games\\EFT to c:\\Battlestate Games\\SPT.</li> <li>Download the downgrade patcher for the specific version you have    installed. This will downgrade the SPT install to the currently supported    SPT version.</li> <li>Extract patcher files to c:\\Battlestate Games\\SPT.</li> <li>Run patcher and ignore virus warnings (triggered as these are re-writing     signed binaries).</li> <li>Download the SPT installer and extract to c:\\Battlestate Games\\SPT.</li> <li>Run installer (ignore virus warnings - these rewrite signed binaries).</li> </ol>"},{"location":"games/escape_from_tarkov/#launching-game","title":"Launching Game","text":"<p>Must be launched in the following order to run properly.</p> <ol> <li>Launch the server (Server.exe if manually patched):     c:\\Battlestate Games\\SPT\\Aki.Server.exe</li> <li>Launch the client (Launcher.exe if manually patched):     c:\\Battlestate Games\\SPT\\Aki.Client.exe</li> <li>Create account with entitlements:<ul> <li>Launcher \u2794 Make a new account</li> <li>Select whatever entitlements you wish (starting items).</li> <li>Launcher \u2794 Start game</li> </ul> </li> </ol>"},{"location":"games/escape_from_tarkov/#settings","title":"Settings","text":"<p>Game settings that balance colors and rendering quality.</p> <p>EFT \u2794 \u2699 \u2794 Graphics</p> <ul> <li>Object LOD quality: 2.5</li> <li>Overall visibility: 1500</li> <li>Anti-aliasing: TAA High</li> <li>Resampling: 1x off</li> <li>Nvidia DLSS: Off</li> <li>HBAO: Off</li> <li>SSR: Off</li> <li>Antistropic Filtering: Off</li> <li>Nvidia Reflex Low Latency: On and boost</li> <li>Sharpness: 0.4</li> <li>High quality color: \u2718</li> <li>Z-Blur: \u2718</li> <li>Chromatic Aberrations: \u2718</li> <li>Noise: \u2718</li> <li>Gress Shadows: \u2718</li> <li>Mip Streaming: \u2718</li> <li>Flash Indicator: \u2718</li> </ul> <p>Nvidia Control Panel \u2794 Display \u2794 Adjust desktop color settings</p> <ul> <li>Apply color enhancements:<ul> <li>Color channel: All channels</li> <li>Brightness: +60%</li> <li>Contrast: +75%</li> <li>Gamma: +1.40</li> <li>Digital vibrance: +80%</li> <li>Hue: 0</li> </ul> </li> </ul>"},{"location":"games/escape_from_tarkov/#reference","title":"Reference<sup>1</sup><sup>2</sup><sup>3</sup><sup>4</sup><sup>5</sup>","text":"<ol> <li> <p>https://github.com/sp-tarkov/patcher \u21a9</p> </li> <li> <p>https://www.sp-tarkov.com/#download \u21a9</p> </li> <li> <p>https://www.sp-tarkov.com/#features \u21a9</p> </li> <li> <p>https://hub.sp-tarkov.com/files/file/6-spt-aki \u21a9</p> </li> <li> <p>https://dev.sp-tarkov.com/SPT-AKI \u21a9</p> </li> </ol>"},{"location":"games/escape_from_tarkov/server/","title":"FIKA Server","text":""},{"location":"games/escape_from_tarkov/server/#fika-server","title":"FIKA Server","text":"<p>FIKA is a locally hosted multiplayer serve for Escape from Tarkov.</p>"},{"location":"games/escape_from_tarkov/server/#requirements","title":"Requirements","text":"Type Minimum Requirement RAM ~1GB DISK ~500MB (~8GB during build process) CPU ~1 core"},{"location":"games/escape_from_tarkov/server/#dedicated-server-ports","title":"Dedicated Server Ports","text":"<ol> <li> <p>'Dedicated server' syncs state, profiles, and enforces settings.     This is the linux server.</p> <p>Ports: TCP 6969 in/out</p> </li> <li> <p>'Host server' actually hosts the game using game assets.     This is the client with the most powerful machine.</p> <p>Ports: UDP 25565 in/out</p> </li> <li> <p>FIKA will force clients to locally process hit registration, culling, etc.     If you are running a 'dedicated server' separately from the 'host server'     you will need to forward the following ports to your machine. The dedicated     server will redirect clients automatically (clients specify the dedicated     server to connect to):</p> </li> </ol>"},{"location":"games/escape_from_tarkov/server/#setup","title":"Setup","text":"<p>Add packages, users, and directories. </p><pre><code>apt update &amp;&amp; apt dist-upgrade\napt install sudo vim ssh git git-lfs\nadduser {USER} sudo\nadduser eft\n\nsudo mkdir /opt/eft\nsudo chown eft:eft /opt/eft\nsudo su - eft</code></pre><p></p> <p>Set build environment. </p><pre><code># Set these to the current release.\nexport SPT_TAG=3.9.8\nexport FIKA_TAG=v2.2.8\nexport NODE_VERSION=20.11.1\n\n# Setup NPM/NVM in current environment\ngit clone https://github.com/nvm-sh/nvm ~/.nvm\n. ~/.nvm/nvm.sh\nsource ~/.bashrc\nnvm install $NODE_VERSION</code></pre><p></p> <p>Build server from source. </p><pre><code># Large repository causes clone issues occasionally; only grab latest files\ngit clone --depth 1 --branch $SPT_TAG https://dev.sp-tarkov.com/SPT/Server ~/srv\ncd ~/srv/project\n\n# SPT=use head from current branch\ngit checkout HEAD^\ngit lfs fetch --all\ngit lfs pull\n\n# Remove AKI encoding\nsed -i '/setEncoding/d' ~/srv/project/src/Program.ts\nnpm install\n\n# Ignore modFilePath warnings, these do not exist during build.\nnpm run build:release -- --arch=x64 --platform=linux\nmv build/* /opt/eft/\nrm -rfv ~/srv</code></pre><p></p> <p>Build FIKA server mod. </p><pre><code>git clone --branch $FIKA_TAG https://github.com/project-fika/Fika-Server /opt/eft/user/mods/fika-server\ncd /opt/eft/user/mods/fika-server\ngit checkout HEAD^\nnpm install</code></pre><p></p> <p>Generate initial configuration files and bind to all interfaces. </p><pre><code>cd /opt/eft\n# Generate initial configs and kill after 25 seconds.\nnohup timeout --preserve-status 25s ./SPT.Server.exe &gt;/dev/null 2&gt;&amp;1\n# Wait 30 seconds to shutdown\nsed -i 's/127.0.0.1/0.0.0.0/g' /opt/eft/SPT_Data/Server/configs/http.json</code></pre><p></p> <p>Set FIKA server settings to preferred options.</p> <p>/opt/eft/user/mods/fika-server/assets/configs/fika.jsonc</p> <p>0644 eft:eft</p> <pre><code>{\n  \"client\": {\n    \"useBtr\": true,\n    \"friendlyFire\": true,\n    \"dynamicVExfils\": false,\n    \"allowFreeCam\": false,\n    \"allowSpectateFreeCam\": true,\n    \"allowItemSending\": true,\n    \"blacklistedItems\": [],\n    \"forceSaveOnDeath\": false,\n    \"mods\": {\n      \"required\": [],\n      \"optional\": []\n    },\n    \"useInertia\": true,\n    \"sharedQuestProgression\": true\n  },\n  \"server\": {\n    \"giftedItemsLoseFIR\": false,\n    \"launcherListAllProfiles\": false,\n    \"sessionTimeout\": 5,\n    \"showDevProfile\": false,\n    \"showNonStandardProfile\": false\n  },\n  \"natPunchServer\": {\n    \"enable\": false,\n    \"port\": 6790,\n    \"natIntroduceAmount\": 1\n  }\n  \"dedicated\": {\n    \"profiles\": {\n      \"amount\": 0\n    },\n    \"scripts\": {\n      \"generate\": true,\n      \"forceIp\": \"\"\n    }\n  },\n  \"background\": {\n    \"enable\": true,\n    \"easteregg\": false\n  }\n}</code></pre>"},{"location":"games/escape_from_tarkov/server/#enable-open-flea-market-for-all-items","title":"Enable Open flea market for all items","text":"<p>Allows traditional flea market usage and quest progression for items that cannot be obtained otherwise.</p> <pre><code>sed -i 's/CanRequireOnRagfair\\\":\\ false/CanRequireOnRagfair\\\":\\ true/g' /opt/eft/SPT_Data/Server/database/templates/items.json\nsed -i 's/CanSellOnRagfair\\\":\\ false/CanSellOnRagfair\\\":\\ true/g' /opt/eft/SPT_Data/Server/database/templates/items.json</code></pre>"},{"location":"games/escape_from_tarkov/server/#migrate-from-sit-to-fika-optional","title":"Migrate from SIT to FIKA (optional)","text":"<ul> <li>Copy <code>/opt/eft/user/profiles</code> from SIT to FIKA (same location)</li> <li>Remove <code>password</code> line in each profile, under <code>info</code> section</li> </ul>"},{"location":"games/escape_from_tarkov/server/#create-and-start-systemd-service","title":"Create and start systemd service","text":"<p>/etc/systemd/system/eft.service</p> <p>0644 root:root</p> <pre><code>[Unit]\nDescription=Escape from Tarkov (Coop) SPT/FIKA Server.\n\n[Service]\nType=exec\nWorkingDirectory=/opt/eft\nExecStart=/opt/eft/SPT.Server.exe\nRestart=on-failure\nUser=eft\nGroup=eft\n\n[Install]\nWantedBy=default.target</code></pre> <pre><code># Enable and start FIKA server.\nsystemctl daemon-reload\nsystemctl enable eft\nsystemctl start eft</code></pre>"},{"location":"games/escape_from_tarkov/server/#upgrading","title":"Upgrading","text":"<p>Just repeat the process above to rebuild from head and update server binaries with the new versions.</p> <pre><code>systemctl stop eft\nmv /opt/eft /opt/{OLD SPT}-eft  # Backup in case of a bad upgrade.</code></pre> <p>Repeat Build Process</p> <pre><code># Migrate profiles.\ncp -av /opt/{OLD SPT}-eft/user/profiles/* /opt/eft/user/profiles/\nsystemctl start eft</code></pre>"},{"location":"games/escape_from_tarkov/server/#profile-conversions","title":"Profile Conversions","text":"<p>User profiles may need to be converted. Always double check profiles load correctly after upgrades. Some upgrades cannot convert profiles.</p>"},{"location":"games/mumble/mumble/","title":"Mumble","text":""},{"location":"games/mumble/mumble/#mumble","title":"Mumble","text":"<p>High quality VOIP server with public certificate authentication, encryption, and ACLs.</p>"},{"location":"games/mumble/mumble/#ports","title":"Ports","text":"<p>64738: UDP - Encrypted Voice Data.</p> <p>64738: UDP - Encrypted Control Data.</p> <p>/var/lib/mumble-server/mumble-server.sqlite, Server user/channel data.</p> <p>/etc/mumble-server.ini, Server configuration.</p>"},{"location":"games/mumble/mumble/#setup","title":"Setup","text":"<p>Warning</p> <p>Registration password cannot be changed.</p> <pre><code>apt install mumble-server</code></pre> <p>/etc/mumble-server.ini</p> <p>0600 mumble-server:mumble-server</p> <pre><code># Database contains all save user information.\ndatabase=/var/lib/mumble-server/mumble-server.sqlite\ndbus=system\nice=\"tcp -h 127.0.0.1 -p 6502\"\nicesecretwrite=\nautobanAttempts = 10\nautobanTimeframe = 30\nlogfile=/dev/null\npidfile=/var/run/mumble-server/mumble-server.pid\n\n# Welcome message sent to clients when they connect.\nwelcometext=\"&lt;br /&gt;&lt;br /&gt;\nWELCOME TEXT&lt;br /&gt;&lt;br /&gt;\nMORE WELCOME TEXT&lt;br /&gt;&lt;br /&gt;\n&lt;br /&gt;\"\n\n# Server accepts connections on TCP/UDP.\nport=64738\nserverpassword=\nbandwidth=1000000\nusers=100\n# Appears in public channel listing.\nregisterName={PUBLIC SERVER NAME TO REGISTER}\nregisterPassword={REGISTER PASSWORD}\n# Reference URL for server.\nregisterUrl={SERVER OR REFERENCE URL}\nbonjour=False\nuname=mumble-server\ncertrequired=True\nrememberchannel=True\nsuggestPushToTalk=True\ndefaultchannel=8\n[Ice]\nIce.Warn.UnknownProperties=1\nIce.MessageSizeMax=65536</code></pre> <p>Re-configure package and set superuser mumble password. </p><pre><code>dpkg-reconfigure mumble-server\nsystemctl start mumble-server</code></pre><p></p>"},{"location":"games/mumble/mumble/#administration","title":"Administration","text":""},{"location":"games/mumble/mumble/#adding-new-member","title":"Adding New Member","text":"<ol> <li>{USER} \u2794 RMB \u2794 Register</li> <li>User should now appear with a +: </li> <li> <p>{ROOT CHANNEL} \u2794 RMB \u2794 Edit:</p> <p></p> </li> <li> <p>Select</p> <ul> <li>1 Groups.</li> <li>2 Select group from the pulldown.</li> <li>3 Type in user name (should auto populate).</li> <li>4 Add.</li> <li>5 OK.</li> </ul> <p></p> </li> <li> <p>User should now be able to move into all properly created channels.</p> </li> </ol>"},{"location":"games/mumble/mumble/#create-new-channel","title":"Create New Channel","text":"<ol> <li> <p>{ROOT CHANNEL} \u2794 RMB \u2794 Add</p> <p></p> </li> <li> <p>Type channel name, leave everything else alone:</p> <p></p> </li> <li> <p>All permissions are inherited from the root channel, so as long as the user    is added to the group, they have access to all channels created in that    channel.</p> </li> </ol>"},{"location":"games/mumble/mumble/#reset-superuser-password","title":"Reset superuser password","text":"<pre><code>dpkg-reconfigure mumble-server</code></pre>"},{"location":"games/mumble/mumble/#references","title":"References<sup>1</sup><sup>2</sup><sup>3</sup>","text":"<ol> <li> <p>https://wiki.mumble.info/wiki/Running_Murmur#Setting_the_SuperUser_Password \u21a9</p> </li> <li> <p>https://www.typefrag.com/mumble/tutorials/advanced-user-settings/ \u21a9</p> </li> <li> <p>https://www.mumble.com/support/mumble-how-to-create-a-channel.php \u21a9</p> </li> </ol>"},{"location":"games/steam/","title":"Steam","text":""},{"location":"games/steam/#steam","title":"Steam","text":"<p>Migrated to ansible collection</p> <p>Use r_pufky.game.</p>"},{"location":"games/steam/#install-old-game-version","title":"Install Old Game Version","text":"<p>All games on steam are versioned and stored in a repository - this provides a mechanism to install an old version for a game.</p> <ol> <li>Find your game on the Steam DB.</li> <li> <p>Locate the manifests for all versions of a game by navigating to a specific     game version manifest:</p> <p>Game \u2794 APPID \u2794 Packages \u2794 SUBID \u2794 Depots \u2794 Depot ID \u2794 Manifests</p> <p>Example manifest list.</p> </li> <li> <p>Determine the MANIFESTID to use.</p> <p>Example manifest.</p> </li> <li> <p>Open the Steam console from browser:     steam://nav/console. Steam Client Boot strapper should launch.</p> </li> <li> <p>Download old version:</p> <pre><code># download_depot &lt;AppID&gt; &lt;DepotID&gt; &lt;ManifestID&gt;\ndownload_depot 239140 335819 23871677621866113</code></pre> <ul> <li>AppID is found on the main game listing.</li> <li>DepotID &amp; ManifestID found on the manifest listing.</li> <li>On completion the location of the download will be shown.</li> <li>Downloaded to Steam\\steamapps\\content\\app_{APPID}\\depot_{DEPOTID}</li> </ul> </li> <li> <p>Copy the original game files that will be overwritten to another location or    back them up.</p> </li> <li>Copy the old version files into the game directory.</li> <li>Disable the Internet connection before starting the game. Steam will    typically force-update on launch. After launching the Internet connection    can be restored.</li> </ol>"},{"location":"games/steam/#references","title":"References<sup>1</sup>","text":"<ol> <li> <p>https://steamcommunity.com/sharedfiles/filedetails/?id=889624474 \u21a9</p> </li> </ol>"},{"location":"games/steam/troubleshooting/","title":"Troubleshooting","text":""},{"location":"games/steam/troubleshooting/#troubleshooting","title":"Troubleshooting","text":""},{"location":"games/steam/troubleshooting/#failed-to-determine-free-disk-space-for-error-75","title":"Failed to determine free disk space for ... error 75","text":"<p>This happens when steamcmd cannot query the underlying data store remaining quota. Common with ZFS backed data stores. Either set an explicit quota or ignore it.</p> <pre><code>sudo zfs set quota=2T zpool1/games</code></pre>"},{"location":"games/steam/troubleshooting/#0x0-or-disk-write-errors","title":"0x0 or disk write errors","text":"<p>No permissions to write updates to the data mount.</p> <p>Explicitly set permissions for Conan Exiles files. </p><pre><code>chown -R conan:conan /data/server/ConanSandbox</code></pre><p></p>"},{"location":"games/steam/troubleshooting/#wine-taking-long-time-for-first-start","title":"Wine Taking Long Time for First Start","text":"<p>winehq may potentially take ~5 minutes on first boot to launch, due to blocking on boot events.</p> <p>0014:err:ole:get_local_server_stream Failed: 80004002 __wine_kernel_init boot event wait timed out</p> <p>This is a suspected issue with the GCC build toolchain, but has not been resolved yet. Steam role should pre-mitigate this, however, system updates could change that. Letting it run will resolve itself.</p> <pre><code>wineboot --update\nxvfb-run --autoservernum wineboot --update</code></pre>"},{"location":"glossary/","title":"Glossary","text":""},{"location":"glossary/#glossary","title":"Glossary","text":""},{"location":"glossary/#2fa","title":"2FA","text":"<p>Two Factor Authentication Combines two different factors to provide strong authentication:</p> <ol> <li>Something you know.</li> <li>Something you have.</li> <li>Something you are.</li> </ol>"},{"location":"glossary/admonitions/","title":"Admonitions","text":""},{"location":"glossary/admonitions/#admonitions","title":"Admonitions","text":"<p>Prefer open (!!!) admonitions and only collapse (???) for excessively large listings to taste.</p> <p>Use \"\" to just create a no context box highlight. Add title when needed.</p> <p>Danger</p> <p>\"Error\" logs and user alerts requiring consideration.</p> <p>Bug</p> <p>\"TODO\" and known bugs / issues.</p> <p>Warning</p> <p>Requires user consideration.</p> <p>Info</p> <p>Contextual information.</p> <p>Abstract</p> <p>Long for contextual information. Used for file listings.</p> <p>Tip</p> <p>Best practices.</p> <p>Example</p> <p>User input and UI navigation.</p>"},{"location":"glossary/gpg/","title":"GPG/Encryption","text":""},{"location":"glossary/gpg/#gpgencryption","title":"GPG/Encryption","text":""},{"location":"glossary/gpg/#signing-key","title":"Signing Key","text":"<p>Key used to cryptographically sign data. This enables others to verify that data sent by you has not been altered.</p>"},{"location":"glossary/gpg/#encryption-key","title":"Encryption Key","text":"<p>Key used to encrypt data. Data is typically signed with the Signing Key after encryption.</p>"},{"location":"glossary/gpg/#authentication-key","title":"Authentication Key","text":"<p>Key used to Authenticate to systems (e.g. SSH). This will allow other systems to load your public GPG key and enable access to systems without needing any information from you.</p>"},{"location":"glossary/mail/","title":"Mail","text":""},{"location":"glossary/mail/#mail","title":"Mail","text":""},{"location":"glossary/mail/#dkim","title":"DKIM","text":"<p>Domain Key Identified Mail: DKIM provides a method for validating a domain name identity that is associated with an email message through cryptographic authentication.</p>"},{"location":"glossary/mail/#dmarc","title":"DMARC","text":"<p>Domain-based Message Authentication, Reporting &amp; Conformance:, is an email authentication, policy, and reporting protocol.</p> <p>It builds on the widely deployed SPF and DKIM protocols, adding linkage to the author ('From:') domain name, published policies for recipient handling of authentication failures, and reporting from receivers to senders, to improve and monitor protection of the domain from fraudulent email.</p>"},{"location":"glossary/mail/#mta","title":"MTA","text":"<p>Mail Transport Agent: handles mail server to server (e.g. other domains).</p>"},{"location":"glossary/mail/#mda","title":"MDA","text":"<p>Mail Delivery Agent: handles user access to email (e.g. IMAP).</p>"},{"location":"glossary/mail/#mua","title":"MUA","text":"<p>Mail User Agent: user client to check email (e.g. thunderbird/outlook).</p>"},{"location":"glossary/mail/#spf","title":"SPF","text":"<p>Sender Policy Framework: Email authentication method designed to detect forging sender addresses during the delivery of the email.</p>"},{"location":"glossary/os/","title":"Operating Systems","text":""},{"location":"glossary/os/#operating-systems","title":"Operating Systems","text":""},{"location":"glossary/os/#ldap","title":"LDAP","text":"<p>Lightweight Directory Access Protocol. Directory service that offers dedicated data storage and APIs for accessing stored information. It functions independently of Active Directory and can function as a standalone data store or can replicate data.</p>"},{"location":"glossary/os/#irm","title":"IRM","text":"<p>Information Rights Management. Form of IT security technology used to protect documents containing sensitive information from unauthorized access. Unlike traditional Digital Rights Management (DRM) that applies to mass-produced media like songs and movies, IRM applies to documents, spreadsheets, and presentations created by individuals. IRM protects files from unauthorized copying, viewing, printing, forwarding, deleting, and editing.</p>"},{"location":"glossary/os/#windows","title":"Windows","text":""},{"location":"glossary/os/#bsod","title":"BSOD","text":"<p>Blue Screen of Death. Windows crash.</p>"},{"location":"glossary/os/#junction","title":"Junction","text":"<p>Windows version of a symlink.</p>"},{"location":"glossary/os/#ad","title":"AD","text":"<p>Active Directory. Provides centralized management of network resources, user identities, and security settings.</p>"},{"location":"glossary/os/#ad-ds","title":"AD DS","text":"<p>Active Directory Domain Services. Provides directory services for managing Windows-based computers on a network. AD DS stores information about objects such as users, groups, computers, and other resources, and provides authentication and authorization services.</p>"},{"location":"glossary/os/#dc","title":"DC","text":"<p>Domain Controller. Network server that responds to security authentication requests and authorizes host access to domain resources. This server enforces security policies, authenticates registered users, and stores important user account information. Domain controllers manage and secure domain networks by only allowing authorized users access to directory services while denying unauthorized access.</p>"},{"location":"glossary/os/#ad-lds","title":"AD LDS","text":"<p>Lightweight Directory Services. LDAP for AD.</p>"},{"location":"glossary/os/#ad-fs","title":"AD FS","text":"<p>Federation Services. Allows secure sharing of identity information between trusted business partners. It is based on industry standards and facilitates federations across extranets, enabling trusted partners to share sensitive identity data.</p>"},{"location":"glossary/os/#ad-rms","title":"AD RMS","text":"<p>Rights Management Services. Enables users and admins to control access permissions for sensitive documents, workbooks, and presentations. By utilizing IRM policies, unauthorized individuals are prevented from duplicating and disseminating the restricted information.</p>"},{"location":"glossary/os/#ad-cs","title":"AD CS:","text":"<p>Active Directory Certificate Services. Windows server designed to issue digital certificates. AD CS offers digital certificates that have a wide range of applications, including the encryption and digital signing of documents and messages, as well as authenticating computer, user, or device accounts on a network. Certificates granted are valid for a specified period and can be renewed or revoked as needed, providing granular control over the certificates' lifespan.</p>"},{"location":"glossary/os/#gpo","title":"GPO","text":"<p>Group Policy for Windows. Provides centralized management and configuration of operating systems, applications, and users' settings.</p> <p>The most restrictive GPO is applied if both machine and user GPO's are set.</p> <p>Policies can be manually applied with:</p> <pre><code>gpupdate /force</code></pre>"},{"location":"glossary/os/#registry","title":"Registry","text":"<p>Hierarchical database that stores low-level settings for Windows and applications that opt to use the registry.</p>"},{"location":"glossary/os/#wsl","title":"WSL","text":"<p>Windows Subsystem for Linux. Run linux in Windows.</p>"},{"location":"glossary/unicode/","title":"Unicode Glyphs","text":""},{"location":"glossary/unicode/#unicode-glyphs","title":"Unicode Glyphs","text":"Glyph Code Use \u2794 2794 Menus, sub-items, links. \ud83e\udc79 1F879 Up arrow. \ud83e\udc83 1F883 Down arrow. \u26a0 26a0 Warning. \u24d8 24be Informational. \ud83d\uddd8 1f5d8 Waiting / Working / Processing. \u2714 2714 Success / Enabled / On. \u2718 2718 Failure / Disabled / Off. \u22ee 22ee Additional context (or context menu). \u2699 2699 Settings. \u2318 2318 Super key. LMB LMB Left click (Left mouse button). MMB MMB Right click (Right mouse button). RMB RMB Middle click (Middle mouse button). \u270b 270B Hover the mouse over the indicated location next to this symbol."},{"location":"glossary/unicode/#alert-window-glyphs","title":"Alert Window Glyphs","text":"Glyph Code Use \u2500 2500 horizontal line. \u2502 2502 Vertical line. \u256d 256D Top left corner. \u256e 256E Top right corner. \u256f 256F Bottom right corner. \u2570 2570 Bottom left corner. \u251c 251C Bottom left message. \u253c 253C Cross Intersection. \u2534 2534 Up Intersection. \u2524 2524 Left Intersection. \u251c 251C Right Intersection. \u252c 252C Down Intersection."},{"location":"glossary/vlan/","title":"VLAN","text":""},{"location":"glossary/vlan/#vlan","title":"VLAN","text":""},{"location":"glossary/vlan/#vlan_1","title":"VLAN","text":"<p>Virtual Local Area Network.</p>"},{"location":"glossary/vlan/#pif-physical-interface","title":"PIF (Physical InterFace)","text":"<p>Defines the physical port of a piece of equipment.</p>"},{"location":"glossary/vlan/#pvid-parent-vlan-identification-pvlan-parent-vlan","title":"PVID (Parent Vlan IDentification) / PVLAN (Parent VLAN)","text":"<p>Defines the default VLAN for traffic leaving a specified interface. Also referred to as Native Network, Parent VLAN. Untagged traffic will be tagged with this ID leaving the port.</p>"},{"location":"glossary/vlan/#vif-virtual-interface","title":"VIF (Virtual InterFace)","text":"<p>Defines a virtual port of a piece of equipment; Commonly swapped with VLAN or VID.</p>"},{"location":"glossary/vlan/#pvif-parent-virtual-interface","title":"PVIF (Parent Virtual InterFace)","text":"<p>Defines a parent virtual port of a piece of equipment; Commonly swapped with PVLAN or PVID.</p>"},{"location":"glossary/vlan/#vid-vlan-identification","title":"VID (Vlan IDentification)","text":"<p>Defines a virtual port of a piece of equipment; must be associated with a PIF. Commonly used interchangeably with VLAN, VIF.</p>"},{"location":"glossary/vlan/#vlan-virtual-local-area-network","title":"VLAN (Virtual Local Area Network)","text":"<p>A virtual network, creating logical separations within a switch. This allows for multiple broadcast domains on the switch.</p> <p>VLAN Attributes:</p> <ul> <li>L2 (layer 2).</li> <li>Independent Broadcast Domain.</li> <li>Configured with 802.1Q.</li> <li>VLANIDs: 0-4095.</li> <li>VLANID: 1 is generally used as a management VLAN with no VLAN   tags.</li> </ul>"},{"location":"glossary/vlan/#vlanid-virtual-local-area-network-identification","title":"VLANID (Virtual Local Area Network IDentification)","text":"<p>Integer number between 0-4095 identifying a specific VLAN.</p>"},{"location":"glossary/vlan/#all-all-networks","title":"ALL (All Networks)","text":"<p>Concept used to denote ALL VLANS and untagged traffic. Typically used in defining Trunks. If ALL is not used, then untagged traffic must be explicitly allowed.</p>"},{"location":"glossary/vlan/#tagged","title":"Tagged","text":"<p>Network packet that has already been tagged with the 802.1Q header, identifying that packet as being on a specific VLAN.</p>"},{"location":"glossary/vlan/#untagged","title":"Untagged","text":"<p>Network packet that does not have the 802.1Q header. This is standard network traffic. Also commonly referred to as the Native VLAN.</p>"},{"location":"glossary/vlan/#management-vlan-default","title":"Management VLAN (Default)","text":"<p>VLAN used for general management and administration; not typically for everyday data traffic. In common practice, the management VLAN is usually Untagged traffic to allow for un-configured devices the ability to be connected to when added to the network. Some devices (like Ubiquiti) treat the Management VLAN, Untagged traffic, and Native VLAN as VLANID 1. May be referred to as Default network.</p>"},{"location":"glossary/vlan/#native-vlan-native-network","title":"Native VLAN (Native Network)","text":"<p>Synonym for Untagged. Standard network traffic to allow for un-configured devices the ability to be connected to when added to the network. Some devices (like Ubiquiti) treat the Management VLAN, Untagged traffic, and Native VLAN as VLANID 1.</p>"},{"location":"glossary/vlan/#trunk","title":"Trunk","text":"<p>Used for upstream or downstream links between switches and routers. Accepts and forwards traffic on multiple VLANS, usually including Untagged traffic.</p>"},{"location":"glossary/yubikey/","title":"Yubikey","text":""},{"location":"glossary/yubikey/#yubikey","title":"Yubikey","text":""},{"location":"glossary/yubikey/#yubikey-manager","title":"Yubikey Manager","text":"<p>Application that will manage Yubikey configuration. There is a GUI Yubikey Manager and a CLI Yubikey Manager.</p>"},{"location":"glossary/yubikey/#yubikey-passwordpin","title":"Yubikey Password/PIN","text":"<p>Password for user and admin accounts for a Yubikey. Can be up to 127 ASCII characters long.</p> <p>The user password is used whenever GPG material needs to be accessed on the card. Daily usage.</p> <p>The admin password is used to reset the user password and perform administrative functions on the Yubikey itself. Limited usage.</p>"},{"location":"media/folders/","title":"Folder Structures","text":""},{"location":"media/folders/#folder-structures","title":"Folder Structures","text":"<p>Organizing and structuring data storage for information retrieval.</p> <p>Based on research from Karl Voit</p>"},{"location":"media/folders/#goals","title":"Goals","text":"<ol> <li> <p>Exportable via NFS to PVE and subseqent LXC mounts.</p> </li> <li> <p>Primary mount MUST be 0755 root:root for mounting NFS</p> </li> <li>PVE - set immutable for mount point</li> <li> <p>PVE - investigate autofs? (or rename /autofs to something else)</p> </li> <li> <p>Least privilege.</p> </li> <li> <p>Separation of broad data capabilities</p> </li> <li> <p>Data: Any user-generated or consumable media (docs, files, media, mail, etc)</p> </li> <li> <p>App: Application related data - \"stateful\" configuration data that CANNOT      be re-created via roles.</p> </li> <li> <p>Naming</p> </li> <li> <p>ISO8601 YYYY-MM-DDTHH.MM.SS</p> </li> <li>hyphens only (-). Spaces allowed.</li> <li>rating: numeric, 1-5</li> </ol> <p>2025-10-11</p> <p>0755 root:root unless otherwise noted</p> <p>zfs create -o encryption=aes-256-gcm -o keyformat=passphrase -o keylocation=prompt -o pbkdf2iters=1000000 -o atime=off -o xattr=sa -o dnodesize=auto hundo/edu</p> <p>zfs set mountpoint=/myspecialfolder mypool zfs rename tank/home/maybee tank/ws/maybee</p> <p>ALL ROOT ZFS MOUNTPOINTS SET:</p> <p>0755 root:root chattr +i /d/{MOUNT}</p> <p>TODO:</p>"},{"location":"media/folders/#dart","title":"/d/art","text":"<p>All public produced artwork (no concerns about PII/SPII personal data). chmod +i /d/art/* /d/art    - all sub dirs should be mounted datasets with correct permissions. * All exported under the same NFS share with same permissisons.</p> <p>/d/art/ (all subdirectories are 0755 media:media - control with LXC mounts)   movies - produced media.   tv - produced media. 0755 media:media   music - produced media. 0755 media:media     * Original format music should be stored side-by-side and noted.   books - produced media. 0755 media:media   edu - produced educational media (courses, yt channels, videos, papers, etc not in above)       *</p>"},{"location":"media/folders/#darchive","title":"/d/archive","text":"<p>Archival data (personal data which is unlikely to change; PII/SPII). chmod +i /d/archive/* /d/archive    - all sub dirs should be mounted datasets with correct permissions.</p> <p>/d/archive - User CREATED data that is in final state (or unlikely to change).   docs - documents (scanned, legal, etc) - paperless.     * Current 950:950 (open permissions - TODO - once migration complete update and restrict permissions?)   memories/{YYYY}/ - generated pictures, videos, events.     * use flat files or dir for grouped media.     * 0755 media:media   mail - 0750 mox:mox   src - 0750 forgeo:forgeo - hosted sources   backup - 0755 root:root - mounted backup locations for services.</p> <p>/d/work/ - all temporary data (no long term storage - 'inbox 0')   * diskimages -&gt; process incoming to work and sort into directories below.      * xcp -&gt; move to PVE and parse down as needed.   * Aggressively remove files which are unknown (if cannot be determined) or move     to work for additional context and resolution.   * Should copyparty only WRITE to here?</p> <p>/d/srv/ - Application 'stateful' data (cannot be re-created via roles) chmod +i /d/srv/* /d/srv    - all sub dirs should be mounted datasets with correct permissions.</p> <p>mail - mox mail data. 0750 mox:mox (check mox permissions)   radarr - these may just be local now with postgres support.   sonarr - these may just be local now with postgres support.   lidarr - these may just be local now with postgres support.   * pve - PVE remote mount (backups, images, containers, etc).   * plex - Plex disk metadata (see if this should be local disk instead) check size on D.   * db - database backed services 0755 root:root     * 0755 by maria, postgres   * user - user configuration state (home directories, etc - MUST BE PROCESSED to archive/art/porn)     * Jaime migrated to user, confirmed ZFS snapshot backup and remove hundo/jaime.   * cache - large cached data (downloads, etc. deleting is NO LOSS - move to archive/art/etc when done).</p> <p>TODO:   * paperless - remove old directory in srv2/paperless.</p> <p>/d/porn/   memories/{NAME} - personal generated by main person (other person, self)   art - produced media (professional or third-party generated)     * XXX / NC-17 (per taste) that should not appear in PLEX.</p> <p>/d/software/   os/ - operating system images (breakout by OS if needed)   app/{NAME}/ - application packages (zip, exe, images, etc)   games/{NAME}/ - game packages (zip, exec, hacking, saves, etc)</p>"},{"location":"media/folders/#delete-datasets","title":"Delete datasets","text":"<ol> <li>Copy data to other datasets (confirm data is correct)</li> <li>Set mountpoint=none to signify data is ready to be deleted.</li> <li>Confirm NEW DATASET snapshot is successful on remote system.</li> <li>Delete old dataset (ALWAYS CONFIRM DATA IS MIGRATED BEFORE DELETING).</li> </ol> <p>Ready: * hundo/jaime * hundo/refsi</p>"},{"location":"media/music/","title":"Music Processing","text":""},{"location":"media/music/#music-processing","title":"Music Processing","text":"<p>Basic music processing rules for importing music.</p>"},{"location":"media/music/#album-artwork","title":"Album Artwork","text":"<ol> <li> <p>Find larger than 500x500 and resize to 500x500.</p> <p>Tip</p> <p>Ensure DPI &gt;= 72; 1600x1600 should be around 1.5 megs.</p> </li> <li> <p>Use Template Image if no image found, replacing text as needed.</p> </li> <li> <p>If no large image or template exists (and template doesn\u2019t make sense), take    largest small picture, and up sample it:</p> <p>Tip</p> <p>Change DPI to something large like 500.</p> </li> <li> <p>Trim / rotate picture as needed for clean edges; touch up if needed.</p> </li> <li> <p>Auto level the picture for sharper image:</p> <p>\u2318 + shift + l</p> </li> <li> <p>Save image as png, uncompressed / interweaved: band - album.png</p> </li> </ol>"},{"location":"media/music/#track-formatting","title":"Track Formatting","text":""},{"location":"media/music/#subtitles-to-albums","title":"Subtitles to albums","text":"<pre><code>[album]: [subtitle]\n[album] - [subtitle]: [subtitle]\nLive Trax Volume XX: YYYY-MM-DD [Venue] City, state</code></pre>"},{"location":"media/music/#multiple-songs-in-a-single-track","title":"Multiple songs in a single track","text":"<pre><code># No segway\n[song 1] / [song 2]\n\n# Segway\n[song 1] &gt; [song 2]</code></pre>"},{"location":"media/music/#mixes-remixes","title":"Mixes, Remixes","text":"<pre><code>[song title] ([style if applicable] Remix)</code></pre>"},{"location":"media/music/#featured-artists","title":"Featured Artists","text":"<pre><code>[song title] (Featuring [artist name 1][, artist name 2] \u2026)</code></pre>"},{"location":"media/music/#remixed-featured-in-same-song","title":"Remixed, Featured in same song","text":"<pre><code>[song title] [remix] [featured artists]</code></pre> <p>Note</p> <p>Mixes, Remixes, Featured Artists formatting is now handled in Set Featured Artist and Remixes script.</p>"},{"location":"media/music/#music-genres","title":"Music Genres","text":""},{"location":"media/music/#house","title":"House","text":"<ul> <li>Beat every 4/4.</li> <li>Distinct drum/beat every measure.</li> <li>Example: turn me on @ 1:18.</li> </ul>"},{"location":"media/music/#dubstep","title":"Dubstep","text":"<ul> <li>Heavy Bass.</li> <li>Drum Patterns.</li> <li>Clipped Samples (jarring / repeating).</li> <li>Electronic bass.</li> <li>Sample: Holy Ghost @ 1:35.</li> </ul>"},{"location":"media/music/#music-purge","title":"Music Purge","text":""},{"location":"media/music/#album-artist-a-z","title":"Album Artist (A-Z)","text":"<ul> <li>Most videos are purged unless unique (i.e. Nirvana MTV, etc); normal music   videos are almost always purged.</li> <li>Experience albums (albums that are continuous) should be marked as such in the   tags (gapless) and not have a song deleted even if it is below 4 stars.</li> <li>Music with no rating is skipped.</li> <li>Skipped: Alanis Morissette</li> <li>Stopped: Ani Defranco</li> </ul>"},{"location":"media/firefly/","title":"Firefly III","text":""},{"location":"media/firefly/#firefly-iii","title":"Firefly III","text":"<p>Self-hosted financial manager.</p> <p>Migrated to ansible collection</p> <p>Use r_pufky.srv.firefly.</p> <p>Read tutorials to configure running application.</p>"},{"location":"media/firefly/#reverse-proxy","title":"Reverse Proxy","text":"<p>Firefly should be run via a Reverse Proxy, allowing you to isolate and wrap connections in SSL. See NGINX for more details. See Base Proxy Control for basic proxy configuration.</p> <p>Set firefly_trusted_proxies to ** or specific proxy IP before enabling the reverse-proxy. firefly_app_url should remain localhost as it does not affect proxied or non-proxied connections.</p> <p>/etc/nginx/conf.d/reverse_proxy.conf</p> <p>0644 root:root</p> <pre><code># Subdomain\nserver {\n  listen                               443 ssl http2;\n  server_name                          firefly.{DOMAIN} firefly;\n\n  location / {\n    proxy_bind                         {PROXY IP ON FIREFLY NETWORK};\n    proxy_pass                         http://firefly/;\n    proxy_set_header Host              $http_host;\n    proxy_set_header X-Real-IP         $remote_addr;\n    proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;\n    proxy_set_header X-Forwarded-Proto $scheme;\n    proxy_buffering                    off;\n  }\n}</code></pre> <p>/etc/nginx/conf.d/reverse_proxy.conf</p> <p>0644 root:root</p> <pre><code># Subpath\nlocation ^~ /firefly/ {\n   deny all;\n}\n\nlocation ^~ /budget {\n   alias /var/www/html/firefly-iii/public;\n   try_files $uri $uri/ @budget;\n\n   location ~* \\.php(?:$|/) {\n      include snippets/fastcgi-php.conf;\n      fastcgi_param SCRIPT_FILENAME $request_filename;\n      fastcgi_param modHeadersAvailable true; #Avoid sending the security headers twice\n      fastcgi_pass unix:/run/php/php8.0-fpm.sock;\n   }\n}\n\nlocation @budget {\n   rewrite ^/budget/(.*)$ /budget/index.php/$1 last;\n}</code></pre>"},{"location":"media/firefly/troubleshooting/","title":"Troubleshooting","text":""},{"location":"media/firefly/troubleshooting/#troubleshooting","title":"Troubleshooting","text":""},{"location":"media/firefly/troubleshooting/#attachment-disappears","title":"Attachment Disappears","text":"<p>There is a hard 2MB limit from lavarel. This will be displayed as uploading successfully but will be silently dropped.</p>"},{"location":"media/plex/","title":"Plex","text":""},{"location":"media/plex/#plex","title":"Plex","text":"<p>Plex Media Server.</p> <p>Migrated to ansible collection</p> <p>Use r_pufky.media.plex.</p> <p>Tip</p> <ul> <li>The UID/GID should be set to a user/group that have access to your media.   All media clients should run under the same user to run correctly.</li> <li>Map your media directly to where it was before to prevent needing to   modify any libraries. This should be read-only.</li> </ul>"},{"location":"media/plex/#new-setup","title":"New Setup","text":"<p>A new plex install (or one requiring a new access token after revocation) requires the initial manual setup process to be run locally. Use a SSH tunnel to access the server-side configuration page.</p> <pre><code>ssh -L 32400:localhost:32400 {plex_host}</code></pre> <p>Then connect to http://localhost:32400/web and obtain token:</p> <ol> <li>Select media libraries to use.</li> <li>Sign-in on server: upper right \u2794 sign-in.</li> <li>Select server and claim: claim now \u2794 claim server.</li> <li>Set PlexOnlineToken.</li> </ol>"},{"location":"media/plex/#enable-secure-server-connection","title":"Enable Secure Server Connection","text":"<ol> <li>Ensure 32400 is forwarded from the router.</li> <li>Enable DNS Rebinding on router.</li> </ol>"},{"location":"media/plex/config/","title":"Configuration","text":""},{"location":"media/plex/config/#configuration","title":"Configuration","text":"<p>Plex does not consistently apply casing to XML settings and are frequently mis-spelled or inconsistently spelled. Order does not matter (Plex initially only stores non-default values until it is set once, then the setting is always stored, last changed setting last).</p> <p>Options here reflect file analysis.</p> <p>Preferences.xml</p> <p>0755 {USER}:{USER}</p> <pre><code>&lt;!-- An empty preferences file will be auto-populated on service start. --&gt;\n&lt;!-- All preferences are stored in the Preferences element. --&gt;\n&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;Preferences /&gt;</code></pre>"},{"location":"media/plex/config/#general","title":"General","text":""},{"location":"media/plex/config/#friendlyname","title":"FriendlyName","text":"<p>Server Friendly name.</p> Variable Type Default FriendlyName str ''"},{"location":"media/plex/config/#sendcrashreports","title":"sendCrashReports","text":"<p>Send crash reports to Plex?</p> Variable Type Default sendCrashReports bool false"},{"location":"media/plex/config/#pushnotificationsenabled","title":"PushNotificationsEnabled","text":"<p>Enable Push Notifications? Allow this server to send push notifications to mobile devices. Push notifications are delivered using Plex services. They're associated with your account, and some of them may contain information about the contents of your library.</p> Variable Type Default PushNotificationsEnabled bool false"},{"location":"media/plex/config/#logdebug","title":"logDebug","text":"<p>Enable Plex Media Server debug logging? Debug logging enables additional detail in the log files and is helpful in diagnosing problems.</p> Variable Type Default logDebug bool false"},{"location":"media/plex/config/#logverbose","title":"LogVerbose","text":"<p>Enable Plex Media Server verbose logging? Verbose logging is only useful to debug specific issues and should only be enabled if requested by support staff.</p> Variable Type Default LogVerbose bool false"},{"location":"media/plex/config/#butlerupdatechannel","title":"ButlerUpdateChannel","text":"<p>Server update channel. Does not circumvent entitlement (PlexPass) early previews.</p> Variable Type Default Values ButlerUpdateChannel int 0 0: Stable (public). 8: Beta."},{"location":"media/plex/config/#remote-access","title":"Remote Access","text":""},{"location":"media/plex/config/#publishserveronplexonlinekey","title":"PublishServerOnPlexOnlineKey","text":"<p>Enable Remote Access? Publishing a server on Plex Online makes it automatically available on your client devices without any configuration of your router.</p> Variable Type Default PublishServerOnPlexOnlineKey bool false"},{"location":"media/plex/config/#manualportmappingmode","title":"ManualPortMappingMode","text":"<p>Enable manual port specification? You may need to enable this to establish a direct connection from outside your network. You may also need to configure your router.</p> Variable Type Default ManualPortMappingMode bool false"},{"location":"media/plex/config/#authenticationmethod","title":"AuthenticationMethod","text":"<p>Manul Port to Use.</p> Variable Type Default AuthenticationMethod int 32400"},{"location":"media/plex/config/#authenticationrequired","title":"AuthenticationRequired","text":"<p>Internet upload speed (Kbps). Overall upload limit for all streams. WebUI uses Mbps and should be converted accordingly.</p> Variable Type Default AuthenticationRequired int 0"},{"location":"media/plex/config/#wanperstreammaxuploadrate","title":"WanPerStreamMaxUploadRate","text":"<p>Limit remote stream bitrate (Kbps). Set the maximum bitrate of a single remote stream from this server.</p> Variable Type Default WanPerStreamMaxUploadRate int 0 (Original - no limit)."},{"location":"media/plex/config/#library","title":"Library","text":""},{"location":"media/plex/config/#fseventlibraryupdatesenabled","title":"FSEventLibraryUpdatesEnabled","text":"<p>Scan my library automatically? Your library will be updated automatically when changes to library folders are detected. Uses iNotify and will not work on network mounted filesystems.</p> Variable Type Default FSEventLibraryUpdatesEnabled bool false"},{"location":"media/plex/config/#fseventlibrarypartialscanenabled","title":"FSEventLibraryPartialScanEnabled","text":"<p>Run a partial scan when changes are detected? When changes to library folders are detected, only scan the folder that changed. Uses iNotify and will not work on network mounted filesystems.</p> Variable Type Default FSEventLibraryPartialScanEnabled bool false"},{"location":"media/plex/config/#watchmusicsections","title":"watchMusicSections","text":"<p>Include music libraries in automatic updates? Linux systems limit the maximum number of watched directories; this may cause problems with large music libraries. Uses iNotify and will not work on network mounted filesystems.</p> Variable Type Default watchMusicSections bool false"},{"location":"media/plex/config/#scheduledlibraryupdatesenabled","title":"ScheduledLibraryUpdatesEnabled","text":"<p>Enable Scan my library periodically? Enable this option for network mounted filesystems.</p> Variable Type Default ScheduledLibraryUpdatesEnabled bool false"},{"location":"media/plex/config/#scheduledlibraryupdateinterval","title":"ScheduledLibraryUpdateInterval","text":"<p>Library scan interval (seconds).</p> Variable Type Default ScheduledLibraryUpdateInterval int 86400"},{"location":"media/plex/config/#autoemptytrash","title":"autoEmptyTrash","text":"<p>Empty trash automatically after every scan?</p> Variable Type Default autoEmptyTrash bool true"},{"location":"media/plex/config/#allowmediadeletion","title":"allowMediaDeletion","text":"<p>Allow media deletion? The owner of the server will be allowed to delete media files from disk.</p> Variable Type Default allowMediaDeletion bool true"},{"location":"media/plex/config/#ondeckwindow","title":"OnDeckWindow","text":"<p>Weeks to consider for Continue Watching. Media that has not been watched in this many weeks will not appear in Continue Watching.</p> Variable Type Default OnDeckWindow int 16 ### OnDeckLimit Maximum number of Continue Watching items which will appear. Limits the number of shows which will appear Continue Watching. Setting it too high can affect performance. Variable Type Default OnDeckLimit int 40"},{"location":"media/plex/config/#ondeckincludepremieres","title":"OnDeckIncludePremieres","text":"<p>Include season premieres in Continue Watching? New season premieres will always appear no matter how many weeks have passed since watching.</p> Variable Type Default OnDeckIncludePremieres bool true"},{"location":"media/plex/config/#libraryvideoplayedthreshold","title":"LibraryVideoPlayedThreshold","text":"<p>Video played threshold. Set the progress percentage for video playback at which point the video will be marked as played.</p> Variable Type Default LibraryVideoPlayedThreshold int 95"},{"location":"media/plex/config/#libraryvideoplayedatbehaviour","title":"LibraryVideoPlayedAtBehaviour","text":"<p>Video play completion behavior. Decide whether to use end credits markers to determine the played state of video items. LibraryVideoPlayedThreshold used when markers are not available.</p> Variable Type Default Values LibraryVideoPlayedAtBehaviour int 3 0: At selected threshold percentage. 1: At final credits marker position. 2: At first credits marker position. 3: Earliest between threshold percent and first credits marker (default)."},{"location":"media/plex/config/#smartshufflemusic","title":"SmartShuffleMusic","text":"<p>Enable smart shuffling on artists and smart music playlists? Smart shuffling prefers highly rated, popular and less recently heard tracks.</p> Variable Type Default SmartShuffleMusic bool true"},{"location":"media/plex/config/#musicseparatealbumtypes","title":"MusicSeparateAlbumTypes","text":"<p>Group albums by type? Group into LPs, EPs &amp; Singles, Compilations, Live Albums, Demos and Remixes.</p> Variable Type Default Values MusicSeparateAlbumTypes str enabled enabled disabled"},{"location":"media/plex/config/#itunessharingenabled","title":"iTunesSharingEnabled","text":"<p>Enable iTunes plugin (requires server restart)?</p> Variable Type Default iTunesSharingEnabled bool false"},{"location":"media/plex/config/#ituneslibraryxmlpath","title":"iTunesLibraryXmlPath","text":"<p>iTunes library XML path (absolute path)?</p> Variable Type Default iTunesLibraryXmlPath str ''"},{"location":"media/plex/config/#scannerlowpriority","title":"ScannerLowPriority","text":"<p>Run scanner tasks at a lower priority?</p> Variable Type Default ScannerLowPriority bool false"},{"location":"media/plex/config/#markersource","title":"MarkerSource","text":"<p>Marker source. Credits markers can be generated locally and/or retrieved via an online database. Online markers may not always exist, if this preference is set to any then any locally detected markers are submitted anonymously back to the online database for future use.</p> Variable Type Default Values MarkerSource str any any: Both, try online first (default). cloud: Online only (no local detection). local: Local detection only."},{"location":"media/plex/config/#generatebifbehavior","title":"GenerateBIFBehavior","text":"<p>Generate video preview thumbnails. Video preview thumbnails provide live updates in Now Playing and while seeking on supported apps. Thumbnail generation may take a long time, cause high CPU usage, and consume additional disk space. You can turn off thumbnail generation for individual libraries in the library's advanced settings.</p> Variable Type Default Values GenerateBIFBehavior str never never: never. scheduled: as a scheduled task. asap: as a scheduled task and when media is added."},{"location":"media/plex/config/#generateintromarkerbehavior","title":"GenerateIntroMarkerBehavior","text":"<p>Generate intro video markers. Detects show intros, exposing the Skip Intro button in clients.</p> Variable Type Default Values GenerateIntroMarkerBehavior str asap never: never. scheduled: as a scheduled task. asap: as a scheduled task and when media is added."},{"location":"media/plex/config/#generatecreditsmarkerbehavior","title":"GenerateCreditsMarkerBehavior","text":"<p>Generate credits video markers. Detects movie and episode end credits.</p> Variable Type Default Values GenerateCreditsMarkerBehavior str asap never: never. scheduled: as a scheduled task. asap: as a scheduled task and when media is added."},{"location":"media/plex/config/#generateadmarkerbehavior","title":"GenerateAdMarkerBehavior","text":"<p>Generate ad video markers. Detects movie and episode ads.</p> Variable Type Default Values GenerateAdMarkerBehavior str scheduled never: never. scheduled: as a scheduled task. asap: as a scheduled task and when media is added."},{"location":"media/plex/config/#generatevadbehavior","title":"GenerateVADBehavior","text":"<p>Generate voice activity data. Detects voice activity data for movies and episodes. This is used to help synchronize subtitles to the audio track. This detection can be toggled per library by editing the individual library and navigating to the advanced section.</p> Variable Type Default Values GenerateVADBehavior str scheduled never: never. scheduled: as a scheduled task. asap: as a scheduled task and when media is added."},{"location":"media/plex/config/#generatechapterthumbbehavior","title":"GenerateChapterThumbBehavior","text":"<p>Generate chapter thumbnails. Chapter thumbnails provide images in the chapter view on supported apps. They can take a long time to generate and consume additional disk space.</p> Variable Type Default Values GenerateChapterThumbBehavior str scheduled never: never. scheduled: as a scheduled task. asap: as a scheduled task and when media is added."},{"location":"media/plex/config/#loudnessanalysisbehavior","title":"LoudnessAnalysisBehavior","text":"<p>Analyze audio tracks for loudness. Loudness analysis allows various features, such as loudness leveling and smart transitions. It can take a long time to complete when analyzing many tracks, and cause high CPU usage.</p> Variable Type Default Values LoudnessAnalysisBehavior str scheduled never: never. scheduled: as a scheduled task. asap: as a scheduled task and when media is added."},{"location":"media/plex/config/#musicanalysisbehavior","title":"MusicAnalysisBehavior","text":"<p>Analyze audio tracks for sonic features. Sonic analysis allows various features, such as track radio. It can take a long time to complete when analyzing many tracks, and cause high CPU usage.</p> Variable Type Default Values MusicAnalysisBehavior str scheduled never: never. scheduled: as a scheduled task. asap: as a scheduled task and when media is added."},{"location":"media/plex/config/#locationvisibility","title":"LocationVisibility","text":"<p>Location visibility. Server owners may wish to restrict who can see location names for items which contain geolocation metadata. By default only the server owner will have visibility of these.</p> Variable Type Default Values LocationVisibility int 1 1: Admin only. 2: Everyone."},{"location":"media/plex/config/#databasecachesize","title":"DatabaseCacheSize","text":"<p>Database Cache Size (MB). Set the size of the main database cache size in MB. Increasing size increases exposure for DB data loss if a crash happens before updates are written to disk.</p> Variable Type Default DatabaseCacheSize int 40"},{"location":"media/plex/config/#network","title":"Network","text":""},{"location":"media/plex/config/#ipnetworktype","title":"IPNetworkType","text":"<p>Client network. Network to advertise to clients.</p> Variable Type Default Values IPNetworkType str dualstack v4only: Advertise only IPv4. v6only: Advertise only IPv6. dualstack: Advertise on both IPv4/6 networks."},{"location":"media/plex/config/#secureconnections","title":"secureConnections","text":"<p>Use Secure connections? When enabled, some unencrypted connections (originating from the Media Server computer) will still be allowed and apps that don't support secure connections will not be able to connect at all.</p> Variable Type Default Values secureConnections bool false True: Required. False: Preferred (default)."},{"location":"media/plex/config/#customcertificatepath","title":"customCertificatePath","text":"<p>Custom certificate location. Absolute path to a PKCS #12 file containing a certificate and private key to enable TLS support on a custom domain.</p> Variable Type Default customCertificatePath str ''"},{"location":"media/plex/config/#customcertificatekey","title":"customCertificateKey","text":"<p>Custom certificate encryption key.</p> Variable Type Default customCertificateKey str ''"},{"location":"media/plex/config/#customcertificatedomain","title":"customCertificateDomain","text":"<p>Custom certificate domain. Domain name to be published to plex.tv using your mapped port; must match a name from the custom certificate file.</p> Variable Type Default customCertificateDomain str ''"},{"location":"media/plex/config/#preferrednetworkinterface","title":"PreferredNetworkInterface","text":"<p>Preferred network interface. The network interface local clients will use to connect.</p> Variable Type Default Values PreferredNetworkInterface str '' '': Any network connection. {ADAPTER}: Use specified location interface (e.g. enp4s0, etc)."},{"location":"media/plex/config/#disabletlsv1_0","title":"DisableTLSv1_0","text":"<p>Use Strict TLS configuration? Disables legacy weak ciphers, increases DH group size, and switches to ECDSA certificates when renewing. May prevent older clients from connecting.</p> Variable Type Default DisableTLSv1_0 bool false"},{"location":"media/plex/config/#gdmenabled","title":"GdmEnabled","text":"<p>Enable local network discovery (GDM)? This enables the media server to discover other servers and players on the local network.</p> Variable Type Default GdmEnabled bool true"},{"location":"media/plex/config/#wanperuserstreamcount","title":"WanPerUserStreamCount","text":"<p>Remote streams allowed per user. Maximum number of simultaneous streams each user is allowed when not on the local network.</p> Variable Type Default Values WanPerUserStreamCount int 0 0: Unlimited connections. 1-20: Max number of connections."},{"location":"media/plex/config/#lannetworksbandwidth","title":"LanNetworksBandwidth","text":"<p>LAN networks bandwidth enforcement. Comma separated list of IP addresses or IP/netmask entries for networks that will be considered to be on the local network when enforcing bandwidth restrictions. If set, all other IP addresses will be considered to be on the external network and will be subject to external network bandwidth restrictions. If left blank, only the server's subnet is considered to be on the local network.</p> Variable Type Default Values LanNetworksBandwidth str '' {CIDR}: CIDR notation. {IP}: IPv4 or IPv6."},{"location":"media/plex/config/#minutesallowedpaused","title":"MinutesAllowedPaused","text":"<p>Terminate Sessions Paused for Longer Than X (minutes). Terminate any sessions which have been paused for longer than specified amount of time in minutes. Audio-only sessions and live sessions are excluded.</p> Variable Type Default Values MinutesAllowedPaused int 0 0: No limit."},{"location":"media/plex/config/#treatwanipaslocal","title":"TreatWanIpAsLocal","text":"<p>Treat WAN IP as LAN bandwidth? Treat incoming requests from this network's WAN IP address as LAN requests in terms of bandwidth. This often occurs when DNS rebinding protection is in place and clients on the LAN cannot contact the server directly but instead have to go through the WAN IP address.</p> Variable Type Default TreatWanIpAsLocal bool true"},{"location":"media/plex/config/#relayenabled","title":"RelayEnabled","text":"<p>Enable Relay? Relay allows connections to the server through a proxy relay when the server is not accessible otherwise. Proxy relay is bandwidth limited.</p> Variable Type Default RelayEnabled bool true"},{"location":"media/plex/config/#customconnections","title":"customConnections","text":"<p>Custom server access URLs. Comma separated list of URLs (http or https) which are published up to plex.tv for server discovery.</p> Variable Type Default customConnections str ''"},{"location":"media/plex/config/#allowednetworks","title":"allowedNetworks","text":"<p>Comma separated list of IP addresses and networks that are allowed without auth. List of IP addresses or IP/netmask entries for networks that are allowed to access Plex Media Server without logging in. When the server is signed out and this value is set, only localhost and addresses on this list will be allowed.</p> <p>Any app connecting to the server this way without being signed in will be treated as the admin/owner. That means access to all libraries as well as the ability to change server settings. We strongly encourage using Plex apps that allow signing in to accounts to ensure the highest security for your computer and network.</p> Variable Type Default Values allowedNetworks str '' {CIDR}: CIDR notation. {IP}: IPv4 or IPv6."},{"location":"media/plex/config/#webhooksenabled","title":"WebHooksEnabled","text":"<p>Use webhooks? Allow this server to send events to external services.</p> Variable Type Default WebHooksEnabled bool true"},{"location":"media/plex/config/#transcoder","title":"Transcoder","text":""},{"location":"media/plex/config/#transcoderquality","title":"TranscoderQuality","text":"<p>Transcoder quality. Quality profile used by the transcoder.</p> Variable Type Default Values TranscoderQuality int 0 0: Automatic. 1: Prefer higher speed encoding. 2: Prefer higher quality encoding. 3: Make my CPU hurt."},{"location":"media/plex/config/#transcodertempdirectory","title":"TranscoderTempDirectory","text":"<p>Transcoder temporary directory.</p> Variable Type Default TranscoderTempDirectory str /tmp"},{"location":"media/plex/config/#downloadstempdirectory","title":"DownloadsTempDirectory","text":"<p>Downloads temporary directory.</p> Variable Type Default DownloadsTempDirectory str /tmp"},{"location":"media/plex/config/#transcoderthrottlebuffer","title":"TranscoderThrottleBuffer","text":"<p>Transcoder default throttle buffer (seconds). Number of seconds to buffer before throttling the transcoder. Playback will not start (even with direct streaming) until buffer is full - if playback takes a long time to start, reduce this value.</p> Variable Type Default TranscoderThrottleBuffer int 60"},{"location":"media/plex/config/#transcoderh264backgroundpreset","title":"TranscoderH264BackgroundPreset","text":"<p>Background transcoding x264 preset. The x264 preset value used for background transcoding (Sync and Media Optimizer). Slower values will result in better video quality and smaller file sizes, but will take significantly longer to complete processing.</p> Variable Type Default Values TranscoderH264BackgroundPreset str veryfast ultrafast superfast veryfast faster fast medium slow slower veryslow"},{"location":"media/plex/config/#transcodertonemapping","title":"TranscoderToneMapping","text":"<p>Enable HDR tone mapping? Transcoded HDR content will appear highly dimmed and desaturated with this disabled. Additional driver components may be needed to support hardware transcoding with this feature enabled; see our support articles for further details.</p> <p>AMD iGPU's will pass encoding frames back and forth between iGPU and CPU drastically reducing performance. Recommend disabling for AMD iGPU.</p> Variable Type Default TranscoderToneMapping bool true"},{"location":"media/plex/config/#transcodertonemappingagorithm","title":"TranscoderToneMappingAgorithm","text":"<p>Tonemapping Algorithm. Algorithm to use when performing HDR tone mapping.</p> <p>Info</p> <p>XML var IS mis-spelled.</p> Variable Type Default Values TranscoderToneMappingAgorithm str hable linear: Stretch entire reference gamut to a linear multiple of display. gamma: Fit a logarithmic transfer between the tone curves. clip: Hard-clip any out-of-range values. Use it for perfect color accuracy for in-range values, while distorting out-of-range values. reinhard: Preserve overall image brightness with a simple curve, using nonlinear contrast, which results in flattening details and degrading color accuracy. hable: Preserve both dark and bright details better than reinhard, at the cost of slightly darkening everything. Use it when detail preservation is more important than color and brightness accuracy. mobius: Smoothly map out-of-range values, while retaining contrast and colors for in-range material as much as possible. Use it when color accuracy is more important than detail preservation."},{"location":"media/plex/config/#transcodercanonlyremuxvideo","title":"TranscoderCanOnlyRemuxVideo","text":"<p>Disable video stream transcoding? Disable transcoding of the video stream in transcoder operations. With this set, the transcoder may still transcode audio as well as remux video.</p> Variable Type Default TranscoderCanOnlyRemuxVideo bool false"},{"location":"media/plex/config/#hardwareacceleratedcodecs","title":"HardwareAcceleratedCodecs","text":"<p>Use hardware acceleration when available? Plex Media Server will attempt to use hardware-accelerated video codecs when encoding and decoding video. Hardware acceleration can make transcoding faster and allow more simultaneous video transcodes, but it can also reduce video quality and compatibility.</p> Variable Type Default HardwareAcceleratedCodecs bool true"},{"location":"media/plex/config/#hardwareacceleratedencoders","title":"HardwareAcceleratedEncoders","text":"<p>Use hardware-accelerated video encoding? If hardware acceleration is enabled, this controls whether it's used for encoding, in addition to decoding.</p> Variable Type Default HardwareAcceleratedEncoders bool true"},{"location":"media/plex/config/#transcoderhevcencoding","title":"TranscoderHEVCEncoding","text":"<p>Enable HEVC video Encoding (experimental)? Enable transcoding using the HEVC codec if it is supported by the client.</p> Variable Type Default Values TranscoderHEVCEncoding str always never: Never use HEVC video encoding. hevc-sources: Encode HEVC sources only. always: Always use HEVC video encoding."},{"location":"media/plex/config/#transcoderhevcoptimize","title":"TranscoderHEVCOptimize","text":"<p>Enable HEVC Optimization (experimental)? If available, enable use of HEVC while optimizing your media.</p> Variable Type Default TranscoderHEVCOptimize bool false"},{"location":"media/plex/config/#hardwaredevicepath","title":"HardwareDevicePath","text":"<p>Hardware transcoding device. The GPU or other hardware device that will be used for transcoding. Path is automatically generated when device is set in WebUI.</p> Variable Type Default Values HardwareDevicePath str '' '': Auto device or auto-generated Plex value (default). {PCI_ID}@{DEVICE_ID}: Hardware address '10de:1eb1:10de:12a0@0000:42:00.0'."},{"location":"media/plex/config/#transcodecountlimit","title":"TranscodeCountLimit","text":"<p>Maximum simultaneous video transcodes. Limit the number of simultaneous video transcode streams server can utilize.</p> Variable Type Default Values TranscodeCountLimit int 0 0: Unlimited connections (default). 1-20: Max number of connections."},{"location":"media/plex/config/#_cpu-transcodecountlimit","title":"_CPU-TranscodeCountLimit","text":"<p>Maximum simultaneous CPU transcodes. Limit the number of simultaneous video transcode streams your server can utilize on your CPU.</p> Variable Type Default Values _CPU-TranscodeCountLimit int 0 0: Unlimited connections. 1-20: Max number of connections."},{"location":"media/plex/config/#optimizertranscodecountlimit","title":"OptimizerTranscodeCountLimit","text":"<p>Maximum simultaneous background video transcodes. Limit the number of simultaneous video transcode your server can utilize for the optimizer and downloads.</p> Variable Type Default Values OptimizerTranscodeCountLimit int 0 0: Unlimited connections. 1-20: Max number of connections."},{"location":"media/plex/config/#dlna","title":"DLNA","text":""},{"location":"media/plex/config/#dlnaenabled","title":"DlnaEnabled","text":"<p>Enable the DLNA server? This allows the server to stream media to DLNA (Digital Living Network Alliance) devices.</p> Variable Type Default DlnaEnabled bool false"},{"location":"media/plex/config/#dlnaclientpreferences","title":"DlnaClientPreferences","text":"<p>DLNA client preferences. These should generally not be altered.</p> Variable Type Default DlnaClientPreferences str ''"},{"location":"media/plex/config/#dlnareporttimeline","title":"DlnaReportTimeline","text":"<p>DLNA server timeline reporting? Enable the DLNA server to report timelines for video play activity.</p> Variable Type Default DlnaReportTimeline bool true"},{"location":"media/plex/config/#dlnadefaultprotocolinfo","title":"DlnaDefaultProtocolInfo","text":"<p>DLNA default protocol info. Protocol info string used in GetProtocolInfo responses by the DLNA server. Comma separated list of protocols.</p> Variable Type Default DlnaDefaultProtocolInfo str http-get::video/mpeg:,http-get::video/mp4:,http-get::video/vnd.dlna.mpeg-tts:,http-get::video/avi:,http-get::video/x-matroska:,http-get::video/x-ms-wmv:,http-get::video/wtv:,http-get::audio/mpeg:,http-get::audio/mp3:,http-get::audio/mp4:,http-get::audio/x-ms-wma,http-get::audio/wav:,http-get::audio/L16:,http-get:image/jpeg:,http-get:image/png:,http-get:image/gif:,http-get:image/tiff:"},{"location":"media/plex/config/#dlnadevicediscoveryinterval","title":"DlnaDeviceDiscoveryInterval","text":"<p>DLNA media renderer discovery interval (seconds). Number of seconds between DLNA media renderer discovery requests.</p> Variable Type Default DlnaDeviceDiscoveryInterval int 60"},{"location":"media/plex/config/#dlnaannouncementleasetime","title":"DlnaAnnouncementLeaseTime","text":"<p>DLNA server announcement lease time (seconds). Duration in seconds of DLNA Server SSDP announcement lease time.</p> Variable Type Default DlnaAnnouncementLeaseTime int 1800"},{"location":"media/plex/config/#dlnadescriptionicons","title":"DlnaDescriptionIcons","text":"<p>DLNA server description icons. Icons offered by DLNA server when devices request server description. Comma separated lists separated by semicolons.</p> Variable Type Default DlnaDescriptionIcons str png,jpeg;260x260,120x120,48x48"},{"location":"media/plex/config/#scheduled-tasks","title":"Scheduled Tasks","text":""},{"location":"media/plex/config/#butlerstarthour","title":"ButlerStartHour","text":"<p>Time at which tasks start to run (24 hour clock). The time at which the server starts running background maintenance tasks.</p> Variable Type Default Values ButlerStartHour int 2 0: Midnight."},{"location":"media/plex/config/#butlerendhour","title":"ButlerEndHour","text":"<p>Time at which tasks stop running (24 hour clock). The time at which the background maintenance tasks stop running.</p> Variable Type Default Values ButlerEndHour int 5 0: Midnight."},{"location":"media/plex/config/#butlertaskbackupdatabase","title":"ButlerTaskBackupDatabase","text":"<p>Backup database every three days?</p> Variable Type Default ButlerTaskBackupDatabase bool true"},{"location":"media/plex/config/#butlerdatabasebackuppath","title":"ButlerDatabaseBackupPath","text":"<p>Backup directory.</p> Variable Type Default ButlerDatabaseBackupPath str /var/lib/plex/Plex Media Server/Plug-in Support/Databases"},{"location":"media/plex/config/#butlertaskoptimizedatabase","title":"ButlerTaskOptimizeDatabase","text":"<p>Optimize database every week?</p> Variable Type Default ButlerTaskOptimizeDatabase bool true"},{"location":"media/plex/config/#butlertaskcleanoldbundles","title":"ButlerTaskCleanOldBundles","text":"<p>Remove old bundles every week?</p> Variable Type Default ButlerTaskCleanOldBundles bool true"},{"location":"media/plex/config/#butlertaskcleanoldcachefiles","title":"ButlerTaskCleanOldCacheFiles","text":"<p>Remove old cache files every week?</p> Variable Type Default ButlerTaskCleanOldCacheFiles bool true"},{"location":"media/plex/config/#butlertaskrefreshlocalmedia","title":"ButlerTaskRefreshLocalMedia","text":"<p>Refresh local metadata every three days?</p> Variable Type Default ButlerTaskRefreshLocalMedia bool true"},{"location":"media/plex/config/#butlertaskrefreshlibraries","title":"ButlerTaskRefreshLibraries","text":"<p>Update all libraries during maintenance?</p> Variable Type Default ButlerTaskRefreshLibraries bool false"},{"location":"media/plex/config/#butlertaskupgrademediaanalysis","title":"ButlerTaskUpgradeMediaAnalysis","text":"<p>Upgrade media analysis during maintenance?</p> Variable Type Default ButlerTaskUpgradeMediaAnalysis bool true"},{"location":"media/plex/config/#butlertaskrefreshperiodicmetadata","title":"ButlerTaskRefreshPeriodicMetadata","text":"<p>Refresh library metadata periodically?</p> Variable Type Default ButlerTaskRefreshPeriodicMetadata bool true"},{"location":"media/plex/config/#butlertaskdeepmediaanalysis","title":"ButlerTaskDeepMediaAnalysis","text":"<p>Perform extensive media analysis during maintenance?</p> Variable Type Default ButlerTaskDeepMediaAnalysis bool true"},{"location":"media/plex/config/#extras","title":"Extras","text":""},{"location":"media/plex/config/#cinematrailerstype","title":"CinemaTrailersType","text":"<p>Choose Cinema Trailers from?</p> Variable Type Default Values CinemaTrailersType bool true False: All movies. True: Only unwatched movies (default)."},{"location":"media/plex/config/#cinematrailersfromlibrary","title":"CinemaTrailersFromLibrary","text":"<p>Include Cinema Trailers from movies in my library?</p> Variable Type Default CinemaTrailersFromLibrary bool true"},{"location":"media/plex/config/#cinematrailersfromtheater","title":"CinemaTrailersFromTheater","text":"<p>Include Cinema Trailers from new and upcoming movies in theaters? PlexPass entitlement only.</p> Variable Type Default CinemaTrailersFromTheater bool false"},{"location":"media/plex/config/#cinematrailersfrombluray","title":"CinemaTrailersFromBluRay","text":"<p>Include Cinema Trailers from new and upcoming movies on Blu-ray? PlexPass entitlement only.</p> Variable Type Default CinemaTrailersFromBluRay bool false"},{"location":"media/plex/config/#cinematrailersincludeenglish","title":"CinemaTrailersIncludeEnglish","text":"<p>Always include English language Cinema Trailers? For trailers of movies not in my library.</p> Variable Type Default CinemaTrailersIncludeEnglish bool true"},{"location":"media/plex/config/#cinematrailersprerollid","title":"CinemaTrailersPrerollID","text":"<p>Movie pre-roll videos. List of absolute paths to videos for pre-roll before playing a movie.</p> Variable Type Default Values CinemaTrailersPrerollID str '' Comma separated list will play all videos before movie. semi-colon separated list will play one random video before movie."},{"location":"media/plex/config/#globalmusicvideopath","title":"GlobalMusicVideoPath","text":"<p>Global music videos path.</p> Variable Type Default GlobalMusicVideoPath str ''"},{"location":"media/plex/config/#libraries","title":"Libraries","text":""},{"location":"media/plex/config/#mergedrecentlyadded","title":"MergedRecentlyAdded","text":"<p>Merge Recently Added items? Recently Added items from the same media type will be combined together on Home for libraries Recommended to Home. Only content from libraries pinned to the app sidebar will appear in Merged Recently Added recommendations.</p> Variable Type Default MergedRecentlyAdded bool false"},{"location":"media/plex/config/#live-tv-dvr","title":"Live TV &amp; DVR","text":"<p>If you have a tuner card, please help out by working with the author and providing anonymous configuration information to codify options.</p>"},{"location":"media/plex/config/#dvrincrementalepgloader","title":"DvrIncrementalEpgLoader","text":"<p>Enable incremental DVR electronic program guides loader? PlexPass entitlement only.</p> Variable Type Default DvrIncrementalEpgLoader bool false"},{"location":"media/plex/config/#identifiers","title":"Identifiers","text":"<p>Auto-generated Plex options to uniquely identifier a Plex server. Carry these settings over to new installations to retain Plex server identification.</p>"},{"location":"media/plex/config/#machineidentifier","title":"MachineIdentifier","text":"Variable Type Default MachineIdentifier str {AUTO}"},{"location":"media/plex/config/#processedmachineidentifier","title":"ProcessedMachineIdentifier","text":"Variable Type Default ProcessedMachineIdentifier str {AUTO}"},{"location":"media/plex/config/#anonymousmachineidentifier","title":"AnonymousMachineIdentifier","text":"Variable Type Default AnonymousMachineIdentifier str {AUTO}"},{"location":"media/plex/config/#stateful","title":"Stateful","text":"<p>Not user configurable.</p> <p>Configuration options here are not found directly in the server UI. These are generally updated/added automatically during Plex usage, but may be set after initial Plex execution. These are kept to document variables in case future releases migrate these to configurable values or migrated into the DB directly.</p> <p>Changing these values have no effect.</p>"},{"location":"media/plex/config/#acceptedeula","title":"AcceptedEULA","text":"<p>Accept Plex EULA? Plex cannot be used without accepting the EULA.</p> Variable Type Default AcceptedEULA bool true"},{"location":"media/plex/config/#certificateuuid","title":"CertificateUUID","text":"<p>Let's Encrypt certificate UUID. Plex automatically creates and distributes certificates to support it's own HTTPS by default scheme. These are automatically issued on first install.</p> <p>Do NOT use your own Let's Encrypt material.</p> Variable Type Default Values CertificateUUID str '' {UUIDv4}: UUIDv4a, generated random data."},{"location":"media/plex/config/#certificateversion","title":"CertificateVersion","text":"<p>Let's Encrypt certificate version.</p> Variable Type Default Values CertificateVersion str 3 1: TLSv1.1. 2: TLSv1.2. 3: TLSv1.3."},{"location":"media/plex/config/#collectusagedata","title":"collectUsageData","text":"<p>Collect usage data? Sends usage data to plex. This has been deprecated in lieu of other mechanisms now, however this is kept in case any edge cases still use this variable. This is no longer configurable in the WebUI.</p> Variable Type Default collectUsageData bool true"},{"location":"media/plex/config/#globalmusicvideopathmigrated","title":"GlobalMusicVideoPathMigrated","text":"<p>Global music video paths migrated from legacy config? Old Plex installs tracked music videos separately from other media; these are now integrated and tracked in Plex DB. This should always be true unless OldestPreviousVersion=legacy.</p> Variable Type Default Values GlobalMusicVideoPathMigrated bool true False: Force Plex to migrate music video paths on next start. True: Paths already migrated or auto-generated Plex value (default)."},{"location":"media/plex/config/#languageincloud","title":"LanguageInCloud","text":"<p>Use plex cloud settings for language options? This overrides local settings in the Language section. Now force enabled by plex.</p> Variable Type Default LanguageInCloud bool true"},{"location":"media/plex/config/#lastautomaticmappedport","title":"LastAutomaticMappedPort","text":"<p>Last port automatically mapped with PublishServerOnPlexOnlineKey.</p> Variable Type Default LastAutomaticMappedPort int 0"},{"location":"media/plex/config/#metricsepoch","title":"MetricsEpoch","text":"<p>Use year 2038+ safe epochs for timestamps? Old Plex installs used unix timestamp epochs which will generate errors after 2038. This should always be true unless plex_cfg_oldest_previous_version=legacy.</p> Variable Type Default Values MetricsEpoch int 1 1: Use 2038 safe epochs or auto-generated Plex value. 0: Use unix timestamp."},{"location":"media/plex/config/#oldestpreviousversion","title":"OldestPreviousVersion","text":"<p>Oldest previously installed plex version. Version is set on initial Plex installation.</p> Variable Type Default Values OldestPreviousVersion str '' '': auto-generated Plex value. legacy: Legacy plex install (1st gen plex &gt;10 years ago). {VERSION}: Last installed plex version (e.g. '1.28.2.6106-44a5bbd28')."},{"location":"media/plex/config/#pubsubserver","title":"PubSubServer","text":"<p>Plex pubsub server IP.</p> Variable Type Default PubSubServer str 184.105.148.115"},{"location":"media/plex/config/#pubsubserverping","title":"PubSubServerPing","text":"<p>Latest plex pubsub server ping.</p> Variable Type Default PubSubServerPing int 65"},{"location":"media/plex/config/#pubsubserverregion","title":"PubSubServerRegion","text":"<p>Plex pubsub server region.</p> Variable Type Default PubSubServerRegion str sjc"},{"location":"media/plex/config/#service","title":"Service","text":""},{"location":"media/plex/config/#plexonlineusername","title":"PlexOnlineUsername","text":"<p>Plex username.</p> Variable Type Default PlexOnlineUsername str ''"},{"location":"media/plex/config/#plexonlinemail","title":"PlexOnlineMail","text":"<p>Plex user email.</p> Variable Type Default PlexOnlineMail str ''"},{"location":"media/plex/config/#plexonlinetoken","title":"PlexOnlineToken","text":"<p>Plex user access token.</p> <p>A new plex install (or one requiring a new access token after revocation) requires the initial manual setup process to be run locally. Use a SSH tunnel to access the server-side configuration page.</p> <pre><code>ssh -L 32400:localhost:32400 {plex_host}</code></pre> <p>Then connect to http://localhost:32400/web and obtain token:</p> <ol> <li>Select media libraries to use.</li> <li>Sign-in on server: upper right \u2794 sign-in.</li> <li>Select server and claim: claim now \u2794 claim server.</li> <li>Update PlexOnlineToken with new token in found in    /var/lib/plexmediaserver/Library/Application Support/Plex Media Server/Preferences.xml.</li> </ol> <p>Enable Secure Server Connection</p> <ol> <li>Ensure 32400 is forwarded from the router.</li> <li>Enable DNS Rebinding on router.</li> </ol> Variable Type Default PlexOnlineToken str ''"},{"location":"media/plex/config/#plexonlinehome","title":"PlexOnlineHome","text":"<p>Use this server as user home (default) server?</p> Variable Type Default PlexOnlineHome bool true"},{"location":"media/plex/config/#experimental-settings","title":"Experimental Settings","text":"<p>Additional settings in Preferences.xml that are typically hidden from users.</p> <p>All options are not configured in Preferences unless explicitly set. Any option that is promoted (e.g. added to the UI) are actively migrated to standardized sections.</p> <p>Only set these options when explicitly fixing an issue.</p>"},{"location":"media/plex/config/#albumsort","title":"AlbumSort","text":"<p>Album sort. A field:direction value for the default album sort. 'year', 'title', etc. PMS 1.4.1+ has UI setting per library/per artist.</p> Variable Type Default AlbumSort str year:desc"},{"location":"media/plex/config/#articlestrings","title":"ArticleStrings","text":"<p>Article strings. A comma-separated list of words considered to be grammatical articles, which are removed in sort titles.</p> Variable Type Default ArticleStrings str the, das, der, a, an, el, la"},{"location":"media/plex/config/#backgroundtranscodelowpriority","title":"BackgroundTranscodeLowPriority","text":"<p>Background transcode low priority. Makes background transcodes have a lower priority than active streaming when enabled.</p> Variable Type Default Values BackgroundTranscodeLowPriority str 1 1: Enabled. 0: Disabled."},{"location":"media/plex/config/#dlnaplatinumlogginglevel","title":"DlnaPlatinumLoggingLevel","text":"<p>DLNA platinum logging level. Sets level for the separate 'Neptune DLNA'.</p> Variable Type Default Values DlnaPlatinumLoggingLevel str OFF OFF: Disabled. ON: Enabled."},{"location":"media/plex/config/#enablelocalsecurity","title":"enableLocalSecurity","text":"<p>Enable local security. Determines whether Plex Media Server must be claimed/signed-in to access it.</p> Variable Type Default Values enableLocalSecurity int 1 1: Enabled. 0: Disabled."},{"location":"media/plex/config/#generatebifframeinterval","title":"GenerateBIFFrameInterval","text":"<p>Generate BIF frame interval. For video preview thumbnails, sets how often (in seconds) we create the thumbnail. This directly affects library scanning performance and storage space. A more reasonable value if there are freezes during scanning is the scrub interval for the player used (10-15).</p> Variable Type Default GenerateBIFFrameInterval int 2"},{"location":"media/plex/config/#generatebifkeyframesonly","title":"GenerateBIFKeyframesOnly","text":"<p>Generate BIF keyframes only. When generating video preview thumbnails for playback, only look at keyframes in the video. Greatly speeds up processing and reduces CPU usage.</p> Variable Type Default Values GenerateBIFKeyframesOnly int 1 1: Enabled. 0: Disabled."},{"location":"media/plex/config/#localappdatapath","title":"LocalAppDataPath","text":"<p>local appdata path. Set the location of of the Plex Media Server data directory (Windows only).</p> Variable Type Default LocalAppDataPath str C:\\Users{USER}\\AppData\\Local\\Plex Media Server"},{"location":"media/plex/config/#logmemoryuse","title":"LogMemoryUse","text":"<p>Log memory use. Set Plex Media Server to log memory use and the system total used memory in Plex Media Server logs. A server restart is required for the change to take effect. Not recommended for normal usage. Requires PMS v1.20.2 or newer. Not available for FreeBSD or NVIDIA SHIELD.</p> Variable Type Default LogMemoryUse int 0: Disabled. 1: Enabled."},{"location":"media/plex/config/#lognumfiles","title":"LogNumFiles","text":"<p>Log num files. Number of past log files to retain.</p> Variable Type Default LogNumFiles int 5"},{"location":"media/plex/config/#longrunningjobthreads","title":"LongRunningJobThreads","text":"<p>Long running job threads. Sets how many threads can be used for long-running jobs, such as Sonic Analysis (Default is half the total threads for the processor).</p> Variable Type Default LongRunningJobThreads int 4"},{"location":"media/plex/config/#radiodayssincelastplayed","title":"RadioDaysSinceLastPlayed","text":"<p>Radio days since last played. When playing a Radio or Smart Shuffle, Plex prefers to include tracks that have not been played recently. This sets that recent period (default is 2).</p> Variable Type Default RadioDaysSinceLastPlayed int 2"},{"location":"media/plex/config/#radiodirectorylimit","title":"RadioDirectoryLimit","text":"<p>Radio directory limit. Controls how many genre, style, or mood radios are exposed, on clients that support those radio types.</p> Variable Type Default RadioDirectoryLimit int 50"},{"location":"media/plex/config/#transcoderdefaultduration","title":"TranscoderDefaultDuration","text":"<p>Transcoder default duration. Duration in minutes to use when transcoding something with an unknown duration (120 is the default if nothing set).</p> Variable Type Default TranscoderDefaultDuration int 120"},{"location":"media/plex/config/#transcoderh264optionsoverride","title":"TranscoderH264OptionsOverride","text":"<p>Transcoder H264 options override. The x264 preset to use when transcoding.</p> Variable Type Default TranscoderH264OptionsOverride str veryfast"},{"location":"media/plex/config/#transcoderloglevel","title":"TranscoderLogLevel","text":"<p>Transcoder log level. The log level for the Plex transcoder itself.</p> Variable Type Default Values TranscoderLogLevel str error error verbose"},{"location":"media/plex/config/#transcoderphotofilesizelimitmib","title":"TranscoderPhotoFileSizeLimitMiB","text":"<p>Transcoder photo file size limit MiB. Maximum photo size to be tagged or transcoded (in mebibytes).</p> Variable Type Default TranscoderPhotoFileSizeLimitMiB int 100"},{"location":"media/plex/troubleshooting/","title":"Troubleshooting","text":""},{"location":"media/plex/troubleshooting/#troubleshooting","title":"Troubleshooting","text":""},{"location":"media/plex/troubleshooting/#fixing-playback-issues","title":"Fixing Playback Issues","text":""},{"location":"media/plex/troubleshooting/#crash-during-library-scanning","title":"Crash During Library Scanning","text":"<p>Deep media analysis and scrubbing image generation will cause the plex service to stall and crash during library scans.</p> <ol> <li>Disable GenerateBIFBehavior. Scrubbing image    generation are generated every 2 seconds for the entire length of each    video. Not required for use.</li> <li>Increase GenerateBIFFrameInterval. If    scrubbing must be kept on set the interval to the player scrub time    (typically 10-15 seconds) which will exponentially reduce system load.</li> <li>Use scheduled intervals with notifications from download clients. Network    mounted filesystems cannot use iNotify for Plex library scans.    Enable ScheduledLibraryUpdatesEnabled,    disable FSEventLibraryUpdatesEnabled,    FSEventLibraryPartialScanEnabled.</li> </ol>"},{"location":"media/plex/troubleshooting/#playback-fails-app-crashes","title":"Playback Fails / App Crashes","text":"<p>Generally this happens when you are playing media on Plex Home Theater or Plex app, where transcoding is being used. The app will crash generally with a message:</p> <p>Conversation failed. Transcoder crashed or failed to start up</p> <p>This usually happens because the transcoder was not able to write to the transcoding directory.</p> <ol> <li>Ensure Transcoding directory is setup properly on Plex Server.</li> <li>Ensure /tmp/Transcode is owned by the right user. Changing the running    user without re-creating this directory will cause this to happen.</li> </ol>"},{"location":"media/plex/troubleshooting/#playback-transcoding-and-plex-are-slow","title":"Playback, transcoding, and Plex are Slow","text":"<p>Many Plex issues are from long-running databases that need pruning.</p> <pre><code>wget -O /tmp/DBRepair.sh https://github.com/ChuckPa/PlexDBRepair/releases/latest/download/DBRepair.sh\n\n# By default the script requires root which may interfere with squashed NFS\n# mounts. Set no root user required only if needed.\nsed -i 's/RootRequired=1/RootRequired=0/' /tmp/DBRepair.sh\n\nchmod +x /tmp/DBRepair.sh\n\n# Shutdown plex and copy database files (if needed). Always make backups.\nsystemctl stop plexmediaserver\ncp /var/lib/plexmediaserver/Library/Application\\ Support/Plex\\ Media\\ Server/Plug-in\\ Support/Databases/* /root/\n\n# Set paging size to filesystem blocksize for optimum performance.\nexport DBREPAIR_PAGESIZE=4096\n/tmp/DBRepair.sh --sqlite /usr/lib/plexmediaserver/Plex\\ SQLite --databases /root\n\n# Use automatic repair, then deflate databases\nauto  # Check, repair, optimize, set paging size, vacuum, re-index.\ndeflate  # Clean orphaned data (statistics data).\nexit</code></pre>"},{"location":"media/plex/troubleshooting/#spinning-playback-icon-no-playback","title":"Spinning playback icon, no playback","text":"<p>Generally if transcoding is setup right, then this is related to the audio transcoding failing. Turn on debug logging on the server and look for:</p> <p>EAE timeout! EAE not running, or wrong folder? Could not read</p> <p>This means you need to remap the /tmp directory to your transcoding directory, as plex updated transcoding and split out audio and video encoding into separate locations. Video transcodes in /transcode while audio transcodes in /tmp. Mapping /tmp to the transcoding directory fixes this.</p>"},{"location":"media/plex/troubleshooting/#managing-duplicates","title":"Managing Duplicates","text":""},{"location":"media/plex/troubleshooting/#duplicate-files-for-single-files","title":"Duplicate Files for Single Files","text":"<p>This happens when two refreshes for a new file happen at the same time. Generally this occurs because inotify detection is turned on in Plex, and Sonarr is set to push a manual update library command to plex on completion. Only one of these things should be enabled at once.</p> <ol> <li>Move duplicate file out of Plex library.</li> <li>Wait for episode refresh trigger / trigger manually (episode should be    removed).</li> <li>Move duplicate file into Plex library.</li> <li>Wait for episode refresh trigger / trigger manually (episode should be    removed). Dupe should be removed.</li> </ol>"},{"location":"media/plex/troubleshooting/#finding-duplicates","title":"Finding Duplicates","text":"<p>To show all detected duplicates in plex:</p> <p>Plex \u2794 TV Shows \u2794 {TV Shows Dropdown in main window} \u2794 Episodes</p> <p>Plex \u2794 TV Shows \u2794 {All in main window} \u2794 Duplicates</p> <p>From there you can Inspect all shows.</p>"},{"location":"media/plex/troubleshooting/#legacy-plex-fixes","title":"Legacy Plex Fixes","text":"<p>Fixes for early Plex servers. These generally do not appear anymore.</p>"},{"location":"media/plex/troubleshooting/#backup-state-configuration","title":"Backup State Configuration","text":"<pre><code>cd /var/lib/plexmediaserver/Library/Application\\ Support/Plex\\ Media\\ Server/Plugin\\ Support/Databases\necho \".dump metadata_item_settings\" | sudo sqlite3 com.plexapp.plugins.library.db | grep -v TABLE | grep -v INDEX &gt; viewstate-information-settings.sql\ncd /var/lib/plexmediaserver/Library/Application\\ Support/Plex\\ Media\\ Server\nsudo cp -av Media /tmp/media-backup\nsudo cp -av Metadata /tmp/metadata-backup</code></pre>"},{"location":"media/plex/troubleshooting/#restoring-plex-state-configuration","title":"Restoring Plex State Configuration","text":"<pre><code>cd /var/lib/plexmediaserver/Library/Application\\ Support/Plex\\ Media\\ Server/Plugin\\ Support/Databases\ncat viewstate-information-settings.sql | sudo sqlite3 com.plexapp.plugins.library.db\ncd /var/lib/plexmediaserver/Library/Application\\ Support/Plex\\ Media\\ Server\nsudo cp -av /tmp/media-backup Media\nsudo cp -av /tmp/metadata-backup Metadata</code></pre>"},{"location":"media/plex/troubleshooting/#plex-stuck-at-initial-startup","title":"Plex Stuck at Initial Startup","text":"<pre><code># Stop Plex and remove Service Bundle Framework.\nsudo service plexmediaserver stop\nsudo ps -ef | grep -i plex\nsudo kill -9 {REMAINING PIDS}\ncd /var/lib/plexmediaserver/Library/Application\\ Support/Plex\\ Media\\ Server/Plugins\nrm -f Service.bundle Framwork.bundle\nsudo service plexmediaserver start\nsudo reboot</code></pre>"},{"location":"networking/vlan/","title":"VLANs","text":""},{"location":"networking/vlan/#vlans","title":"VLANs","text":"<p>Basic understanding of VLANs and how they work.</p> <p>Edge OS VLAN Setup.</p>"},{"location":"networking/vlan/#vlans-are-not-subnets","title":"VLANS are Not Subnets","text":"<p>A VLAN may transmit multiple subnets of traffic as long as those packets are tagged appropriately and are physically enforced at the hardware/server level. Subnets are defined farther up in the networking stack, typically in software.</p> <p>Generally you'll see one subnet per VLAN.</p>"},{"location":"networking/vlan/#implementation-concepts","title":"Implementation Concepts","text":"<p>Fundamental concepts about VLANS need to be clarified before proceeding. VLANS allow the separation of networks on the physical switch level (L2/L3); which can be thought of as applying switch-level filters to prevent specific traffic from ever hitting network ports.</p> <p>Important things to note:</p> <ul> <li>Untagged traffic is traffic without any VLAN tags. Within   VLAN aware devices this is tagged as 1 or VLAN1. ALL also   includes this traffic.</li> <li>Ports will have a default or PVIF. This is the default VLAN traffic   will be tagged with, if no tags are present. If you connect a bunch of   computers to a switch, and plug that switch into this port, they will all   behave as though they are on the default or PVIF network.</li> <li>Ports will typically have an additional set of VLANS that are allowed.   Traffic using these VLANS needs to be pre-tagged with VLAN IDs to be allowed   through. Untagged traffic will be tagged with the default VLAN.</li> <li>Trunks aggregate traffic together, used to push traffic upstream to another   device. Trunk configurations should be the same set of VLANS on both ends in   most cases. Trunks connecting directly to the router should generally contain   all VLANS, while Trunks downstream should only specify VLANS that are   actually used or needed on those devices. It my be helpful to look at the   leaf nodes first and work your way back to prevent VLANS inadvertently being   dropped on the way to the router.</li> <li>Set a spare port on switches for Management VLAN access so you can   locally manage devices if something goes wrong.</li> <li>Design and understand your network layout and plan for how the traffic should   work on VLANS. Generally VLANs segregate traffic based on type; e.g. wifi,   iot, servers, desktops, etc.</li> </ul>"},{"location":"networking/vlan/#switch-concepts","title":"Switch Concepts","text":"<p>VLANs allow you to breakup a switch to effectively act as multiple switches by isolating the broadcast domain of traffic.</p> <p>In this example</p> <ul> <li>Port 1 will see all traffic from all VLANS.</li> <li>Ports 2 and 3 will only see traffic on VLAN 2.</li> <li>Ports 4-6 sees only VLAN 3.</li> <li>Ports 7-8 sees only VLAN4.</li> </ul> <pre><code>VLAN       A  \u2502  2   2  \u2502  3   3   3  \u2502  4   4\n        \u256d-\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n        \u2502 \u256d-\u256e \u2502 \u256d-\u256e \u256d-\u256e \u2502 \u256d-\u256e \u256d-\u256e \u256d-\u256e \u2502 \u256d-\u256e \u256d-\u256e \u2502\nPort    \u2502 \u25021\u2502 \u2502 \u25022\u2502 \u25023\u2502 \u2502 \u25024\u2502 \u25025\u2502 \u25026\u2502 \u2502 \u25027\u2502 \u25028\u2502 \u2502\n        \u2502 \u2570-\u256f \u2502 \u2570-\u256f \u2570-\u256f \u2502 \u2570-\u256f \u2570-\u256f \u2570-\u256f \u2502 \u2570-\u256f \u2570-\u256f \u2502\n        \u2570\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\nTraffic   A,2,\u2502   2     \u2502     3       \u2502    4\n          3,4 \u2502         \u2502             \u2502</code></pre> <p>The equivalent physical configuration looks something like:</p> <pre><code>Switch        2   3   4\n           \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500-\u256e\n           \u2502 \u256d\u2500\u256e \u256d\u2500\u256e \u256d\u2500\u256e \u2502\n    \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u25021\u2502 \u25022\u2502 \u25023\u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n    \u2502      \u2502 \u2570\u2500\u256f \u2570\u2500\u256f \u2570\u2500\u256f \u2502      \u2502\n    \u2502      \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u256f      \u2502\n  2 \u2502 2       3   \u25023  3       4 \u2502 4\n\u256d\u2500\u2500-\u2534\u2500\u2500\u2500\u2500\u256e \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u256d\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u256e\n\u2502\u256d\u2500\u256e \u256d\u2500\u256e \u2502 \u2502 \u256d\u2500\u256e \u256d\u2500\u256e \u256d\u2500\u256e \u2502 \u2502 \u256d\u2500\u256e \u256d\u2500\u256e \u2502\n\u2502\u25021\u2502 \u25022\u2502 \u2502 \u2502 \u25021\u2502 \u25022\u2502 \u25023\u2502 \u2502 \u2502 \u25021\u2502 \u25022\u2502 \u2502\n\u2502\u2570\u2500\u256f \u2570\u2500\u256f \u2502 \u2502 \u2570\u2500\u256f \u2570\u2500\u256f \u2570\u2500\u256f \u2502 \u2502 \u2570\u2500\u256f \u2570\u2500\u256f \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500-\u256f \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500-\u256f</code></pre>"},{"location":"networking/vlan/#basic-vlan-port-concepts","title":"Basic VLAN Port Concepts","text":"<p>Conceptualize VLANS as a way to filter traffic from either side of a port. It may also help to think of VLANs as 'cables' between switching devices.</p>"},{"location":"networking/vlan/#clarifying-terms","title":"Clarifying Terms","text":"<ul> <li>PIF will be used for all cases   of PIF, PVIF,   PVID,   Native VLAN and   Parent VLAN.</li> <li>VIF will be used for all cases   of VIF,   VID,   VLAN.</li> <li>Management VLAN is defined as   Untagged network (e.g. PIF 1, VLAN 1).</li> </ul>"},{"location":"networking/vlan/#standard-device-on-a-port","title":"Standard device on a port","text":"<p>Devices which do not support VLANs will send data Untagged onto the network. This untagged traffic will be tagged with the PIF ID exiting the port.</p>"},{"location":"networking/vlan/#egress-traffic","title":"Egress Traffic","text":""},{"location":"networking/vlan/#untagged-traffic-with-a-trunk","title":"Untagged traffic with a trunk","text":"<p>Untagged traffic from a device will be untagged exiting the port if ALL networks are allowed:</p> <pre><code> Device               Port\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u256e           \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502      \u2502 untagged  \u2502 PIF ALL \u2502 untagged\n\u2502      \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500&gt;\u2502 VIF 20  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500&gt;\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u256f           \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</code></pre>"},{"location":"networking/vlan/#tagged-untagged-traffic-with-pif","title":"Tagged untagged traffic with PIF","text":"<p>Untagged traffic from a device will be tagged with the PIF VLAN if it is explicitly defined.</p> <pre><code> Device               Port\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u256e           \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502      \u2502 untagged  \u2502 PIF 1  \u2502    1\n\u2502      \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500&gt;\u2502 VIF 20 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500&gt;\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u256f           \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</code></pre>"},{"location":"networking/vlan/#blocking-vlan-traffic-at-the-port","title":"Blocking VLAN traffic at the port","text":"<p>Tagged and Untagged traffic will be filtered at the port based on PIF and VIF:</p> <pre><code> Device               Port\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u256e           \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502      \u2502   20      \u2502  PIF 1  \u2502\n\u2502      \u2502   30      \u2502  VIF 20 \u2502   20\n\u2502      \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500&gt;\u2502         \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500&gt;\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u256f           \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</code></pre>"},{"location":"networking/vlan/#ingress-traffic","title":"Ingress Traffic","text":""},{"location":"networking/vlan/#port-allowing-untagged-traffic-in-via-all","title":"Port allowing untagged traffic in via ALL","text":"<p>Untagged traffic will be allow through the port to the device if ALL networks are allowed:</p> <pre><code> Device               Port\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u256e           \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502      \u2502  untagged \u2502 PIF ALL \u2502  untagged\n\u2502      \u2502&lt;\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 VIF 20  \u2502&lt;\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u256f           \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</code></pre>"},{"location":"networking/vlan/#pif-will-untag-traffic-sent-to-it","title":"PIF will untag traffic sent to it","text":"<p>Traffic must be tagged with the PIF VLAN for it to reach the device:</p> <pre><code> Device               Port\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u256e           \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502      \u2502  untagged \u2502 PIF 1  \u2502     1\n\u2502      \u2502&lt;\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 VIF 20 \u2502&lt;\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u256f           \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\n Device                Port\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u256e           \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502      \u2502     X     \u2502 PIF 3  \u2502  untagged\n\u2502      \u2502           \u2502 VIF 20 \u2502&lt;\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u256f           \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</code></pre>"},{"location":"networking/vlan/#filter-tagged-and-untagged-traffic","title":"Filter Tagged and Untagged Traffic","text":"<p>Tagged and Untagged traffic will be filtered at the port based on PIF and VIF.</p> <pre><code> Device                Port\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u256e           \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502      \u2502     20    \u2502 PIF 1  \u2502     20\n\u2502      \u2502&lt;\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 VIF 20 \u2502&lt;\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u256f           \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</code></pre>"},{"location":"networking/vlan/#unifi-aps","title":"UniFi APs","text":"<p>UniFi APs transmit both tagged and untagged data at the same time.</p> <ul> <li>Tagged: AP data. If configured, AP data is explicitly tagged with a   VLAN before leaving the device.</li> <li>Untagged: AP Management Interface. By default the management   interface is exposed with untagged traffic Management VLAN - VLAN1   to make adoption easier. In newer versions you can configure the management   VLAN to a custom VLAN.</li> <li>The LAN network defined in Networks on the UniFi controller describes   the properties of the Management VLAN. This is the network that   Untagged traffic will be sent on.</li> </ul>"},{"location":"networking/vlan/#reference","title":"Reference<sup>1</sup><sup>2</sup><sup>3</sup><sup>4</sup>","text":"<ol> <li> <p>https://help.ui.com/hc/en-us/articles/222183968-Intro-to-Networking-Introduction-to-Virtual-LANs-VLANs-and-Tagging#3 \u21a9</p> </li> <li> <p>https://community.ui.com/questions/62e527e3-aa03-4de9-84fc-a5e42a44cfb9 \u21a9</p> </li> <li> <p>https://help.ui.com/hc/en-us/articles/219654087 \u21a9</p> </li> <li> <p>https://community.ui.com/questions/7462245c-95a7-455e-a711-209f44e194cb \u21a9</p> </li> </ol>"},{"location":"networking/edge_os/","title":"Edge OS","text":""},{"location":"networking/edge_os/#edge-os","title":"Edge OS","text":"<p>Advanced routing, high performance, and long support lifetime Ubiquiti devices.</p>"},{"location":"networking/edge_os/#security","title":"Security","text":""},{"location":"networking/edge_os/#telemetry","title":"Telemetry","text":"<p>Options exists but are disable by default. Block or black hole trace.svc.ui.com.</p>"},{"location":"networking/edge_os/#disable-ubnt-discovery-service","title":"Disable UBNT Discovery Service","text":"<p>UBNT Discovery Service enables other UBNT devices the ability to discover this device.</p> <p>Danger</p> <p>This is exposed externally and exploitable. Disable this service.</p> <pre><code>configure\nset service ubnt-discover disable\nset service ubnt-discover-server disable\ncommit\nsave</code></pre>"},{"location":"networking/edge_os/#default-login","title":"Default Login","text":"<p>Common default username and password is ubnt.</p>"},{"location":"networking/edge_os/#cli","title":"CLI","text":""},{"location":"networking/edge_os/#create-static-dhcp-mapping","title":"Create Static DHCP Mapping","text":"<p>Maps computer to 10.0.0.2 on Test DHCP server using MAC address AA:BB:CC:11:22:33.</p> <pre><code>configure\nset service dhcp-server shared-network-name Test subnet 10.0.0.0/24 static-mapping computer ip-address 10.0.0.2\nset service dhcp-server shared-network-name Test subnet 10.0.0.0/24 static-mapping computer mac-address AA:BB:CC:11:22:33\ncommit\nsave</code></pre>"},{"location":"networking/edge_os/#create-static-host-mapping","title":"Create Static Host Mapping","text":"<p>CNAME for IP lookups without DNS - static /etc/hosts mapping.</p> <p>Simulates NAT Reflection by statically adding multiple host names to hosts file. Works with subdomains as well. This will provide an internal or custom IP for a given DNS request.</p> <p>Important</p> <p>Modifications should only be done via the GUI or CLI. Do not modify /etc/hosts manually as these are not recognized or kept by system across upgrades and restores.</p> <p>With later versions of debian based systems, entries in the local host file for the system will resolve to 127.0.1.1. This is by design.</p> <ul> <li>The alias will resolve to network IP.</li> <li>The hostname will resolve to 127.0.1.1.</li> </ul> <p>Map computer and computer.example.com to 10.0.0.2. Appear in /etc/hosts as: </p><pre><code>10.0.0.2  computer.example.com computer</code></pre><p></p>"},{"location":"networking/edge_os/#cli_1","title":"CLI","text":"<p>create_host</p> <p>0755 root:root</p> <pre><code>#!/bin/vbash\n#\n# create_host {HOST} {IP}\n#\nsource /opt/vyatta/etc/functions/script-template\n\nconfigure\nset system static-host-mapping host-name ${1}.example.com inet ${2}\nset system static-host-mapping host-name ${1}.example.com alias ${1}\ncommit\nsave\nexit</code></pre> <pre><code>configure\nset system static-host-mapping host-name computer.example.com inet 10.0.0.2\nset system static-host-mapping host-name computer.exmaple.com alias computer\ncommit\nsave</code></pre>"},{"location":"networking/edge_os/#webui","title":"WebUI","text":"<p>Config Tree \u2794 system \u2794 static-host-mapping \u2794 host-name</p> <ul> <li> <p>Add \u2794 host-name: {FQDN}</p> <p>Preview then Apply.</p> <p>When doing the initial leaf creation a failure message appears because it is not configured with an alias or network address yet. This is normal.</p> </li> <li> <p>{FQDN}:</p> <ul> <li>alias: {FQDN}</li> <li>alias: {ALIAS}</li> <li>inet: {IP}</li> </ul> <p>Preview then Apply.</p> <p>Aliases should all resolve to the same IP (base host). Verify by resolving both names on your network.</p> </li> </ul>"},{"location":"networking/edge_os/#hairpin-nat","title":"Hairpin NAT","text":"<p>Internal Only NAT Reflection. This may be used for faking subdomains, assuming there is a wildcard DNS setup on your Registrar and it resolves to your public IP.</p> <p>Info</p> <p>Split DNS is better to use than Hairpin NAT as it allows more control. This will enable you to redirect internal requests destined for your external IP to another internal destination based on selected criteria. You will need to do this for every subnet on the network.</p> <p>Firewall/NAT \u2794 Port Forwarding</p> <ul> <li>WAN Interface: {WAN}</li> <li>Hairpin NAT: \u2714 Enable hairpin NAT (also known as 'NAT loopback' or 'NAT reflection')</li> <li>LAN Interface: {ALL LAN INTERFACES}</li> </ul>"},{"location":"networking/edge_os/#restrict-subnet-traffic-to-internet-only-access","title":"Restrict Subnet Traffic to Internet Only Access","text":""},{"location":"networking/edge_os/#define-rfc1918-private-address-group","title":"Define RFC1918 Private Address Group","text":"<p>Firewall/NAT \u2794 Firewall/NAT Groups \u2794 Add Group</p> <ul> <li>Name: RFC1918</li> <li>Description: Private IPv4 address space</li> <li>Group Type: Network Group</li> </ul>"},{"location":"networking/edge_os/#define-networks-within-rfc-1918","title":"Define Networks within RFC 1918","text":"<p>Firewall/NAT \u2794 Firewall/NAT Groups \u2794 RFC1918 \u2794 Actions \u2794 Config</p> <ul> <li>Network: 192.168.0.0/16</li> <li>Network: 172.16.0.0/12</li> <li>Network: 10.0.0.0/8</li> </ul>"},{"location":"networking/edge_os/#restrict-subnet-traffic-from-reaching-internal-networks","title":"Restrict Subnet Traffic from Reaching Internal Networks","text":""},{"location":"networking/edge_os/#net_in-creation","title":"{NET}_IN Creation","text":"<p>Firewall/NAT \u2794 Firewall Policies \u2794 Add Ruleset</p> <ul> <li>Name: {NET}_IN</li> <li>Description: {NET} to LAN</li> <li>Default action: Accept</li> <li>Default Log: \u2718</li> </ul>"},{"location":"networking/edge_os/#drop-net-to-lan-basic","title":"Drop {NET} to LAN Basic","text":"<p>Firewall/NAT \u2794 Firewall Policies \u2794 {NET}_IN \u2794 Actions \u2794 Edit Ruleset \u2794 Add New Rule \u2794 Basic</p> <ul> <li>Description: Drop {NET} to LAN</li> <li>Action: Drop</li> <li>Protocol: All protocols</li> <li>Actions \u2794 Destination<ul> <li>Network Group: Private IPv4 address space</li> </ul> </li> </ul>"},{"location":"networking/edge_os/#drop-net-to-lan-interface","title":"Drop {NET} to LAN Interface","text":"<p>Firewall/NAT \u2794 Firewall Policies \u2794 {NET}_IN \u2794 Actions \u2794 Interfaces</p> <ul> <li>Interface: {NET}</li> <li>Direction: {IN}</li> </ul>"},{"location":"networking/edge_os/#only-allow-dns-traffic-to-router","title":"Only Allow DNS Traffic to Router","text":"<p>Firewall/NAT \u2794 Firewall Policies \u2794 Add Ruleset</p> <ul> <li>Name: {NET_LOCAL}</li> <li>Description: {NET} to Router</li> <li>Default action: Drop</li> <li>Default Log: \u2718</li> <li>Actions \u2794 Edit Ruleset \u2794 Add New Rule \u2794 Basic<ul> <li>Description: Allow DNS</li> <li>Action: Accept</li> <li>Protocol: Both TCP and UDP</li> </ul> </li> <li>Actions \u2794 Edit Ruleset \u2794 Drop {NET} to LAN \u2794 Actions \u2794 Destination<ul> <li>Destination: 53</li> </ul> </li> <li>Actions \u2794 Interfaces<ul> <li>Interface: {NET}</li> <li>Direction: {LOCAL}</li> </ul> </li> </ul>"},{"location":"networking/edge_os/#destination-nat-dnat-for-captive-dns","title":"Destination NAT (DNAT) for Captive DNS","text":"<p>Force all unencrypted DNS queries regardless of destination server to a specific DNS server.</p> <p>Danger</p> <p>Do not enable this for internal DNS servers!</p>"},{"location":"networking/edge_os/#add-a-destination-nat-rule","title":"Add a Destination NAT Rule","text":"<p>For each interface serving internal networks.</p> <p>Firewall/NAT \u2794 NAT \u2794 Add Destination NAT Rule</p> <ul> <li>Description:  {CAPTIVE_DNS_NAME}</li> <li>Enable: \u2714</li> <li>Inbound Interface: {INTERFACE}</li> <li>Translations Address: {DNS_IP}</li> <li>Translations Port: 53</li> <li>Exclude from NAT:\u2718</li> <li>Enable Logging: \u2718</li> <li>Protocol: Both TCP and UDP</li> <li>Source Address: {IP_NET_CIDR}</li> <li>Destination Address: !{DNS_IP}</li> <li>Destination Port: 53</li> </ul> <p>! negates matching for address.</p>"},{"location":"networking/edge_os/#add-masquerade-nat-rule","title":"Add Masquerade NAT Rule","text":"<p>For each interface serving internal networks.</p> <p>Note</p> <p>Enables appropriate transparent DNS lookups (Clients will think that they are resolving from the DNS server they made request to, not the actual DNS server responding).</p> <p>Firewall/NAT \u2794 NAT \u2794 Add Source NAT Rule</p> <ul> <li>Description: {CAPTIVE_DNS_NAME}</li> <li>Enable: \u2714</li> <li>Outbound Interface: {INTERFACE}</li> <li>Translation: Use Masquerade</li> <li>Exclude from NAT: \u2718</li> <li>Enable Logging: \u2718</li> <li>Protocol: Both TCP and UDP</li> <li>Source Address: {IP_NET_CIDR}</li> <li>Destination Address: {DNS_IP}</li> <li>Destination Port: 53</li> </ul>"},{"location":"networking/edge_os/#captive-dns-exceptions","title":"Captive DNS Exceptions","text":"<p>Allow for specific client exceptions to DNAT rules.</p> <p>Create a Source Address Group to manage all clients for the exception</p> <p>Firewall/NAT \u2794 Firewall/NAT Groups \u2794 Add Group</p> <ul> <li>Name: {DNAT_EXCEPTION_NAME}</li> <li>Description: Disable DNAT / Captive DNS for exceptions</li> <li>Group Type: Address Group</li> <li>Actions \u2794 Edit<ul> <li>Address: {IP}</li> </ul> </li> </ul> <p>Add additional Destination NAT Rule for each interface on internal networks</p> <p>Firewall/NAT \u2794 NAT \u2794 Add Destination NAT Rule</p> <ul> <li>Description: {CAPTIVE_DNS_EXCEPTIONS}</li> <li>Enable: \u2714</li> <li>Inbound Interface: {INTERFACE}</li> <li>Translations Address: {DNS_IP}</li> <li>Translations Port: 53</li> <li>Exclude from NAT: \u2718</li> <li>Enable Logging: \u2718</li> <li>Protocol: Both TCP and UDP</li> <li>Source Address: {DNAT_EXCEPTION_NAME}</li> <li>Destination Port: 53</li> </ul> <p>Set rule above the captive DNS rule for the specific network for the exception to apply. IP is router.</p>"},{"location":"networking/edge_os/#custom-ssl-certificate-for-webui","title":"Custom SSL Certificate for WebUI","text":"<p>Use custom SSL certificates to serve HTTPS router traffic. Turn on SSH.</p> <p>Combine private key and certificate into one file and copy to EdgeOS. </p><pre><code>cat privkey.pem cert.pem\u2794server.pem\n\n# Backup existing cert and restart webface (EdgeOS CLI).\ncp /etc/lighttpd/server.pem /etc/lighttpd/server.pem.Backup\nmv /tmp/server.pem /etc/lighttpd/server.pem\nkill -SIGINT $(cat /var/run/lighttpd.pid)\n/usr/sbin/lighttpd -f /etc/lighttpd/lighttpd.conf</code></pre><p></p>"},{"location":"networking/edge_os/#export-config-cli","title":"Export Config (CLI)","text":"<p>Export the list of CLI commands to manually re-create the current configuration of the router.</p> <pre><code>show configuration commands\n\n# Dump router configuration as JSON file.\nshow configuration all</code></pre>"},{"location":"networking/edge_os/#vlan-setup","title":"VLAN Setup","text":"<p>See VLANs for concepts.</p> <p>Tip</p> <p>Set an spare port on your router with a static management address without VLANS or use a console cable.</p>"},{"location":"networking/edge_os/#add-vlan","title":"Add VLAN","text":"<p>Dashboard \u2794 Add Interface \u2794 Add VLAN</p> <ul> <li>VLANID: {ID}</li> <li>Interface: {BASE INTERFACE}</li> <li>Description: {DESCRIPTION}</li> <li>Address: Static</li> <li>Address: {CIDR}</li> </ul>"},{"location":"networking/edge_os/#define-management-network-on-base-interface","title":"Define Management Network on Base Interface","text":"<p>Dashboard \u2794 {BASE INTERFACE} \u2794 Actions \u2794 Config</p> <ul> <li>Address: Static</li> <li>Address: 10.1.1.1/24</li> </ul> <p>Management VLAN is not explicitly defined as a VLAN - untagged traffic coming into an interface IS management traffic.</p>"},{"location":"networking/edge_os/#add-dhcp-server","title":"Add DHCP Server","text":"<p>Services \u2794 DHCP Server \u2794 Add DHCP Server</p> <ul> <li>DHCP Name: {NAME}</li> <li>Subnet: {CIDR}</li> <li>Range Start: {START}</li> <li>Range End: {END}</li> <li>Router: {ROUTER_IP}</li> <li>UniFi Network IP: {UNIFI_CONTROLLER_IP}</li> <li>DNS 1: {DNS_IP}</li> <li>Domain: {DOMAIN}</li> <li>Domain: Enable</li> </ul>"},{"location":"networking/edge_os/#add-dns","title":"Add DNS","text":"<p>Services \u2794 DNS \u2794 Interface \u2794 Add Listen Interface</p> <p>Add for all networks and VLANS. VLANS will appear as eth0.{VLAN_ID}.</p>"},{"location":"networking/edge_os/#reference","title":"Reference<sup>1</sup><sup>2</sup><sup>3</sup>","text":"<ol> <li> <p>https://community.ui.com/questions/ab712740-d579-4c89-824a-cda582a6bdd4 \u21a9</p> </li> <li> <p>https://help.ui.com/hc/en-us/articles/218889067-EdgeMAX-How-to-Protect-a-Guest-Network-on-EdgeRouter \u21a9</p> </li> <li> <p>https://help.ui.com/hc/en-us/articles/204959444-EdgeRouter-Router-on-a-Stick \u21a9</p> </li> </ol>"},{"location":"networking/edge_os/troubleshooting/","title":"Troubleshooting","text":""},{"location":"networking/edge_os/troubleshooting/#troubleshooting","title":"Troubleshooting","text":""},{"location":"networking/edge_os/troubleshooting/#deleted-dhcp-host-still-resolves-in-dns","title":"Deleted DHCP Host Still Resolves in DNS","text":"<p>When deleting a DHCP host, the DNS reservation should be removed as well. However there is a bug in which these hosts are never deleted.</p> <p>Delete hosts in /etc/hosts which are no longer used and reboot the router.</p>"},{"location":"networking/edge_os/troubleshooting/#dns-hostnames-not-resolving","title":"DNS Hostnames not Resolving","text":"<p>DHCP server on the edgerouter needs to update the hosts file when new IP's are issued.</p> <p>Enable Dynamic DNS Updates</p> <p>Config Tree \u2794 Service \u2794 dhcp-server \u2794 dynamic-dns-update</p> <ul> <li>Enable: \u2714</li> </ul>"},{"location":"networking/unifi/","title":"UniFi","text":""},{"location":"networking/unifi/#unifi","title":"UniFi","text":""},{"location":"networking/unifi/#security","title":"Security","text":""},{"location":"networking/unifi/#telemetry","title":"Telemetry","text":"<p>Options exists but are disable by default. Block or black hole: trace.svc.ui.com.</p>"},{"location":"networking/unifi/#default-login","title":"Default Login","text":"Username Password ubnt ubnt root ubnt root ui"},{"location":"networking/unifi/#best-practices","title":"Best Practices","text":"<ul> <li>Always enable Layer 2 discovery (\u2699 \u2794 System \u2794 Network Discovery: \u2714) on   controller. L2 device discovery will help to adopt controllers which are not   receiving a UniFi controller DHCP option.</li> <li>Set a spare port on switches for Management VLAN or ALL access so   you can locally manage devices if something goes wrong.</li> <li>Always factory-reset equipment before configuring. This guarantees fresh   state.</li> <li>Always physically label your switch ports so you can easily remember them   when you come back in a year.</li> <li>Switches/APs/Routers should always have   static IP information set, so they are   at a known address if they ever get mis-configured. Plan and document static   IPs for these devices before implementation.</li> </ul>"},{"location":"networking/unifi/#configure-controller","title":"Configure Controller","text":""},{"location":"networking/unifi/#define-vlan-networks","title":"Define VLAN Networks","text":"<p>These should match VLAN networks defined at the router.</p> <p>\u2699 \u2794 Networks \u2794 Net Virtual Network</p> <ul> <li>Name: {NAME}</li> <li>Router: Third Party Router</li> <li>VLAN ID: {ID}</li> </ul>"},{"location":"networking/unifi/#define-port-profiles","title":"Define Port Profiles","text":"<p>Port profiles apply consistent settings across multiple ports. Highly recommend defining trunking profiles and port profiles which are easy to understand:</p> <p>\u2699 \u2794 Overview \u2794 Ethernet Port Profiles \u2794 Create New</p> <ul> <li>trunk-all-default:<ul> <li>Native: Default</li> <li>Tagged VLAN Management: Allow All</li> <li>PoE: Auto</li> </ul> </li> <li>trunk-wifi:<ul> <li>Native: Default</li> <li>Tagged VLAN Management: Custom</li> <li>Tagged VLANs: iot(3), wifi(4)</li> <li>PoE: Auto</li> </ul> </li> <li>trunk-iot:<ul> <li>Native: Default</li> <li>Tagged VLAN Management: Custom</li> <li>Tagged VLANs: iot(3)</li> <li>PoE: Auto</li> </ul> </li> <li>port-wired:<ul> <li>Native: wired(2)</li> <li>Tagged VLAN Management: Block All</li> </ul> </li> <li>port-wifi:<ul> <li>Native: wifi(4)</li> <li>Tagged VLAN Management: Block All</li> </ul> </li> <li>port-iot:<ul> <li>Native: iot(3)</li> <li>Tagged VLAN Management: Block All</li> </ul> </li> </ul>"},{"location":"networking/unifi/#set-static-ip-on-management-vlan","title":"Set Static IP on Management VLAN","text":"<p>All managed devices should be set with a static IP on the Management VLAN to ensure they are at known locations in case the controller fails.</p> <p>Devices \u2794 Switch \u2794 Properties \u2794 Config \u2794 Network</p> <ul> <li>Network Override: \u2714<ul> <li>Virtual Network: Default</li> </ul> </li> <li>Configure IP: Static<ul> <li>IP Address: {VLAN1_IP}</li> <li>Preferred DNS: {DNS}</li> <li>Subnet Mask: {VLAN1_SUBNET}</li> <li>Gateway: {ROUTER_IP}</li> <li>DNS Suffix: {DOMAIN}</li> </ul> </li> </ul>"},{"location":"networking/unifi/#migrating-controllers","title":"Migrating Controllers","text":"<p>The easiest migration path is to replace the controller with the same IP. This requires no additional setup other than replacing the controller.</p>"},{"location":"networking/unifi/#new-controller-ip","title":"New Controller IP","text":""},{"location":"networking/unifi/#update-inform-ip-and-backup-existing-controller","title":"Update Inform IP and Backup Existing Controller","text":"<p>Devices \u2794 Device Updates and Settings \u2794 Device Settings</p> <ul> <li>Inform Host Override: \u2714<ul> <li>Controller Hostname/IP: {NEW_IP}</li> </ul> </li> </ul> <p>Update for all devices. These devices may appear to disconnect from the controller - this is expected.</p> <p>\u2699 \u2794 System \u2794 Backups \u2794 Download</p> <ul> <li>Download Current Backup: Settings Only</li> </ul> <p>At least settings need to be downloaded. Shutdown original Controller.</p>"},{"location":"networking/unifi/#update-dhcp-inform-addresses","title":"Update DHCP Inform Addresses.","text":""},{"location":"networking/unifi/#start-new-controller","title":"Start New Controller","text":"<p>\u2699 \u2794 System \u2794 Backups \u2794 Restore</p> <p>Update controller IP after restoring from settings.</p>"},{"location":"networking/unifi/#manually-update-devices","title":"Manually Update Devices","text":"<p>Some devices may not pickup the new inform IP of the new controller. These may be manually set if SSH is enabled; otherwise factory reset them and re-adopt - current settings are stored in the backup.</p> <p>Manually Update Controller Inform IP on Device </p><pre><code>ssh root@{DEVICE}  # Use SSH account that is setup in controller.\n\ninfo\n\n# Device should appear within a minute.\nset-inform http://{IP}:8080/inform</code></pre><p></p>"},{"location":"networking/unifi/#reference","title":"Reference<sup>1</sup><sup>2</sup><sup>3</sup><sup>4</sup><sup>5</sup><sup>6</sup><sup>7</sup><sup>8</sup><sup>9</sup>","text":"<ol> <li> <p>https://dl.ubnt.com/guides/UniFi/UniFi_Controller_V5_UG.pdf \u21a9</p> </li> <li> <p>https://www.youtube.com/watch?v=b2w1Ywt081o \u21a9</p> </li> <li> <p>https://www.youtube.com/watch?v=HcfIpTso_Ys \u21a9</p> </li> <li> <p>https://www.youtube.com/watch?v=SKeFqFhBwJY&amp;t= \u21a9</p> </li> <li> <p>https://www.youtube.com/watch?v=L9gZQh1rAMc \u21a9</p> </li> <li> <p>https://www.handymanhowto.com/ubiquiti-edgerouter-lite-soho-network-design/ \u21a9</p> </li> <li> <p>https://arstechnica.com/information-technology/2018/07/enterprise-wi-fi-at-home-part-two-reflecting-on-almost-three-years-with-pro-gear/5/ \u21a9</p> </li> <li> <p>https://help.ui.com/hc/en-us/articles/204962144#1 \u21a9</p> </li> <li> <p>https://help.ui.com/hc/en-us/articles/219654087-UniFi-Using-VLANs-with-UniFi-Wireless-Routing-Switching-Hardware \u21a9</p> </li> </ol>"},{"location":"networking/unifi/troubleshooting/","title":"Troubleshooting","text":""},{"location":"networking/unifi/troubleshooting/#troubleshooting","title":"Troubleshooting","text":""},{"location":"networking/unifi/troubleshooting/#slow-adoption","title":"Slow Adoption","text":"<p>Device adopted multiple times as it is configured by the UniFi Controller.</p> <p>Wait 3-5 minutes or 2-3 cycles.</p> <p>Adoption takes a few minutes and may look like it is failing. Generally this will be 3-5 minutes with typically 2 power cycles for it to finish.</p>"},{"location":"networking/unifi/troubleshooting/#adoption-failure","title":"Adoption Failure","text":"<p>Controller is directly connected device but consistently fails adoption.</p> <p>Restart the controller.</p>"},{"location":"networking/unifi/troubleshooting/#consistently-failing-repeated-adoptions","title":"Consistently Failing Repeated Adoptions","text":"<p>Adoption device must be connected to Management VLAN for adoption.</p> <ul> <li>Ensure controller is on port that allows same VLAN traffic as the set in the   hardware.</li> <li>Restart switch if port profiles were changed.</li> <li>Ensure controller is listening on the correct IP.</li> <li>Ensure the hardware is set to inform to the correct controller IP.</li> <li>Alternatively directly connect the UniFi controller to switch with the device   connected to it.</li> </ul>"},{"location":"networking/unifi/troubleshooting/#cannot-set-port-name","title":"Cannot Set Port Name","text":"<p>Port names cannot be the same name as the profile name being used.</p>"},{"location":"networking/unifi/troubleshooting/#cpu-load-is-extremely-high-on-unifi-switch","title":"CPU Load is Extremely High on UniFi Switch","text":"<p>UniFi Switches run a realtime OS, and you will see consistent CPU utilization regardless of switch load. This is an artifact of how load is measured.</p> <p>Nothing is wrong.</p>"},{"location":"networking/unifi/troubleshooting/#dhcp-not-working","title":"DHCP Not Working","text":"<p>Typically a MAC address caching issue, or Trunking ports are swapped/wrong.</p>"},{"location":"networking/unifi/troubleshooting/#caching-issue","title":"Caching Issue","text":"<p>Caused by swapping networks with the same device too quickly or caches not being expired when new VLANs are setup.</p> <ol> <li>Physically disconnect device from network wait a few seconds and re-connect.</li> <li>Restart DHCP services on the router.</li> </ol>"},{"location":"networking/unifi/troubleshooting/#trunking-ports-swappedwrong","title":"Trunking ports Swapped/Wrong","text":"<p>Trunk VLANs do not match on Upstream or Downstream ports. If DHCP was confirmed working before final placement, it is probably a swapped connection.</p> <p>Verify the device downstream is the correct device using the same trunk port profile.</p>"},{"location":"os/kindle/","title":"Kindle","text":""},{"location":"os/kindle/#kindle","title":"Kindle","text":"<p>Find compatible models.</p> <p>Danger</p> <p>Delete any stray .bin or update.bin.tmp.partial that appear on the root of the Kindle during the process. These are kindle updates downloading.</p> <p>Danger</p> <p>Kindle must have less than 90MB (ideally around 50MB) free to prevent updates.</p> <p>Connect the Kindle to the computer and use Kindle Filler Disk to fill up the Kindle. Nested directories are fine and these can be removed after patching.</p>"},{"location":"os/kindle/#adbreak","title":"Adbreak","text":"<p>Uses CVE-2012-3748 to jailbreak recent Kindle updates.</p> <ol> <li>Download Adblock.</li> <li> <p>Enable Advertisements (Temporarily)</p> <p>amazon.com \u2794 Account \u270b \u2794 Devices \u2794 Preferences \u2794 Country/Region Settings</p> <ul> <li>Set: US</li> <li>Email: {VALID_EMAIL}</li> <li>Phone: {VALID_PHONE}</li> <li>Address: {VALID_ADDRESS}</li> </ul> <p>amazon.com \u2794 Account \u2794 Payments \u2794 Settings \u2794 Your Purchase Preferences</p> <p>Set default credit card and billing address matching region above.</p> <p>amazon.com \u2794 Account \u270b \u2794 Kindle \u2794 Details \u2794 Special Offers: \u2714</p> <p>Leave kindle on and connected to the internet. Restarting may help to pull advertisements. They will show up on the lock screen.</p> </li> <li> <p>Enable airplane mode.</p> </li> <li> <p>Verify ads are listed:</p> <p>Kindle \u2794 \u22ee \u2794 View All Ads</p> </li> <li> <p>Connect Kindle and copy .assets to local computer.</p> </li> <li> <p>Extract Ablock into .assets folder.</p> </li> <li> <p>Execute Adblock</p> LinuxWindows <pre><code>Run find . -name 'details.html' -exec cp adbreak.html {} \\;</code></pre> <pre><code>replace.bat</code></pre> </li> <li> <p>Copy modified .assets to Kindle and overwrite.</p> </li> <li> <p>Disconnect Kindle and view an ad:</p> <p>Kindle \u2794 \u22ee \u2794 View All Ads \u2794 Any Ad</p> <p>A terminal should appear while executing jailbreak. Application errors are OK.</p> <p>There will be multiple windows that open - ignore them.</p> <p>Bang!</p> <p>This message will appear when the jailbreak succeeds.</p> <ol> <li>Enable airplane mode.</li> </ol> </li> </ol>"},{"location":"os/kindle/#hotfix","title":"Hotfix","text":"<ol> <li>Enable airplane mode.</li> <li>Download hotfix.</li> <li>Connect kindle and extract Update_hotfix_universal.bin to the root of    the Kindle.</li> <li> <p>Unplug Kindle and Update</p> <p>Kindle \u2794 \u22ee \u2794 Update your Kindle</p> <p>Airplane mode must be on.</p> </li> <li> <p>Hotfix will install a 'book' labeled Run Hotfix. Open (execute) it.</p> <p>Warning</p> <p>This must be run after every Kindle update to ensure jailbreak persistence.</p> </li> </ol>"},{"location":"os/kindle/#install-kual-and-mrpi","title":"Install KUAL and MRPI","text":"<p>Kindle Unified Application Launcher (KUAL) and MobileRead Package Installer (MRPI) are used to run homebrew on Kindle.</p> <p>Download KUAL.</p> <p>Download MRPI.</p> <ol> <li>Connect Kindle.</li> <li>Extract MRPI and copy mrpackages and extensions to the root of the    Kindle.</li> <li> <p>Extract KUAL and rename</p> <p>Warning</p> <p>Rename to Update_KUALBooklet_HDRepack_install.bin</p> <p>Install appears to work but does not succeed without renaming the file.</p> </li> <li> <p>Copy renamed KUAL package to Kindle/mrpackages/</p> </li> <li>Unplug Kindle.</li> <li> <p>Execute MRPI</p> <p>Kindle \u2794 Search \u2794 ;log mrpi</p> <p>Enter ';log mrpi' in the search bar to execute command injection and launch MRPI setup. There will be multiple windows that open - ignore them.</p> <p>'Success. :)' will appear when complete.</p> <p>KUAL should appear as a book on your Kindle once rebooted.</p> </li> </ol>"},{"location":"os/kindle/#disable-ota-updates","title":"Disable OTA Updates","text":"<p>Install mod that disables updates.</p> <p>Download renametobin</p> <ol> <li>Connect Kindle.</li> <li>Create Kindle/update.bin.tmp.partial folder.</li> <li>Extract and copy renametobin folder to Kindle/extensions.</li> <li>Unplug Kindle.</li> <li> <p>Extract RenameToBin</p> <p>Kindle \u2794 KUAL \u2794 Rename OTA Binaries \u2794 Rename</p> <p>Kindle will automatically reboot.</p> <p>Selecting 'Restore' will re-enable OTA updates.</p> </li> </ol>"},{"location":"os/kindle/#koreader","title":"KOReader","text":"<p>Opensource ebook reader that supports a massive amount of formats.</p> <p>Download koreader-kindlehf-*.zip.</p> <ol> <li>Connect Kindle.</li> <li>Extract and copy extensions and koreader to root of Kindle. Merge or    replace any files.</li> <li>Unplug Kindle.</li> <li> <p>Launch KOReader</p> <p>Kindle \u2794 KUAL \u2794 KOReader</p> </li> </ol> <p>Tip</p> <p>See https://koreader.rocks/user_guide for a helpful user guide.</p>"},{"location":"os/kindle/#kindleforge","title":"KindleForge","text":"<p>Opensource Kindle App Store. Allows for easy installation of packages without manually connecting to a computer each time.</p> <p>Download KindleForge.</p> <ol> <li>Connect Kindle.</li> <li>Extract KindleForge and .sh script to Kindle/documents.</li> <li>Unplug Kindle.</li> </ol>"},{"location":"os/kindle/#disable-ads","title":"Disable Ads","text":"<p>Remove Ads and tracking information after jailbreak.</p> <p>amazon.com \u2794 Account \u270b \u2794 Kindle \u2794 Details \u2794 Special Offers: \u2718</p>"},{"location":"os/kindle/#reference","title":"Reference<sup>1</sup><sup>2</sup><sup>3</sup><sup>4</sup><sup>5</sup><sup>6</sup>","text":"<ol> <li> <p>https://kindlemodding.org/jailbreaking \u21a9</p> </li> <li> <p>https://github.com/koreader/koreader \u21a9</p> </li> <li> <p>https://github.com/iiroak/Kindle-Filler-Disk \u21a9</p> </li> <li> <p>https://www.mobileread.com/forums/showthread.php?t=225030 \u21a9</p> </li> <li> <p>https://scriptlets.notmarek.com/ \u21a9</p> </li> <li> <p>https://open-slum.org \u21a9</p> </li> </ol>"},{"location":"os/pikvm/","title":"PiKVM","text":""},{"location":"os/pikvm/#pikvm","title":"PiKVM","text":"<p>Raspberry Pi KVM with multi-port extenders based on Arch linux.</p>"},{"location":"os/pikvm/#setup","title":"Setup","text":"<p>Tip</p> <p>All commands are executed from an SSH session or launching Terminal after WebUI login.</p> <p>The filesystem must be set using rw before executing writes and using ro or rebooting after changes are made.</p>"},{"location":"os/pikvm/#set-root-passwords","title":"Set Root Passwords","text":"<p>Danger</p> <p>The root user and the WebUI use different passwords. Change both.</p> <p>root: root/root. WebUI: admin/admin.</p> <pre><code># Terminal at WebUI login or SSH.\nsu -\npasswd root  # Update root user password.\nkvmd-htpasswd set admin  # Update WebUI admin password.</code></pre>"},{"location":"os/pikvm/#enable-certificate-authentication","title":"Enable Certificate Authentication","text":"<p>See SSHD.</p> <pre><code>cp {SSH KEYS} /root/.ssh/authorized_keys</code></pre> <p>/etc/ssh/sshd_config</p> <p>0644 root:root </p><pre><code>PasswordAuthentication no</code></pre><p></p> <pre><code>systemctl restart ssh</code></pre>"},{"location":"os/pikvm/#update","title":"Update","text":"<pre><code>pikvm-update</code></pre>"},{"location":"os/pikvm/#enable-two-factor-authentication-2fa","title":"Enable Two-Factor Authentication (2FA)","text":"<pre><code>kvmd-totp init</code></pre>"},{"location":"os/pikvm/#disable-web-terminal","title":"Disable Web Terminal","text":"<pre><code># Be sure SSH connections work.\nsystemctl disable --now kvmd-webterm</code></pre>"},{"location":"os/pikvm/#disable-switch-lights","title":"Disable Switch Lights","text":"<p>Switch \u2794 Color scheme</p> <p>Drag all sliders to the left.</p>"},{"location":"os/pikvm/#reference","title":"Reference<sup>1</sup>","text":"<ol> <li> <p>https://docs.pikvm.org/v4 \u21a9</p> </li> </ol>"},{"location":"os/shield/","title":"Shield TV","text":""},{"location":"os/shield/#shield-tv","title":"Shield TV","text":""},{"location":"os/shield/#fix-black-screen-launcher-crashes","title":"Fix Black Screen &amp; Launcher Crashes","text":"<p>The default launcher crashes, black screens consistently, and injects Ads to the home screen. Use an alternative launcher to resolve these issues.</p>"},{"location":"os/shield/#install-projectivity-launcher","title":"Install Projectivity Launcher","text":"<p>If you like this launcher please support the author.</p> <p>Projectivity \u2794 Accessibility \u2794 Settings \u2794 Override Launcher: \u2714</p> <p>Change category orders by moving all the way left in the desired row and using \ud83e\udc79 \ud83e\udc83 arrows.</p>"},{"location":"os/shield/#enable-developer-mode","title":"Enable Developer Mode","text":"<p>\u2699 \u2794 Device Preferences \u2794 About \u2794 Build</p> <p>Click 7 times to enable developer mode.</p> <p>\u2699 \u2794 Developer Options \u2794 Remote Debugging: \u2714</p> <p>This may also be called 'wireless debugging'.</p>"},{"location":"os/shield/#disable-built-in-launcher","title":"Disable Built-in Launcher","text":"<pre><code># Alternatively configure package from reference.\npamac install android-tools\n\nadb connect {SHIELD_IP}  # Accept connection on shield.\n\n# Disable launcher.\nadb shell pm disable-user --user 0 com.google.android.tvlauncher\n\n# Re-enable launcher.\n# adb shell pm enable com.google.android.tvlauncher</code></pre> <p>\u2699 \u2794 Developer Options \u2794 Remote Debugging: \u2718</p> <p>This may also be called 'wireless debugging'.</p>"},{"location":"os/shield/#disable-google-voice-button","title":"Disable Google Voice Button","text":"<p>\u2699 \u2794 Settings \u2794 Apps \u2794 App Permissions \u2794 Microphone \u2794 Show System Apps</p> <ul> <li>Google: Don't Allow</li> </ul> <p>Press the Voice Assistant button and Deny, Never ask again when prompted. Remap</p> <p>Button may be remapped to other functions with Button Mapper.</p>"},{"location":"os/shield/#reference","title":"Reference<sup>1</sup><sup>2</sup>","text":"<ol> <li> <p>https://www.reddit.com/r/ShieldAndroidTV/comments/ssbtmi/a_short_guide_on_how_to_get_rid_of_ads_while \u21a9</p> </li> <li> <p>https://www.nvidia.com/en-us/geforce/forums/legacy-products/12/173396/rooting-your-shield-the-why-and-how \u21a9</p> </li> </ol>"},{"location":"os/web_os/","title":"WebOS","text":""},{"location":"os/web_os/#webos","title":"WebOS","text":"<p>Smart TV Asshattery.</p> <p>Danger</p> <p>Always hard block WebOS with firewall rules and Destination NAT.</p> <p>Track MAC addresses and block on all network devices even if not configured for use (e.g. Wifi and Ethernet).</p> <p>TV will upload viewing habits and display Ads regardless of settings.</p> <p>Tip</p> <p>TV's are displays and should be dumb. Use another device that is upgradable and not motivated to harvest user data for playing media.</p>"},{"location":"os/web_os/#disable-always-on-voice-recording","title":"Disable Always On Voice Recording","text":"<p>Warning</p> <p>Internet is required to disable 'Always Ready'. Disable immediately after setting this option to prevent Updates.</p> <p>\u2699 \u2794 AI Settings</p> <ul> <li>Voice: Disable ALL voice settings</li> <li>Always Ready: \u2718</li> </ul> <p>\u2699 \u2794 General \u2794 Terms \u2794 User Agreements</p> <p>Disable all.</p> <p>Warning</p> <p>Disable Internet connection.</p> <p>\u2699 \u2794 General \u2794 Terms \u2794 User Agreements</p> <p>Disable all. Option sometimes re-enables during network state changes.</p>"},{"location":"os/debian/","title":"Debian","text":""},{"location":"os/debian/#debian","title":"Debian","text":"<p>Migrated to ansible collection</p> <p>Use r_pufky.deb.</p>"},{"location":"os/debian/#install-tcp-bbr-kernel-patches","title":"Install TCP BBR Kernel Patches","text":"<p>TCP BBR is a new congestion controlling algorithm that is designed to respond to actual congestion instead of packet loss. This results in a dramatic increase in transfer speeds. This applies to any Linux distribution running Kernel 4.9+ with BBR patches.</p> <pre><code># Check TCP BBR supported.\nuname -r\n\n# Both parameters should be returned.\negrep 'CONFIG_TCP_CONG_BBR|CONFIG_NET_SCH_FQ' /boot/config-$(uname -r)</code></pre>"},{"location":"os/debian/#enable-bbr-support","title":"Enable BBR Support","text":"<p>/etc/sysctl.d/10_custom_kernel_bbr.conf</p> <p>0644 root:root</p> <pre><code>net.core.default_qdisc=fq\nnet.ipv4.tcp_congestion_control=bbr</code></pre> <pre><code>sysctl -p  # Or reboot.</code></pre>"},{"location":"os/debian/#disable-ipv6","title":"Disable IPv6","text":"<p>Disable if IPv6 is not being actively used to prevent any IPv6 misconfiguration attacks.</p> <p>/etc/sysctl.d/10_disable_ipv6.conf</p> <p>0644 root:root</p> <pre><code>net.ipv6.conf.all.disable_ipv6=1\nnet.ipv6.conf.default.disable_ipv6=1\nnet.ipv6.conf.lo.disable_ipv6=1</code></pre> <pre><code>sysctl -p  # Or reboot.</code></pre>"},{"location":"os/debian/#operations","title":"Operations","text":""},{"location":"os/debian/#make-raw-disk-image-of-physical-disk","title":"Make RAW Disk Image of Physical Disk","text":"<p>DD can be used to make a RAW image of a disk, and can be mounted in other linux systems for use.</p> <pre><code># Copy disk block device to a file.\ndd if=/dev/{BLOCK} of=/some/filesystem/{IMAGE}.raw bs=1M conv=noerror,sync status=progress\n\n# Mount RAW disk image for use.\nlosetup -f -P /some/filesystem/{IMAGE}.raw\nlosetup -l\nmount /dev/loop0p1 /mnt/test/\numount /dev/loop0p1\nlosetup -d /dev/loop0</code></pre>"},{"location":"os/debian/#apt-auto-selection","title":"Apt Auto Selection","text":"<p>Automatically select user-required options during package install.</p> <p>This is used for configuration management and preseeding for automatic installs that require user input.</p>"},{"location":"os/debian/#get-debconf-options","title":"Get debconf Options","text":"<p>Determine debconf options used by installing the package with the options set.</p> <pre><code>apt install debconf-utils\napt install {PACKAGE}\ndebconf-get-selections | grep {PACKAGE}</code></pre>"},{"location":"os/debian/#set-debconf-options","title":"Set debconf Options","text":"<p>On target machines, set options before installing the package. This will remove the prompts from apt.</p> <p>Tip</p> <p>debconf will list with tabs for easy reading. When setting selections separate with a space, otherwise the extra whitespace will be included with the option.</p> <pre><code>echo \"{PACKAGE}-{VERSION} package/option {NAME} {VALUE}\" | debconf-set-selections\napt install {PACKAGE}</code></pre>"},{"location":"os/debian/#example","title":"Example","text":"<pre><code>apt install mysql-server debconf-utils\ndebconf-get-selections | grep mysql-server\n&gt; mysql-server-5.5        mysql-server/root_password_again        password\n&gt; mysql-server-5.5        mysql-server/root_password      password\n&gt; mysql-server-5.5        mysql-server/error_setting_password     error\n&gt; mysql-server-5.5        mysql-server-5.5/postrm_remove_databases        boolean false\n&gt; mysql-server-5.5        mysql-server-5.5/start_on_boot  boolean true\n&gt; mysql-server-5.5        mysql-server-5.5/nis_warning    note\n&gt; mysql-server-5.5        mysql-server-5.5/really_downgrade       boolean false\n&gt; mysql-server-5.5        mysql-server/password_mismatch  error\n&gt; mysql-server-5.5        mysql-server/no_upgrade_when_using_ndb  error\n\necho \"mysql-server-5.5        mysql-server-5.5/start_on_boot  boolean true\"  | debconf-set-selections\napt install mysql-server-5.5</code></pre>"},{"location":"os/debian/troubleshooting/","title":"Troubleshooting","text":""},{"location":"os/debian/troubleshooting/#troubleshooting","title":"Troubleshooting","text":""},{"location":"os/debian/troubleshooting/#grub-cryptfs-password-typo","title":"GRUB CryptFS Password Typo","text":"<p>Unlocked CryptFS on GRUB boot will stall if mistyping the password. Restart the unlock and boot process without restarting:</p> <pre><code>cryptomount -a\ninsmod normal\nnormal</code></pre>"},{"location":"os/debian/troubleshooting/#remote-dropbearwireguardcryptfs-rescue-from-bad-upgrade","title":"Remote Dropbear/Wireguard/CryptFS Rescue from Bad Upgrade","text":"<p>System does not boot after a dist-upgrade but Dropbear connects over wireguard.</p>"},{"location":"os/debian/troubleshooting/#connect-via-dropbear-and-manually-mount-drive","title":"Connect via Dropbear and Manually Mount Drive","text":"<pre><code># Remote unlock as normal.\nssh -i ~/.ssh/dropbear root@172.31.255.11\n\n# Open LUKS encrypted disk.\ncryptsetup luksOpen /dev/nvme0n1p3 luks\n\n# Find mapped device.\nls /dev/mapper\n&gt; /dev/mapper/b--vg-root ../dm-1\n\n# Mount drive for changes.\nmkdir /mnt\nmount -t ext4 /dev/dm-1 /mnt\n\n# Make changes also chroot if needed.</code></pre>"},{"location":"os/debian/troubleshooting/#umount-and-reboot","title":"Umount and reboot","text":"<pre><code>umount /mnt\nrmdir /mnt\ncryptsetup luksClose /dev/mapper/b--vg-root\ncryptsetup luksClose /dev/mapper/b--vg-swap-1\ncryptsetup luksClose /dev/mapper/luks\n\nreboot -f</code></pre>"},{"location":"os/debian/troubleshooting/#grub-os-prober","title":"Grub OS Prober","text":"<p>Grub will throw the following error on 4.9+ Kernels running VM's on block devices or ZFS during normal upgrades:</p> <p>device-mapper reload ioctl on osprober-linux</p> <p>These devices are attempted to be unmounted while in use to detect other OS's on those partitions. This may be safely disabled if you are only running one OS.</p> <p>/etc/default/grub</p> <p>0644 root:root</p> <pre><code>GRUB_DISABLE_OS_PROBER=true</code></pre> <pre><code>update-grub\napt update &amp;&amp; apt upgrade\nreboot</code></pre>"},{"location":"os/debian/troubleshooting/#reducing-disk-writes","title":"Reducing Disk Writes","text":"<p>Minimize disk writes to SSD devices to increase longevity.</p> <ul> <li>Debian SSD optimization guide.</li> <li>deferring disk writes.</li> <li>minimizing server disk writes.</li> <li>SD card optimizations.</li> </ul>"},{"location":"os/firmware/","title":"Firmware","text":""},{"location":"os/firmware/#firmware","title":"Firmware","text":""},{"location":"os/firmware/#disable-amt","title":"Disable AMT","text":"<p>Intel Active Management Technology runs a separate linux instance on the management engine. It has active real-world exploits.</p> <ul> <li>Press F10 to get to AMT screen.</li> <li>Default password admin.</li> <li>New password constraints:<ul> <li>Minimum 8 characters</li> <li>One uppercase character</li> <li>One lowercase character</li> <li>One number (0-9)</li> <li>One symbol (!@#$% ... etc)</li> </ul> </li> <li>Disable.</li> </ul>"},{"location":"os/manjaro/","title":"Manjaro","text":""},{"location":"os/manjaro/#manjaro","title":"Manjaro","text":"<p>Manjaro KDE.</p> <p>Disable Secure Boot</p> <p>Secure boot requires manual configuration and is not recommended.</p>"},{"location":"os/manjaro/#install","title":"Install","text":"<p>Use USB Boot Disk.</p> <ol> <li>Boot with Proprietary drivers.</li> <li>Click on Install Manjaro Linux on Desktop.<ul> <li>Language: American English.</li> <li>Region: America.</li> <li>Zone: Los Angeles.</li> <li>Keyboard: English (US) / Default.</li> <li>Disk: Erase Disk / No Swap / EXT4.</li> <li>Encryption: \u2714</li> <li>User:</li> <li>Login: Username.</li> <li>Computer: Hostname.</li> <li>Log in automatically without asking for password: \u2718</li> <li>Use the same password for the administrator account: \u2718</li> <li>Administrator account: leave password empty (disables logins).</li> <li>Office Suite: None / LibreOffice.</li> </ul> </li> <li> <p>Select Wayland at bottom left of login screen.</p> <p>Avoid X11</p> <p>Modern linux distributions have great support for Wayland applications and allow for better gaming experiences given the change in MVC model from network server to local machine.</p> <p>This can always be switched at the login screen.</p> </li> <li> <p>Manjaro users default to ZSH shell. Set desired shell.</p> <pre><code>chsh {USER} -s /bin/bash</code></pre> </li> <li> <p>Disable root logins</p> <pre><code>passwd --lock root</code></pre> </li> <li> <p>Secure SSH.</p> </li> </ol>"},{"location":"os/manjaro/#configure-updates","title":"Configure Updates","text":"<p>Note</p> <p>Prefer pamac when executing commands excluding update configuration.</p> <p>pacman is the Arch package manager and pamac is the Manjaro package manager using pacman libraries.</p> <pre><code># Top 20 fastest servers.\npacman-mirrors --fasttrack 10 &amp;&amp; pacman -Syyu\n\n# Or update based on Country.\npacman-mirrors --country United_States &amp;&amp; pacman -Syyu</code></pre> <p>\u2318 \u2794 add/remove software \u2794 \u22ee \u2794 preferences</p> <ul> <li>General:<ul> <li>Check for updates: \u2714</li> <li>Update check frequency: every day</li> <li>Automatically download updates: \u2714</li> <li>Hide tray icon when no updates: \u2714</li> <li>Use mirrors from: United_States</li> </ul> </li> <li>Advanced:<ul> <li>Check available disk space: \u2714</li> <li>Remove un-required dependencies: \u2714</li> </ul> </li> <li>Third Party:<ul> <li>Enable AUR support: \u2714</li> <li>Keep built packages: \u2714</li> <li>Check for updates: \u2714</li> <li>Check for development package updates: \u2714</li> </ul> </li> </ul>"},{"location":"os/manjaro/#optional-packages","title":"Optional Packages","text":"<pre><code>pamac install iptable-nft  # More performant IPTable drop-in.\n\n# Steam client\npamac install steam  # Do not install steam-native-runtime unless issues.\n\n# Remove Manjaro branding / default homepage for browsers.\npacman -R manjaro-browser-settings</code></pre>"},{"location":"os/manjaro/#windows-dual-boot","title":"Windows Dual-boot","text":"<p>Dual booting requires Windows 10 to use UTC instead of RTC.</p> <p>Set RTC (realtime clock) to UTC and use NTP with timezone. </p><pre><code>timedatectl set-local-rtc 0\nsudo ln -sf /usr/share/zoneinfo/America/Los_Angeles /etc/localtime\nsystemctl enable --now systemd-timesyncd</code></pre><p></p> <p>\u2318 \u2794 manjaro settings manager \u2794 Time and Date</p> <ul> <li>Set time and date automatically: \u2714</li> <li>Hardware clock in local time: \u2718</li> </ul>"},{"location":"os/manjaro/preferences/","title":"Preferences","text":""},{"location":"os/manjaro/preferences/#preferences","title":"Preferences","text":"<p>These are personal configuration preferences.</p>"},{"location":"os/manjaro/preferences/#install-arc-and-papirus-themes","title":"Install Arc and Papirus themes","text":"<pre><code># Choose arc-icon-theme for recommended features.\npamac install papirus-icon-theme arc-gtk-theme\nwget -qO- https://raw.githubusercontent.com/PapirusDevelopmentTeam/arc-kde/master/install.sh | env uninstall=true sh\nwget -qO- https://raw.githubusercontent.com/PapirusDevelopmentTeam/arc-kde/master/install.sh | sh\nsudo find /usr/share/{plasma,aurorae,color-schemes,konsole,konversation,Kvantum,plasma,wallpapers,yakuake} -type d -exec chmod o+rx {} \\;\nsudo find /usr/share/{plasma,aurorae,color-schemes,konsole,konversation,Kvantum,plasma,wallpapers,yakuake} -type f -exec chmod o+r {} \\;</code></pre> <p>Note</p> <p>Login required. KDE will not display themes correctly until logging off and logging back in.</p>"},{"location":"os/manjaro/preferences/#system-settings","title":"System Settings","text":""},{"location":"os/manjaro/preferences/#global-theme","title":"Global Theme","text":"\u2318 \u2794 System Settings \u2794 Appearance &amp; Style <ul> <li> <p>Colors &amp; Themes:</p> <ul> <li>Global Theme:<ul> <li>Colors:  Arc Dark</li> <li>Night Light: Always off</li> <li>Application Style: Breeze<ul> <li>GNOME/GTK Application Style: Breeze</li> </ul> </li> <li>Plasma Style: Arc Dark</li> <li>Window Decorations: Arc Dark<ul> <li>Titlebar Buttons (from left to right)<ul> <li>Keep above other windows: Leftmost</li> <li>Keep below other windows: Left</li> <li>Context help: Right</li> <li>Shade: Right</li> <li>Minimize: Right</li> <li>Maximize: Right</li> <li>Close: Rightmost</li> </ul> </li> </ul> </li> <li>Icons: Papirus-Dark</li> <li>Cursors: Breeze<ul> <li>Configure Launch Feedback<ul> <li>Cursor feedback: None</li> <li>Task Manager feedback: \u2714</li> <li>Stop animations after: 5 seconds</li> </ul> </li> </ul> </li> <li>System Sound: Ocean<ul> <li>Enable Notification Sounds: \u2718</li> </ul> </li> <li>Splash Screen: Manjaro Splash 2.0  (Use Get New ...)</li> <li>Login Screen: Breath</li> <li>Boot Splash Screen: manjaro-mac-style  (Use Get New ...)</li> </ul> </li> <li>Login Screen (SDDM)<ul> <li>Breath: \u2714</li> <li> <p>Background: /usr/share/wallpapers/SafeLanding/contents/images/*.jpg</p> <p>Note</p> <p>Apply plasma settings after setting background and any other theme UI settings. This will apply the current UI settings (arc dark) to the Breeze login screen; this should match the lockscreen.</p> </li> </ul> </li> </ul> </li> <li> <p>Text &amp; Fonts:</p> <ul> <li>Anti-Aliasing: \u2714</li> </ul> </li> </ul> \u2318 \u2794 System Settings \u2794 Workspace <ul> <li>General Behavior:<ul> <li>Display informational tooltips on mouse hover: \u2714</li> <li>Display visual feedback for status changes: \u2714</li> <li>Scrolling: Prefer smooth scrolling</li> <li>Clicking files or folders: Selects them</li> <li>Clicking in scrollbar track: Scrolls to the clicked location</li> <li>Middle-click: Pastes selected text</li> <li>Touch Mode: Automatically enable as needed</li> </ul> </li> <li>File Search:<ul> <li>File Indexing: \u2718</li> </ul> </li> <li>Plasma Search:<ul> <li>All: \u2718</li> <li>Applications: \u2714</li> <li>System Settings: \u2714</li> <li>Calculator: \u2714</li> <li>Date and Time: \u2714</li> <li>Dictionary: \u2714</li> <li>Help Runner: \u2714</li> <li>Special Characters: \u2714</li> <li>Spell Checker: \u2714</li> <li>Terminate Applications: \u2714</li> <li>Unit Converter: \u2714</li> </ul> </li> </ul> \u2318 \u2794 System Settings \u2794 Apps &amp; Windows <ul> <li>Default Applications:<ul> <li>Web browser: Firefox</li> <li>Email client: Firefox</li> <li>Image viewer: Gwenview</li> <li>Music player: Elisa</li> <li>Video player: VLX media player</li> <li>Text editor: VSCodium</li> <li>PDF Viewer: Okular</li> <li>File manager: Dolphin</li> <li>Terminal Emulator: alacritty</li> <li>Archive manager: Ark</li> </ul> </li> <li>Window Management:<ul> <li>Window Behavior:<ul> <li>Focus:<ul> <li>Window activation policy: Focus follows mouse</li> <li>Delay focus by: 300ms</li> <li>Focus stealing prevention: None</li> <li>Raising window: Click raises active window</li> <li>Multiscreen behavior: Separate screen focus</li> </ul> </li> <li>Titlebar Actions:<ul> <li>Double-click: Maximize</li> <li>Mouse wheel: Change opacity</li> <li>Maximize window by double clicking its frame: \u2714</li> <li>Maximize button action (left click): Maximize</li> <li>Maximize button action (Middle click): Vertically Maximize</li> <li>Maximize button action (Right click): Horizontally Maximize</li> </ul> </li> <li>Advanced:<ul> <li>Window placement: Centered</li> </ul> </li> </ul> </li> <li>Task Switcher<ul> <li>Show selected window: \u2714</li> <li>Compact: \u2714</li> </ul> </li> <li>Desktop Effects:<ul> <li>Accessibility:<ul> <li>All: \u2718</li> <li>Zoom: \u2714</li> </ul> </li> <li>Appearance:<ul> <li>All: \u2718</li> <li>Blur: \u2714</li> <li>Desaturate Unresponsive Applications: \u2714</li> <li>Fading Popups: \u2714</li> <li>Full Screen: \u2714</li> <li>Highlight Screen Edges and hot Corners: \u2714</li> <li>Login: \u2714</li> <li>Logout: \u2714</li> <li>Maximize: \u2714</li> <li>Sliding Popups: \u2714</li> </ul> </li> <li>Focus:<ul> <li>All: \u2718</li> <li>Dialog Parent: \u2714</li> <li>Dim Screen for Administrator Mode: \u2714</li> </ul> </li> <li>Peek at Desktop Animation:  Window Aperture</li> <li>Tools:<ul> <li>All: \u2718</li> </ul> </li> <li>Virtual Desktop Switching Animation: Slide</li> <li>Window Management: Overview</li> <li>Window Open/Close Animation: Fade</li> </ul> </li> <li>Virtual Desktops:<ul> <li>Delete all extra desktops.</li> </ul> </li> </ul> </li> <li>Notifications:<ul> <li>Do Not Distrub Mode: \u2714 **when screens are mirrored **</li> <li>Do Not Distrub Mode: \u2714 During screen sharing</li> <li>Critical Notifications: \u2714 Show in Do Not Disturb mode</li> <li>Normal Notifications: \u2718</li> <li>Low priority notifications: \u2714 Show popup</li> <li>Low priority notifications: \u2718 Show in history</li> <li>Location: \u2714 Near notification icon</li> <li>Hide: 5 seconds</li> <li>Application progress: \u2714 show in notifications</li> <li>Application progress: \u2714 Keep popup open during progress</li> <li>Application progress: \u2714 Show in task manager</li> <li>System Notifications:<ul> <li>All: \u2718</li> <li>Notification: \u2714 show a message in a pop-up</li> </ul> </li> <li>Application Notifications:<ul> <li>All: \u2718 (Re-enable to taste)</li> </ul> </li> </ul> </li> </ul> \u2318 \u2794 System Settings \u2794 Input &amp; Output <ul> <li>Mouse &amp; Touchpad \u2794 Screen Edges<ul> <li>Upper left: Lock Screen</li> <li>Upper Right: Present Windows - All Desktops</li> <li>Trigger quarter tiling in: outer 25%</li> <li>Switch on desktop edge: Disabled</li> <li>Activation delay: 75ms</li> <li>Reactivation delay: 350ms</li> <li>Corner Barrier: \u2714</li> <li>Edge Barrier: None</li> </ul> </li> <li>Keyboard \u2794 Shortcuts<ul> <li>KWin:<ul> <li>Make window fullscreen: alt+return</li> <li>Maximize Window: Meta_PgUp</li> <li>Minimize Window: Meta_PgDown</li> </ul> </li> <li>Krunner:<ul> <li>Launch: Alt+Space, Search, Alt+F2</li> </ul> </li> <li>plasmashell:<ul> <li>Activate Application Launcher Widget: Meta+Space</li> </ul> </li> </ul> </li> <li>Accessibility:<ul> <li>System Bell:<ul> <li>Audible Bell: \u2718</li> <li>Visual Bell: \u2718</li> </ul> </li> <li>Keyboard filters:<ul> <li>Slow keys: \u2718</li> <li>Bounce keys: \u2718</li> </ul> </li> </ul> </li> </ul> \u2318 \u2794 System Settings \u2794 Security &amp; Privacy <ul> <li>Screen Locking:<ul> <li>Lock screen automatically: 5 minutes</li> <li>Lock after waking from sleep: \u2714</li> <li>Delay before password required: Require password immediately</li> <li>Keyboard shortcut: Meta+L</li> </ul> </li> <li>KDE Wallet:<ul> <li>Enable the KDE Wallet Subsystem: \u2714</li> <li>Use KDE Wallet for the Secret Service interface: \u2714</li> </ul> </li> <li>Recent Files:<ul> <li>Keep history: For 1 month</li> <li>Remember opened documents: Only for specific applications</li> <li>Exclude applications not on the list: \u2714</li> </ul> </li> <li>User Feedback: Disabled</li> </ul> \u2318 \u2794 System Settings \u2794 System \u2794 Autostart <ul> <li>Delete all.</li> </ul>"},{"location":"os/manjaro/preferences/#taskbar","title":"Taskbar","text":"Clock \u2794 MMB \u2794 Configure Digital Clock <ul> <li>Show date: \u2714 Awlays below</li> <li>Show seconds: Only in tooltip</li> <li>Show time zone: Only when different from local time zone</li> <li>Display timezone as: *Code</li> <li>Time display: 24 hour</li> <li>Date format: ISO date</li> <li>Text display: Automatic</li> </ul> System Tray \u2794 MMB \u2794 Configure System Tray <ul> <li>General:<ul> <li>Scale with Panel height: \u2714</li> </ul> </li> <li>Entries:<ul> <li>Always show all entries: \u2714</li> <li>All: Disabled</li> <li>Audio Volume: Shown when relevant</li> <li>Bluetooth: Shown when relevant</li> <li>Disks &amp; Devices: Shown when relevant</li> <li>Notifications: Enable for file copy progress to be shown</li> </ul> </li> </ul> Taskbar \u2794 MMB \u2794 Show Panel Configuration <ul> <li>Style: Disable floating</li> </ul> Remove Unused Tray Apps <ul> <li>Show desktop</li> <li>News<ul> <li>Autostart: \u2718</li> <li>Error notifications: \u2718</li> </ul> </li> <li>Key lock status</li> <li>Manjaro settings manager<ul> <li>Check unsupported kernels: \u2718</li> <li>Check missing language packs: \u2718</li> <li>Manually quit.</li> </ul> </li> </ul>"},{"location":"os/manjaro/preferences/#applications","title":"Applications","text":"<p>\u2318 \u2794 add/remove software \u2794 \u22ee \u2794 preferences \u2794 third party</p> <ul> <li>Enable AUR support: \u2714</li> <li>Check for updates: \u2714</li> <li>Check for development packages updates: \u2714</li> </ul> <pre><code>pamac install alacritty git git-lfs vim tmux meld steam\n#  extra/bind\npamac install signal-desktop discord</code></pre> <p>Remove extra software to taste </p><pre><code>pamac remove skanlit  # Flatbed scanning.\npamac remove hplip  # HP printer libraries.\npamac remove k3b  # CD burner.\npamac remove qbittorrent  # Torrents.\npamac thunderbird thunderbird-i18n-en-us  # Thick email client.\npamac remove yakuake  # Dropdown terminal.\npamac remove openconnect  # Cisco VPNs.\npamac remove networkmanager-openconnect  # Cisco VPNs.</code></pre><p></p> <p>Install Chrome.</p> <p>Install VSCodium.</p>"},{"location":"os/manjaro/preferences/#remove-msn-manjaro-settings-notifier","title":"Remove MSN (Manjaro Settings Notifier)","text":"<p>Remove if you are an advanced user.</p> <p>Comment out all contents:</p> <p>/etc/xdg/autostart/msm_kde_notifier.desktop</p> <p>/etc/xdg/autostart/pamac-tray-plasma.desktop</p> <p>/etc/xdg/autostart/org.fcitx.Fcitx5.desktop</p> <p>Optionally set immutable to prevent upgrades reverting changes. </p><pre><code>chattr +i /etc/xdg/autostart/{msm_kde_notifier.desktop,pamac-tray-plasma.desktop,org.fcitx.Fcitx5.desktop}</code></pre><p></p> <p>Reboot to apply changes</p>"},{"location":"os/manjaro/troubleshooting/","title":"Troubleshooting","text":""},{"location":"os/manjaro/troubleshooting/#troubleshooting","title":"Troubleshooting","text":""},{"location":"os/manjaro/troubleshooting/#increase-failed-auth-lockout-attempts","title":"Increase Failed auth Lockout Attempts","text":"<p>Manjaro will lockout a user for 10 minutes on 3 failed password attempts over 15 minutes.</p> <p>Expressed as sudo not working with valid password or unable to login to the system.</p> <p>/etc/security/faillock.conf</p> <p>0644 root:root</p> <pre><code>deny = 5\nfail_interval = 300\nunlock_time = 600</code></pre>"},{"location":"os/manjaro/troubleshooting/#application-scaling","title":"Application Scaling","text":"<p>High DPI monitors require custom scaling settings.</p> <p>\u2318 \u2794 system settings \u2794 display and monitor \u2794 display configuration</p> <ul> <li>Global scale: 150%</li> <li>Legacy applications (X11): Apply scaling themselves</li> </ul>"},{"location":"os/manjaro/troubleshooting/#fonts-look-fuzzy","title":"Fonts look fuzzy","text":"<p>Fonts may not support subpixel hints or it may be disabled.</p> <p>Copy custom fonts to system. </p><pre><code># Requires reboot if not manually loaded in Font Manager.\ncp {FONTS} /usr/share/fonts\nsystemsettings kcm_fontinst  # Font Manager in GUI.</code></pre><p></p> <p>Tweak font display for LCD's if display is still not clean.</p> <p>/etc/fonts/local.conf</p> <p>0644 root:root</p> <pre><code>&lt;?xml version=\"1.0\"?&gt;\n&lt;!DOCTYPE fontconfig SYSTEM \"fonts.dtd\"&gt;\n&lt;fontconfig&gt;\n  &lt;match target=\"font\"&gt;\n    &lt;edit name=\"autohint\" mode=\"assign\"&gt;\n      &lt;bool&gt;false&lt;/bool&gt;\n    &lt;/edit&gt;\n    &lt;edit name=\"hinting\" mode=\"assign\"&gt;\n      &lt;bool&gt;true&lt;/bool&gt;\n    &lt;/edit&gt;\n    &lt;edit name=\"antialias\" mode=\"assign\"&gt;\n      &lt;bool&gt;true&lt;/bool&gt;\n    &lt;/edit&gt;\n    &lt;edit mode=\"assign\" name=\"hintstyle\"&gt;\n      &lt;const&gt;hintslight&lt;/const&gt;\n    &lt;/edit&gt;\n    &lt;edit mode=\"assign\" name=\"rgba\"&gt;\n      &lt;const&gt;rgb&lt;/const&gt;\n    &lt;/edit&gt;\n    &lt;edit mode=\"assign\" name=\"lcdfilter\"&gt;\n      &lt;const&gt;lcddefault&lt;/const&gt;\n    &lt;/edit&gt;\n  &lt;/match&gt;\n&lt;/fontconfig&gt;</code></pre> <p>~/.Xresources</p> <p>0644 {USER}:{USER}</p> <pre><code>Xft.antialias: 1\nXft.hinting: 1\nXft.autohint: 0\nXft.rgba: rgb\nXft.hintstyle: hintslight\nXft.lcdfilter: lcddefault</code></pre> <p>Merge settings, link additional profiles, and update cache. </p><pre><code>xrdb -merge ~/.Xresources\nln -s /usr/share/fontconfig/conf.avail/10-sub-pixel-rgb.conf /etc/fonts/conf.d/\nln -s /usr/share/fontconfig/conf.avail/11-lcdfilter-default.conf /etc/fonts/conf.d/\nfc-cache -f -v</code></pre><p></p>"},{"location":"os/manjaro/troubleshooting/#caps-lock-as-control","title":"Caps lock as Control","text":"<p>Override caps lock for keyboards that do not remap caps lock key.</p> <p>/etc/default/keyboard</p> <p>0644 root:root</p> <pre><code>XKBOPTIONS=\"ctrl:nocaps\"</code></pre> <p>For current session. </p><pre><code>localectl set-x11-keymap us pc105 ,query ctrl:nocaps</code></pre><p></p> <p>Reboot to apply.</p>"},{"location":"os/manjaro/troubleshooting/#windows-opening-on-wrong-monitor","title":"Windows Opening on Wrong Monitor","text":"<p>Some applications misbehave.</p> <p>System Settings \u2794 Apps &amp; Windows \u2794 Window Management</p> <ul> <li>Window Behavior:<ul> <li>Advanced:<ul> <li>Window placement: Centered</li> </ul> </li> </ul> </li> <li>Window Rules:<ul> <li>Add New:<ul> <li>Description: Fix windows starting on wrong screen</li> <li>Window class (application): Unimportant</li> <li>Match whole window class: No</li> <li>Window types: Normal Window  # un-select all others.</li> <li>Add Property:<ul> <li>Ignore requested geometry:<ul> <li>Apply Initially: Yes</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"os/manjaro/troubleshooting/#manjaro-updates-consistently-fail","title":"Manjaro Updates Consistently Fail","text":"<p>Last update was more than six months ago and keys are expired.</p> <p>/etc/pacman.conf</p> <p>0644 root:root</p> <pre><code># Only for expired PGP keys -- DANGEROUS - always revert after updates.\n# SigLevel = Required DatabaseOptional\nSigLevel = Optional TrustAll</code></pre> <pre><code>pamac update</code></pre>"},{"location":"os/manjaro/troubleshooting/#mouse-acceleration-seems-wonky","title":"Mouse Acceleration Seems Wonky","text":"<p>Adaptive refresh seems to cause mouse acceleration issues in KDE Plasma Wayland.</p> <p>\u2318 \u2794 System Settings \u2794 Input &amp; Output</p> <ul> <li>Mouse &amp; Touchpad (All devices)<ul> <li>Pointer Acceleration: None</li> </ul> </li> <li>Display &amp; Monitor<ul> <li>Adaptive sync:  Never</li> </ul> </li> </ul>"},{"location":"os/manjaro/troubleshooting/#recover-from-a-bad-upgrade-with-encrypted-root-disk","title":"Recover from a Bad Upgrade with Encrypted Root Disk","text":"<p>Generally when Windows decides it's the boot manager and is wrong.</p> <p>Boot from USB Boot Disk.</p> <p>Mount LUKS Volume </p><pre><code>ls -l /dev/{nvme,sd}*\n\n# Mount LUKS encrypted partition.\ncrypt setup -v luksOpen /dev/{PARTITION} crypt_drive\n\n# Mount and decrypt.\nmount /dev/mapper/crypt_drive /mnt\n\n# Switch to installed system root and update.\nmanjato-chroot /mnt\npacman-mirrors --fasttrack 5 &amp;&amp; pacman -Syyu\n\n# Update EFI boot manager.\nefibootmgr -v\ngrub-install --target=x86_64-efi --efi-directory=/boot/efi --bootloader-id=manjaro --recheck\ngrub-mkconfig -o /boot/grub/grub.cfg\nmkinitcpio -P\npacman -S linux\nefibootmgr -v</code></pre><p></p>"},{"location":"os/manjaro/troubleshooting/#list-of-user-installed-packages","title":"List of User Installed Packages","text":"<p>Only explicitly installed by user (no dependencies).</p> <pre><code>pacman -Qqe | grep -v \"$(awk '{print $1}' /desktopfs-pkgs.txt)\"</code></pre> <p>Reference:</p>"},{"location":"os/manjaro/troubleshooting/#list-of-package-by-install-date","title":"List of Package by Install Date","text":"<pre><code>pacman -Syu expac\nexpac --timefmt='%Y-%m-%d %T' '%l\\t%n' | sort -n</code></pre>"},{"location":"os/pve/","title":"Promox (PVE)","text":""},{"location":"os/pve/#promox-pve","title":"Promox (PVE)","text":""},{"location":"os/pve/#setup","title":"Setup","text":""},{"location":"os/pve/#prep","title":"Prep","text":"<ul> <li>Make full stop backup of containers/vms to pve/backups.</li> <li>Shutdown containers.</li> </ul> <p>For all cluster nodes </p><pre><code>mkdir -p /autofs/pve/{DATE}-upgrade/{NODE}\ncp -av /etc /autofs/pve/{DATE}-upgrade/{NODE}\ncp -av /root /autofs/pve/{DATE}-upgrade/{NODE}</code></pre> * Only upgrade one cluster node at a time.<p></p>"},{"location":"os/pve/#base-install","title":"Base Install","text":"<p>Create Live USB Install.</p> <p>Install Options</p> <ul> <li>Graphical install</li> <li>License: agree</li> <li>Default HD Setup (EXT4): next</li> <li>Country: United States</li> <li>Timezone: UTC</li> <li>Keyboard Layout: U.S. English</li> <li>Email: root@localhost</li> <li>Reboot when complete</li> </ul>"},{"location":"os/pve/#base-networking","title":"Base Networking","text":"<p>Use bonded interface (only the first adapter) for management IP. Always confirm device names as they may change between major OS releases.</p> <pre><code>nano /etc/network/interfaces  # No network - vim not installed.\nsystemctl restart networking\nping google.com\napt install vim</code></pre> <p>Remaining configuration may be done vis SSH (easier for copying). Leave console open for easy rescue if networking get mis-configured.</p>"},{"location":"os/pve/#enable-iommu-and-passthrough-virtualization","title":"Enable IOMMU and Passthrough Virtualization","text":"<p>/etc/default/grub</p> <p>0644 root:root</p> <pre><code># AMD: IOMMU &amp; SVM enabled in BIOS. Use amd_iommu for grub.\n# Intel: IOMMU &amp; VT-d enabled in BIOS. Use intel_iommu for grub.\nGRUB_CMDLINE_LINUX_DEFAULT=\"quiet intel_iommu=on iommu=pt\"</code></pre> <pre><code>update-grub\nreboot</code></pre>"},{"location":"os/pve/#update-sources","title":"Update Sources","text":"<p>Source list here.</p> <p>Warning</p> <p>Always update Proxmox with dist-upgrade. Never use upgrade.</p> <p>/etc/apt/sources.list.d/debian.sources</p> <pre><code>Types: deb\nURIs: http://deb.debian.org/debian/\nSuites: trixie trixie-updates\nComponents: main contrib non-free-firmware\nSigned-By: /usr/share/keyrings/debian-archive-keyring.gpg\n\nTypes: deb\nURIs: http://security.debian.org/debian-security/\nSuites: trixie-security\nComponents: main contrib non-free-firmware\nSigned-By: /usr/share/keyrings/debian-archive-keyring.gpg</code></pre> <p>/etc/apt/sources.list.d/ceph.sources</p> <pre><code>Types: deb\nURIs: http://download.proxmox.com/debian/ceph-squid  # NOTE: URL, HTTP.\nSuites: trixie\nComponents: no-subscription\nSigned-By: /usr/share/keyrings/proxmox-archive-keyring.gpg</code></pre> <p>/etc/apt/sources.list.d/pve-enterprise.sources</p> <pre><code>Types: deb\nURIs: http://download.proxmox.com/debian/pve  # NOTE: URL, HTTP.\nSuites: trixie\nComponents: pve-no-subscription\nSigned-By: /usr/share/keyrings/proxmox-archive-keyring.gpg</code></pre> <p>Upgrade distribution </p><pre><code>apt update\napt dist-upgrade</code></pre><p></p>"},{"location":"os/pve/#update-microcode","title":"Update Microcode","text":"<p>Trixie+ base should now include firmware by default.</p> <p>Confirm update applied (Current patch for i9-13900H is 0x4128). </p><pre><code>apt install intel-microcode\ngrep microcode /proc/cpuinfo</code></pre><p></p>"},{"location":"os/pve/#install-fake-subscription","title":"Install Fake Subscription","text":"<pre><code>wget https://github.com/Jamesits/pve-fake-subscription/releases/download/v0.0.11/pve-fake-subscription_0.0.11+git-1_all.deb\ndpkg -i pve-fake-subscription_*.deb\necho \"127.0.0.1 shop.maurer-it.com\" | tee -a /etc/hosts\nreboot</code></pre>"},{"location":"os/pve/#setup-interfaces","title":"Setup interfaces","text":"<p>Always confirm device names as they may change between major OS releases.</p> <p>Make a backup of interfaces (this also has the detected interface names). </p><pre><code>cp /etc/network/interfaces /etc/network/interfaces.orig</code></pre><p></p>"},{"location":"os/pve/#etcnetworkinterfaces","title":"/etc/network/interfaces","text":"<ul> <li>Copy from backup or source from host_vars (verify interface names).</li> <li>Remove <code>post-up /usr/bin/systemctl restart frr.service</code>.</li> <li>Update host_vars.</li> </ul>"},{"location":"os/pve/#direct-mesh-networking-routed-simple","title":"Direct mesh networking (routed, simple).","text":"<p>Ensure network is not an existing routed VLAN on router/switches or requests will be routed instead of sent via links (VLAN may be defined and exist but no interfaces should be defined to use them or serve DHCP/DNS).</p>"},{"location":"os/pve/#pve9-default-enables-frr","title":"PVE9+ default enables FRR.","text":"<p>Warning</p> <p>FRR does not need <code>post-up /usr/bin/systemctl restart frr.service</code> as of PVE9+/Trixie. Issue has been resolve in base OS and will cause hard-locks during boot requiring console access to resolve.</p> <p>Using FRR for cluster network will not show network in WebUI; cluster configuration must be done on CLI and node additions via SSH.</p> <pre><code># Get Interface Addresses\napt install frr pciutils  # lspci now in pciutils.\nls -l /sys/class/net\nlspci\nlspci -nn\nlspci -k</code></pre> <p>/etc/frr/daemons</p> <p>0640 frr:frr</p> <pre><code>  fabricd=yes  # Other FRR daemons already enabled in PVE9+.</code></pre> <p>/etc/frr/frr.conf</p> <p>0640 frr:frr</p> <p>Copy from backup or source from host_vars (verify interface names):</p> <ul> <li>See is-is routing for net definition.</li> <li>Use subnet for area ID.</li> <li>IP address with padding for system identifier.</li> <li>Update host_vars.</li> </ul>"},{"location":"os/pve/#confirm-frr-configured-correctly","title":"Confirm FRR configured correctly.","text":"<pre><code>systemctl restart frr.service  # FRR non-root. Config must be owned by FRR.\nsystemctl enable frr.service\nvtysh -c \"show openfabric topology\"\n\n# Restart Networking\nsystemctl restart networking  # May take up to 1 minute over SSH.\nreboot</code></pre> <ul> <li>Alternatively use console.</li> <li>Reboot and confirm node networking working.</li> </ul>"},{"location":"os/pve/#create-cluster-first-node","title":"Create Cluster (First Node)","text":"<p>Only use on first first node.</p> <pre><code>pvecm create hv --link0 10.11.11.10 --nodeid 1\npvecm status</code></pre>"},{"location":"os/pve/#add-node-to-cluster-all-other-nodes","title":"Add Node to Cluster (All Other Nodes)","text":"<pre><code># Node2: Add node 2 to node 1.\npvecm add 10.11.11.10 --link0 10.11.11.20 --use_ssh\n# Node3: Add node 3 to node 1.\npvecm add 10.11.11.10 --link0 10.11.11.30 --use_ssh\n\npvecm status</code></pre>"},{"location":"os/pve/#enable-acme-cluster-node-certificates","title":"Enable ACME Cluster Node Certificates","text":""},{"location":"os/pve/#backup-initial-ssh-config","title":"Backup Initial SSH Config","text":"<p>Warning</p> <p>Proxmox uses host keys and root user for intra-cluster traffic. Changing SSH settings may break this.</p> <p>Create a backup to ensure a default working state can be restored.</p> <p>Backup each node. </p><pre><code>cp -av /root /autofs/pve/{DATE}-upgrade-8-to-9/{NODE}/complete\ncp -av /etc /autofs/pve/{DATE}-upgrade-8-to-9/{NODE}/complete</code></pre><p></p>"},{"location":"os/pve/#gpu-passthrough","title":"GPU Passthrough","text":"<p>Configure for all nodes.</p> <p>/etc/default/grub</p> <p>0644 root:root</p> <pre><code>GRUB_CMDLINE_LINUX_DEFAULT=\"quiet intel_iommu=on iommu=pt i915.enable_gvt=1\"</code></pre> <p>See IMMOU and Passthrough Virtualization for other GRUB options.</p> <p>Remove legacy module configs (future Debian release will remove these). </p><pre><code>rm /etc/modules-load.d/modules.conf  # Remove symlink to /etc/modules.\nrm /etc/modules</code></pre><p></p> <p>/etc/modules-load.d/video.conf</p> <p>0644 root:root</p> <pre><code># /etc/modules is obsolete and has been replaced by /etc/modules-load.d/.\n# Please see modules-load.d(5) and modprobe.d(5) for details.\nvfio\nvfio_iommu_type1\nvfio_pci\nkvmgt</code></pre>"},{"location":"os/pve/#map-non-root-users-to-gpu","title":"Map non-root users to GPU","text":"<p>Unmapped containers require other R/W permissions on GPU.</p> <p>/etc/udev/rules.d/59-igpu-passthrough.rules</p> <p>0644 root:root</p> <pre><code>KERNEL==\"renderD128\", MODE=\"0666\"\nKERNEL==\"card1\", MODE=\"0666\"</code></pre> <p>Update grub. </p><pre><code>update-grub\nreboot\n\n# Confirm card reported.\ndmesg | grep -e DMAR -e IOMMU  # IOMMU enabled w. graphics passthrough.\nlspci -nnv | grep -i vga  # PCI device reported.</code></pre><p></p>"},{"location":"os/pve/#container-configuration","title":"Container configuration","text":""},{"location":"os/pve/#get-gpu-major-device-id","title":"Get GPU major device ID","text":"<pre><code>getent group video\n&gt; video:x:44:root  # GID: 44\ngetent group render\n&gt; render:x:993:root  # GID: 993\n\nid -g render\nls -l /dev/dri\n# Major ID is 226.\n&gt; crw-rw---- 1 root video  226,   0 May 12 21:54 card1\n&gt; crw-rw---- 1 root render 226, 128 May 12 21:54 renderD128</code></pre> <p>/etc/pve/lxc/{ID}.conf</p> <p>0644 root:root</p> <pre><code># Map major device ID to LXC container.\nlxc.cgroup2.devices.allow: c 226:* rwm\nlxc.mount.entry: /dev/dri/card1 dev/dri/card1 none bind,optional,create=file,mode=0666\nlxc.mount.entry: /dev/dri/renderD128 dev/dri/renderD128 none bind,optional,create=file,mode=0666</code></pre> <p>/etc/subgid</p> <p>0644 root:root</p> <pre><code># Map render, video groups for unprivileged containers.\n# ALWAYS confirm group ID's as they may change between major OS versions.\nroot:44:1\nroot:993:1  # 108 in Bookworm.</code></pre> <pre><code># Host dev/dri permissions do not require containers to set groups with.\nusermod -aG render,video root</code></pre>"},{"location":"os/pve/#add-nfs-mounted-volumes","title":"Add NFS mounted volumes","text":""},{"location":"os/pve/#add-uidgid-mappings-for-nfs-mounts","title":"Add UID/GID mappings for NFS mounts.","text":"<p>Use https://github.com/ddimick/proxmox-lxc-idmapper to generate mappings or copy existing mappings from backups.</p> <p>/etc/subuid</p> <p>0644 root:root</p> <p>/etc/subgid</p> <p>0644 root:root</p>"},{"location":"os/pve/#create-nfs-mount-locations","title":"Create NFS mount locations","text":"<p>Set mounts immutable to prevent writes when not mounted.</p> <pre><code>mkdir /autofs\nmkdir {MOUNT}\nchattr +i /autofs\ncd /autofs\nchattr +i *</code></pre> <p>/etc/fstab</p> <p>0644 root:root</p> <pre><code>{SERVER}:/d/pve /autofs/pve nfs4 rw,nfsvers=4,minorversion=2,proto=tcp,fsc,rsize=1048576,wsize=1048576,nocto,_netdev 0 0</code></pre> <pre><code>systemctl daemon-reload\nmount -a\nls -l /autofs  # Mounted R/W with NFS squashed permissions.</code></pre>"},{"location":"os/pve/#mount-pve-storage","title":"Mount PVE Storage","text":"<p>Cluster data storage over NFS.</p> <pre><code>pvesm add dir pve --path /autofs/pve --content images,vztmpl,backup,snippets,rootdir,iso\nreboot  # NFS should be mounted on boot.</code></pre>"},{"location":"os/pve/#reference","title":"Reference<sup>1</sup><sup>2</sup><sup>3</sup><sup>4</sup><sup>5</sup><sup>6</sup>","text":"<ol> <li> <p>https://www.juniper.net/documentation/us/en/software/junos/is-is/topics/concept/is-is-routing-overview.html#routing-is-is-overview__id-11020505 \u21a9</p> </li> <li> <p>https://gist.github.com/scyto/4c664734535da122f4ab2951b22b2085 \u21a9</p> </li> <li> <p>https://www.baeldung.com/linux/ethernet-dual-cards-increase-throughput \u21a9</p> </li> <li> <p>https://bookstack.swigg.net/books/linux/page/lxc-gpu-access \u21a9</p> </li> <li> <p>https://forum.proxmox.com/threads/proxmox-lxc-igpu-passthrough.141381/ \u21a9</p> </li> <li> <p>https://www.youtube.com/watch?v=0ZDr5h52OOE \u21a9</p> </li> </ol>"},{"location":"os/pve/acme/","title":"ACME","text":""},{"location":"os/pve/acme/#acme","title":"ACME","text":"<p>Use Let's Encrypt certificates for PVE cluster nodes with Google Cloud DNS.</p>"},{"location":"os/pve/acme/#setup-acme-in-pve-datacenter","title":"Setup ACME in PVE Datacenter","text":"<p>Applies to all nodes.</p> <p>Datacenter \u2794 ACME \u2794 Accounts \u2794 Add</p> <ul> <li>Account Name: staging</li> <li>E-Mail: user@example.com</li> <li>ACME Directory: Let's Encrypt V2 Staging</li> <li>Accept TOS: \u2714</li> </ul> <p>Datacenter \u2794 ACME \u2794 Accounts \u2794 Add</p> <ul> <li>Account Name: prod</li> <li>E-Mail: user@example.com</li> <li>ACME Directory: Let's Encrypt V2</li> <li>Accept TOS: \u2714</li> </ul> <p>Datacenter \u2794 ACME \u2794 Challenge Plugins \u2794 Add</p> <ul> <li>Plugin ID: gcloud</li> <li>Validation Delay: 120  # SLA for glcoud DNS.</li> <li>DNS API: gcloud</li> <li>API Data:     <pre><code>HOME=/home/nobody\nCLOUDSDK_AUTH_CREDENTIAL_FILE_OVERRIDE=/home/nobody/pve_acme.json\nCLOUDSDK_CORE_PROJECT={PROJECT_ID}</code></pre></li> </ul>"},{"location":"os/pve/acme/#add-google-cloud-sdk","title":"Add Google Cloud SDK","text":"<p>Add for all cluster nodes.</p> <pre><code># Add signing key.\ncurl -o /usr/share/keyrings/cloud.google.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg</code></pre> <p>/etc/apt/sources.list.d/google-cloud-sdk.sources</p> <p>0644 root:root </p><pre><code>Types: deb\nURIs: http://packages.cloud.google.com/apt/\nSuites: cloud-sdk\nComponents: main\nSigned-By: /usr/share/keyrings/cloud.google.gpg</code></pre><p></p> <pre><code># Install Google Cloud SDK and init project as ROOT.\napt-get update &amp;&amp; apt-get install google-cloud-sdk\n\ngcloud init\n&gt; Welcome! This command will take you through the configuration of gcloud.\n&gt;\n&gt; Your current configuration has been set to: [default]\n&gt;\n&gt; You can skip diagnostics next time by using the following flag:\n&gt;   gcloud init --skip-diagnostics\n&gt;\n&gt; Network diagnostic detects and fixes local network connection issues.\n&gt; Checking network connection...done.\n&gt; Reachability Check passed.\n&gt; Network diagnostic passed (1/1 checks passed).\n\nYou must sign in to continue. Would you like to sign in (Y/n)?  y\n\n&gt; Go to the following link in your browser, and complete the sign-in prompts:\n&gt;\n&gt;     https://accounts.google.com/o/oauth2/auth?response_type={AUTH_CODE}\n\n# Copy link and use local browser to authenticate. Copy auth code.\n\nOnce finished, enter the verification code provided in your browser: {AUTH_CODE}\n\n&gt; You are signed in as: [user@example.com].\n&gt;\n&gt; Pick cloud project to use:\n&gt;  [1] {PROJECT_ID}\n&gt;  [3] Enter a project ID\n&gt;  [4] Create a new project\n\nPlease enter numeric choice or text value (must exactly match list item):  1\n&gt; Your current project has been set to: [{PROJECT_ID}].\n&gt; ...</code></pre> <pre><code># Add ACME configuration for nobody user.\nmkdir -p /home/nobody/.config\ncp pve_acme.json /home/nobody/pve_acme.json\nchmod 0600 /home/nobody/pve_acme.json\nchown -R nobody:nogroup /home/nobody</code></pre>"},{"location":"os/pve/acme/#add-acme-certificates","title":"Add ACME Certificates","text":"<p>Add for all cluster nodes.</p> <p>Datacenter \u2794 {NODE} \u2794 System \u2794 Certificates \u2794 ACME \u2794 Add</p> <ul> <li>Challenge Type: DNS</li> <li>Domain: {NODE}.example.com</li> </ul> <p>Datacenter \u2794 {NODE} \u2794 System \u2794 Certificates \u2794 ACME</p> <ul> <li>Using Account: staging</li> </ul> <p>Datacenter \u2794 {NODE} \u2794 System \u2794 Certificates \u2794 Order Certificates</p> <p>Once completed switch to prod and re-order certificates to finish.</p> <p>Staging certificate will automatically be removed.</p>"},{"location":"os/pve/acme/#reference","title":"Reference<sup>1</sup><sup>2</sup>","text":"<ol> <li> <p>https://forum.proxmox.com/threads/google-domains-and-lets-encrypt-certificates-using-dns-validation-for-local-proxmox-servers.70337/ \u21a9</p> </li> <li> <p>https://pve.proxmox.com/wiki/Certificate_Management \u21a9</p> </li> </ol>"},{"location":"os/pve/troubleshooting/","title":"Troubleshooting","text":""},{"location":"os/pve/troubleshooting/#troubleshooting","title":"Troubleshooting","text":""},{"location":"os/pve/troubleshooting/#ascii-codec-cant-decode-byte-0xe2-in-position","title":"Ascii codec can't decode byte 0xe2 in position","text":"<p>See Failed to run vncproxy.</p>"},{"location":"os/pve/troubleshooting/#failed-to-run-vncproxy","title":"Failed to run vncproxy","text":"<p>SSH vncproxy proxy tunnel between pve nodes are not auto-accepted.</p> <p>VM consoles can be access on each local cluster node, but not on remote cluster nodes. May be confirmed by manually ssh'ing to other nodes and confirming that the connection is denied or the host key has changed. Frequently happens when node host keys are regenerated.</p> <p>Resolve by clearing root and host known_hosts and syncing pve certificates.</p> <pre><code># On affected nodes\nrm /root/.ssh/known_hosts\nrm /etc/ssh/ssh_known_hosts\npvecm updatecerts</code></pre>"},{"location":"os/pve/troubleshooting/#wrong-timezone","title":"Wrong Timezone","text":"<p>Containers assume UTC. Explicitly set timezone.</p> <pre><code>timedatectl\ntimedatectl list-timezones\ntimedatectl set-timezone America/Los_Angeles</code></pre>"},{"location":"os/pve/troubleshooting/#corrupted-terminal-characters-or-no-utf-8-support","title":"Corrupted Terminal Characters or No UTF-8 Support","text":"<p>Containers do not have locals set by default. Specify default locales for the container to use.</p> <p>/etc/default/locale</p> <p>0644 root:root</p> <pre><code>LANG=\"en_US.UTF-8\"\nLANGUAGE=\"en_US:en\"\nLC_CTYPE=\"en_US.UTF-8\"\nLC_NUMERIC=\"en_US.UTF-8\"\nLC_TIME=\"en_US.UTF-8\"\nLC_COLLATE=\"en_US.UTF-8\"\nLC_MONETARY=\"en_US.UTF-8\"\nLC_MESSAGES=\"en_US.UTF-8\"\nLC_PAPER=\"en_US.UTF-8\"\nLC_NAME=\"en_US.UTF-8\"\nLC_ADDRESS=\"en_US.UTF-8\"\nLC_TELEPHONE=\"en_US.UTF-8\"\nLC_MEASUREMENT=\"en_US.UTF-8\"\nLC_IDENTIFICATION=\"en_US.UTF-8\"</code></pre> <pre><code># Update locales and save.\nlocale-gen en_US.UTF-8\ndpkg-reconfigure --frontend=noninteractive locales\nupdate-locale LAN=en_US.UTF-8</code></pre> <p>Reference:</p> <ul> <li>https://old.reddit.com/r/Proxmox/comments/dhgez0/console_utf8</li> </ul>"},{"location":"os/pve/troubleshooting/#lxc-long-boot-times-or-no-console","title":"LXC Long Boot Times or No Console","text":"<p>Debian based systems will pause for up to 5 minutes on boot waiting for SLAAC IPv6 configuration information; appearing to have no console. Disable IPv6 if not actively used.</p>"},{"location":"os/pve/troubleshooting/#cephfs-read-only-cannot-run-backups","title":"CephFS Read-only Cannot Run Backups","text":"<p>In cases of individual node backups after a cluster is 'broken'.</p> <p>Never set this if the cluster is going to be re-connected</p> <pre><code>pvecm expect 1</code></pre>"},{"location":"os/windows/","title":"Windows","text":""},{"location":"os/windows/#windows","title":"Windows","text":"<p>Registry &amp; GPO Tweaks Removed</p> <p>See 2022-10.19.0 for Registry and GPO settings before they were removed.</p> <p>WinUtil</p> <p>Goto utility for non-AD Windows machines. All major standard tweaks may be done with this utility.</p> <pre><code># Run as administrator.\nirm \"https://christitus.com/win\" | iex</code></pre> <p>Tip</p> <p>See run commands for launching all settings windows from run command.</p>"},{"location":"os/windows/#setting-execution-policy","title":"Setting Execution Policy","text":"<p>Powershell scripts require unrestricted execution policy to be set to execute. By default this is disabled and is the correct choice. Once you've executed scripts, you must manually reset this to restricted or you leave yourself open to bad things. This persists across sessions.</p> <p>Check and set unrestricted policy. </p><pre><code># Run as administrator.\nGet-ExecutionPolicy\nSet-ExecutionPolicy -ExecutionPolicy unrestricted -Force</code></pre><p></p> <p>Set restricted policy. </p><pre><code># Run as administrator.\nSet-ExecutionPolicy -ExecutionPolicy restricted -force</code></pre><p></p>"},{"location":"os/windows/#set-execution-policy-via-script","title":"Set Execution Policy Via Script","text":"<p>Commands entered directly into powershell are executed. Scripts may be run without setting execution policy by launching a sub-shell with ExecutionPolicy bypassed.</p> <p>Execute script without setting ExecutionPolicy. </p><pre><code>PowerShell.exe -ExecutionPolicy Bypass -File {SCRIPT}.ps1</code></pre><p></p>"},{"location":"os/windows/#iso-downloads","title":"ISO Downloads","text":"<p>Microsoft provides ISO images of Windows for users to install, which require a separate activation key.</p> <ul> <li>Windows 11.</li> <li>Windows 10.</li> </ul> <p>Execute the downloaded binary:</p> <ol> <li>Create installation media for a different PC.</li> <li>Select correct options (typically, english, Pro / Multi, 64-bit).</li> <li>Select save location for the ISO file.</li> </ol> <p>Try Linux</p> <p>Modern linux distributions have greatly increased useability and game support in recent years. Instead of dealing with the Ad and privacy nightmare that is non-AD connected Windows machines, any modern distribution will meet your needs.</p> <p>Recommend Manjaro (Arch stable) or Mint (Debian testing).</p>"},{"location":"os/windows/#create-uefi-usb-boot-disk","title":"Create UEFI USB Boot Disk","text":"<p>Using the Windows Media Creation Tool will create a USB boot disk, however this will be using MBR. This specific setup will create a UEFI USB boot disk:</p> <ol> <li>Download and run Ventoy.</li> <li>Copy ISO downloaded to root of USB disk.</li> <li>Reboot and select ISO to boot into.</li> </ol>"},{"location":"os/windows/#install","title":"Install","text":"<p>Use USB Boot Disk.</p>"},{"location":"os/windows/#local-account-install","title":"Local Account Install","text":"<p>Connected Microsoft accounts associate TPM keys, Bitlocker keys, MS account, as well as user data together leading to a privacy nightmare. Additionally MS has recently pushed for automatically uploading user data via OneDrive without asking and setting default locations for Word documents to MS servers.</p> <p>Warning</p> <p>Always install using a local account. If you want an MS account associated later you can always make that link yourself.</p> <p>Windows 11 (1)</p> <ol> <li>Windows versions &lt;26120 use OOBE/BYPASSNRO local account bypass.</li> </ol> <p>Continue through install until Sign in appears.</p> <ol> <li>Shift+F10 will open a terminal.</li> <li>start ms-cxh:local</li> <li>Create local user with opened dialog window.</li> </ol> <p>Use 11 or Linux</p> <p>Windows 10 is being actively exploited with 0-days post update support drop. Do not use unless isolated.</p> <p>Windows 10 Home</p> <ol> <li>Unplug and disable all network connections.</li> <li>Continue through install until Let's connect you to a network.</li> <li>Select I don't have internet.</li> <li>Select Continue with limited setup.</li> </ol> <p>Windows 10 Pro</p> <ol> <li>Continue through install until How would you like to set up?.</li> <li>Select Set up for personal use.</li> <li>Select Offline account.</li> <li>Create a local account.</li> </ol> <p>Tip</p> <p>Install Process Explorer and Secure Delete for detailed process tracking, debugging, and secure delete.</p>"},{"location":"os/windows/crashes/","title":"Crashes","text":""},{"location":"os/windows/crashes/#crashes","title":"Crashes","text":"<p>I'm asked this all the time, so I put together a list of all the common things to look for when a PC is flaky and crashing. Even if you know what you're doing, you should run through these steps. You'd be surprised.</p>"},{"location":"os/windows/crashes/#general-maintenance","title":"General Maintenance","text":"<p>Required typically yearly. If you are using a new build, skip to Random Crashes.</p> <ol> <li>Pull all filters and use canned air / damp rag to clean them. They should be    obstruction free.</li> <li>Fans<ul> <li>Hold fan to prevent rotation. Use canned air on both sides (may require   removing fan).</li> <li>Use a damp rag (clorox bleach cleaners are good), and wipe out any of the   hard/compacted dust. Fan should look nearly new.</li> </ul> </li> <li>Heatsinks<ul> <li>Position canned air in fins and blow through fins to remove dust. Blow   both ways.</li> </ul> </li> <li>Blow dust out of remaining components<ul> <li>Pay special attention to flat/unused surfaces.</li> <li>Get under hard-drives.</li> <li>Should look pretty new when done.</li> </ul> </li> <li>RAM<ul> <li>Remove RAM.</li> <li>Use canned air to clean sticks as well as connectors, reseat.</li> <li>Pay attention to order in case you are using dual or quad channel RAM.</li> </ul> </li> <li>Power-up computer with case side off<ul> <li>Listen and locate any rapid 'ticking' or 'grinding' noises coming from   fans and replace those.</li> <li>Replace or ensure fans that are not spinning are connected properly (fans   may not spin if configured as such in the BIOS/UEFI. You'll have to check   that).</li> <li>Replace fans that are under spinning.</li> </ul> </li> <li>Ensure all connections are tight, and you haven't knocked anything out of    whack.</li> </ol>"},{"location":"os/windows/crashes/#random-crashes","title":"Random Crashes","text":"<p>In most cases I've seen, this is due to hardware not connected properly, or actual defective hardware. Most BSOD's I've seen in Windows 10 are actually hardware related and not due to funky Windows installs.</p> <p>First, make sure when you run tests, you log everything. When you crash you will probably not be paying attention to specific values. This also helps you to verify faulty hardware with manufacturers later on.</p> <p>Additionally, pay attention to what you are doing when you crash. It can give you a good jump-off point for quickly debugging the issue. Gaming? Maybe start with power/connections/airflow. BSOD's? What does the screen infer?</p> <p>Basic utilities to monitor system include HWinfo and HWmonitor. Both of these provide monitoring and logging for many computer components.</p>"},{"location":"os/windows/crashes/#memory","title":"Memory","text":"<p>Setup memtest86 on a USB drive and set it to run the standard tests. Faulty memory will be apparent either immediately, or within a few minutes. In most cases I've seen, running the test for 24 hours works as a good 'burn in' test, but won't actually detect any additional memory issues.</p> <p>If you get errors, walk through each of these steps, retesting on each change:</p> <ol> <li>Save the logs.</li> <li>Reseat your memory.</li> <li>Seriously, Reseat your memory.</li> <li>Ensure your memory is paired properly for dual/quad channel.</li> <li>Disable XMP timings.</li> <li>Iterate through the minimum number of sticks to boot; test and add an    additional memory stick after each test.</li> <li>Always verify your suspected 'defective' stick independently.</li> </ol>"},{"location":"os/windows/crashes/#cpus","title":"CPU's","text":"<p>Setup CPUZ and run it. It should display your CPU as well as current frequency and voltages. Check your voltages to make sure your CPU is getting at least the minimum required to work.</p> <p>Setup prime95 to stress test CPU.</p> <p>Options \u2794 Torture Test \u2794 In-place large FFT's</p> <p>This will allow you to test your CPU under load.</p> <ol> <li>Ensure your CPU power (4/8 pin power near CPU) is actually connected.</li> <li>Search for and check voltages for your specific CPU:<ul> <li>Watch these numbers as you do the task that crashes your machine.</li> <li>Do they dip? Are they low? You may need to tweak motherboard BIOS to   supply the right amount of power, or replace the power supply.</li> </ul> </li> <li>Is the CPU running hot at idle/load?<ul> <li>Generally, 85c is the limit on CPU heat -- if it is, ensure that   fans/heatsink are clean and connected.</li> <li>Remove heatsink, clean both CPU and heatsink with isopropyl alcohol, and   replace heatsink compound.</li> <li>Ensure heatsink is contacting CPU correctly.</li> </ul> </li> <li>Is your BIOS configured to shutdown automatically when a temperature limit is    hit? By default this is for extreme cases, but you may be hitting it.</li> </ol>"},{"location":"os/windows/crashes/#gpus","title":"GPU's","text":"<p>Setup GPUZ and Furmark. Use GPUZ to get information on the GPU, and run a stress test on your video card with Furmark. A stable system should be able to run this at max settings for your PC without crashing indefinitely.</p> <ol> <li>Ensure Windows drivers for the video card are the most recent version.    Clean install your drivers if you crash.</li> <li>If you just started crashing and you recently updated drivers,    Clean install older versions of your drivers.</li> <li>Re-seat GPU, ensure you are locking the card into the slot.</li> <li>Ensure that Power cables are connected to the GPU if they have connections    for it.</li> <li>If GPU temperatures are hot at idle, clean fan/heatsinks.</li> <li>Search for and check voltages for your specific GPU.<ul> <li>Watch these numbers as you do the task that crashes your machine.</li> <li>Do they dip? Are they low? You may need to tweak motherboard BIOS/EFI to   supply the right amount of power, or replace the power supply.</li> </ul> </li> <li>Is the GPU running hot at idle/load?<ul> <li>Generally, 85c is the limit on GPU heat -- if it is, ensure that   fans/heatsink are clean and connected.</li> <li>Some drivers will BSOD if the GPU temperature remains too hot. f8. Use a different PCIe slot. Your 16x might be borked.</li> </ul> </li> <li>SLI Configurations<ul> <li>Test each card independently, in each slot.</li> <li>Verify that both cards and slots are functioning properly.</li> </ul> </li> </ol>"},{"location":"os/windows/crashes/#hdds","title":"HDD's","text":"<p>Setup CrystalDiskInfo and run it. It should detect all of your HDD's and SSD's. It will report a general 'SMART' status (e.g. GOOD) for each disk and the temperature.</p> <p>Setup CrystalDiskMark. After analyzing CrystalDiskInfo results, if you believe your crashes related to disk, run the CrystalDiskMark bench on your disks -- this will prematurely wear your SSD's. A BSOD crash running this software usually means the disk in question is bad (test a different disk) or the motherboard SATA/chipset drivers need to be installed or updated.</p> <p>Sound isn't necessarily a signal of failure. Some drives (like Western Digitals) are notorious for being loud on spin-up and seeking. This is normal. You need to make a determination if the sound you are hearing is normal or not. Check youtube for videos of your specific drive / manufacturer. Bad sounds generally entail loud 'clicking' or 'clacking' and are obvious.</p> <ol> <li>Generally, HDD's should be pretty tolerant to high temperatures, though    excessive temperatures for prolonged periods of time (&gt;~55c) could cause    premature failure. Fix this by re-locating drives or adding some cooling.</li> <li>SSD drives (especially M.2 NVME) perform better at higher temperatures and    have internal throttling mechanisms. It's generally OK to see them operating    around ~60c.</li> <li> <p>Check on the drive in question. In the detailed SMART report, look for    indicators of failing drives.</p> <ul> <li>Raw Read Error Rate.</li> <li>Reallocated Sectors/NAND Count.</li> <li>Spin Retry Count.</li> <li>Reallocation Event Count.</li> <li>Uncorrectable Sector Count.</li> <li>Ultra DMA CRC Error Count.</li> <li>Write Error Rate.</li> <li>Seek Error Rate.</li> <li>Erase Fail Count.</li> <li>Program Fail Count.</li> </ul> <p>Note</p> <p>SMART still may report GOOD, but high rates of the preceding failures  is an indication your drive is failing. It is common to have a few of  these in normal usage, that's how drives work; a drive with an issue  will stand out with error rates. You'll know it when you see it.</p> </li> <li> <p>If SATA: replace cables. Throw the old ones out. Check power connections.</p> </li> <li>If M.2 NVME: ensure slot isn't shared or disabled. Move to another slot if    possible.</li> </ol>"},{"location":"os/windows/crashes/#motherboards","title":"Motherboards","text":"<p>This is very specific to each motherboard you own. however general concepts remain the same. Get your motherboard model in the BIOS, usually by pressing del.</p> <ol> <li>Always search for and apply the latest non-beta BIOS update. This will    usually address CPU microcode and board instability issues.</li> <li>Only apply beta BIOS updates if the specific fix applies directly to your    situation. No, you are not a special case.</li> <li>Ensure you haven't disabled something you are trying to use in your BIOS</li> <li>Always download the drivers associated with your motherboard and install them. I don't care if windows 'auto-detected' everything. This is a huge    source of many issues. Particularly, you want to ensure that you have    installed these (listed in order of importance). Most of the time there will    be a newer version on the site, and if you don't use the specific device, you    can disable it in the BIOS or Windows Device Manager:<ul> <li>BIOS/UEFI.</li> <li>Chipset.</li> <li>SATA.</li> <li>Audio.</li> <li>VGA (even if descrete card, e.g. GPU, is used).</li> <li>LAN.</li> <li>Wireless.</li> <li>Bluetooth.</li> </ul> </li> <li>If power supplied to the motherboard (and other components) is consistently    low, or jumps around a lot, replace your power supply.</li> <li>Verify your RAM and SSD's (especially NVME) are listed as compatible with    your specific motherboard. These are listed usually as hardware    qualification lists. In recent years, I've noticed that motherboards are    much more sensitive to RAM and SSD's used, even though they are based on a    standard.</li> </ol>"},{"location":"os/windows/crashes/#reference","title":"Reference<sup>1</sup>","text":"<ol> <li> <p>https://docs.microsoft.com/en-us/sysinternals/downloads/process-explorer \u21a9</p> </li> </ol>"},{"location":"os/windows/reinstall/","title":"Reinstall","text":""},{"location":"os/windows/reinstall/#reinstall","title":"Reinstall","text":"<p>Common things to remember when reinstalling a Windows machine.</p>"},{"location":"os/windows/reinstall/#use-robocopy","title":"Use Robocopy","text":"<p>Fast, multi-threaded, stateful copy. Faster that GUI copy.</p> <p>Remove any existing junctions, otherwise copy with halt on them. Backup any wanted data from the following default locations:</p> <ul> <li>c:\\Users</li> <li>c:\\Programs</li> <li>c:\\ProgramData</li> <li>c:\\Program Files (x86)</li> <li>c:\\Program Files</li> </ul> <p>Copy with robocopy (powershell as admin) </p><pre><code># Run as administrator\nrobocopy \"{SOURCE} \" \"{DESTINATION} \" /copyall /mt /z /e</code></pre><p></p> <p>Note</p> <p>There is an escaping issue with ** at the end of a path. Paths with trailing ** (e.g. **\"c:\\Program Files (x86)\\ \") require an extra space to parse the path correctly based on how the strings are passed internally.</p> <p>Add extra space to all paths as it does not affect outcome and ensures no path errors. Always quote paths.</p>"},{"location":"os/windows/reinstall/#dump-existing-registry","title":"Dump Existing Registry","text":"<p>Backup the existing registry in case anything is missed after reinstall.</p> <p>\u2318 \u2794 regedit \u2794 Computer \u2794 {RMB} \u2794 Export</p>"},{"location":"os/windows/reinstall/#gamesave-manager","title":"Gamesave Manager","text":"<p>Backup the installation directory and games database:</p> <ul> <li>c:\\Program Files (x86)GameSave Manager v3</li> <li>%appdata%\\roaming\\GameSave Manager 3</li> </ul>"},{"location":"os/windows/reinstall/#putty","title":"Putty","text":"<p>Dump putty settings to reg file. </p><pre><code># Run as administrator.\nregedit /e '%userprofile%\\Desktop\\putty.reg' 'HKEY_CURRENT_USER\\Software\\SimonTatham'</code></pre><p></p>"},{"location":"os/windows/reinstall/#winscp","title":"WinSCP","text":"<p>\u2318 \u2794 winscp \u2794 Tools \u2794 Export/Backup Configuration</p> <p>Dump winscp settings to reg file. </p><pre><code># Run as administrator.\nregedit /e '%userprofile%\\Desktop\\winscp.reg' 'HKEY_CURRENT_USER\\Software\\Martin Prikryl\\WinSCP 2'</code></pre><p></p>"},{"location":"os/windows/reinstall/#musicbee","title":"MusicBee","text":"<ul> <li>Copy any special files from installation directory (e.g. plugins, etc). These   are located in c:\\Program Files (x86)/MusicBee**.</li> <li>Copy configuration data from %appdata%/roaming/musicbee.</li> </ul>"},{"location":"os/windows/reinstall/#mumble","title":"Mumble","text":"<p>Backup the client settings, certificates, and database:</p> <ul> <li>%appdata%\\Mumble\\mumble.sqlite</li> <li>%appdata%\\roaming\\Mumble</li> </ul> <p>Dump mumble client settings to reg file. </p><pre><code># Run as administrator.\nregedit /e '%userprofile%\\Desktop\\putty.reg' 'HKEY_CURRENT_USER\\Software\\Mumble\\Mumble'</code></pre><p></p>"},{"location":"os/windows/reinstall/#claws-mail","title":"Claws-mail","text":"<p>Default installation directory includes configuration and mail data:</p> <ul> <li>c:\\Program Files (x86)\\claws</li> </ul>"},{"location":"os/windows/reinstall/#gaming","title":"Gaming","text":"<p>Backup saves and game data from game services.</p>"},{"location":"os/windows/reinstall/#origin","title":"Origin","text":"<p>Directory contains configuration and saves: c:\\Program Files (x86)\\Origin.</p>"},{"location":"os/windows/reinstall/#uplay","title":"Uplay","text":"<p>Directory contains configuration and saves: c:\\Program Files (x86)\\Ubisoft.</p> <p>Warning</p> <p>Older Ubisoft games do not back up to their servers even though they say they do.</p>"},{"location":"os/windows/reinstall/#steam","title":"Steam","text":"<p>Directory contains configuration and saves: c:\\Program Files (x86)\\Steam\\userdata.</p>"},{"location":"os/windows/troubleshooting/","title":"Troubleshooting","text":""},{"location":"os/windows/troubleshooting/#troubleshooting","title":"Troubleshooting","text":""},{"location":"os/windows/troubleshooting/#applications-not-appearing-in-start-menu-searches","title":"Applications Not Appearing in Start Menu Searches","text":"<p>Background Tasks need to be enabled for the application index to be updated when new programs are installed.</p> <p>\u2318 + r \u2794 ms-settings:privacy-backgroundapps</p> <p>Let apps run in the background: \u2714</p> <p>By disabling all background tasks (global toggle) this index is never updated, and therefore apps will stop appearing in start menu searches. You can still disable all apps in the background, however the service still needs to be enabled.</p>"},{"location":"os/windows/troubleshooting/#ntfs-file-ownership-access-denied","title":"NTFS File Ownership Access Denied","text":"<p>Default well known SIDs were removed from file permissions and replaced with a specific user SID that no longer exists.</p> <p>Replace old SID with current system SID. (1)</p> <ol> <li>Alternatively take ownership and copy files to a NTFS partition with proper    SID's set.</li> </ol> <pre><code># Run as administrator.\nsetacl.exe -on c:\\ -ot file -actn trustee -trst \"n1:S-old-501;n2:S-new-501;ta:repltrst\" -rec cont</code></pre> <p>Affected NTFS partition should be nuked and re-formatted.</p>"},{"location":"os/windows/troubleshooting/#undeletable-system-volumes","title":"Undeletable System Volumes","text":"<p>System Volume information copied from another system which no longer exists.</p> <p>Take ownership and grant full privileges for everyone to remove the directory. </p><pre><code># Run as administrator.\ntakeown /f \".\\System Volume Information\" /a /r /d y\nicacls \".\\System Volume Information\" /t /c /grant administrators:F System:F everyone:F\nrd \".\\System Volume Information\"</code></pre><p></p>"},{"location":"os/windows/troubleshooting/#application-or-game-refuses-to-start-hyper-v-virtualization-detected","title":"Application or game refuses to start (Hyper-V Virtualization detected)","text":"<p>Some applications and games detect Hyper-V virtualization and refuse to start.</p> <p>Disable Hyper-V on Windows boot instead of through the BIOS. This removes the hypervisor kernel modules which prevents this from happening without needing to turn it off. </p><pre><code># run as administrator.\nbcdedit --% /copy {current} /d \"No Hyper-V\"\n\nbcdedit --%  /set {GUID} hypervisorlaunchtype off</code></pre><p></p> <p>Restart holding shift to show boot options. Select No Hyper-V.</p>"},{"location":"os/windows/troubleshooting/#locked-out-after-update-password-reset","title":"Locked out after Update (Password Reset)","text":"<p>Updates may cause users to be locked out after rebooting.</p> <p>No Alternative Account.</p> <ol> <li>Download Hiren BootCD ISO.</li> <li> <p>Create Bootable USB Disk.</p> <p>Utilities \u2794 Security \u2794 Passwords \u2794 Lazesoft Password Security</p> <p>Note</p> <p>Accounts may only be reset and unlocked (no password); passwords cannot be set in this tool without a license. Resetting the account will also clear saved tokens, such as chrome auto login.</p> </li> </ol> <p>Alternative Account (no admin required).</p> <ol> <li> <p>Reboot and hold shift until the troubleshooting options appear.</p> <p>Login Screen \u2794 shift (hold) + Restart</p> <p>Troubleshoot \u2794 Advanced options \u2794 Startup Settings \u2794 Restart \u2794 Enable Safe Mode with Command Prompt</p> </li> <li> <p>Find the correct user and set password.</p> <pre><code>net user\nnet user {USER} {PASS}</code></pre> </li> </ol>"},{"location":"os/windows/troubleshooting/#utc-realtime-clock","title":"UTC Realtime Clock","text":"<p>Only required if dual booting requires Windows 10.</p> <p>Set BIOS clock to UTC and update windows to interpret the Realtime Clock (RTC) using the UTC timezone. Disable NTP updates and let other operation system handle clock updates.</p> <p>Set RTC to UTC</p> <p><code>HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation</code></p> <p>Key: RealTimeIsUniversal</p> <p>Type: DWORD</p> <p>Value: 1</p> <p>Disable NTP sync</p> <p><code>HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\W32Time\\TimeProviders\\NtpClient</code></p> <p>Key: Enabled</p> <p>Type: DWORD</p> <p>Value: 0</p>"},{"location":"os/windows/troubleshooting/#realtek-a-volute-nahimic","title":"Realtek A-Volute (Nahimic)","text":"<p>Realtek has added A-Volute(Nahimic) services to the install package. These generally automatically take over speaker and microphone settings to improve 'quality'. They are also added automatically via Microsoft auto updates based on hardware detection, as well as through Dolby Atmos installation.</p> <p>Disabling does not affect either realtek or dolby installs.</p> <p>Nahimic behaves very much like a virus, automatically reinstalling itself and running two processes to ensure it is always loaded; providing no value to the end user.</p>"},{"location":"os/windows/troubleshooting/#disabling","title":"Disabling","text":"<p>If the realtek device is not being used, disable it in the BIOS. This will prevent Microsoft from re-installing the software every time windows update runs.</p> <p>Disable Nahimic Virtual Devices</p> <p>\u2318 + x \u2794 Device Manager \u2794 Software components \u2794 A-Volute Nh3 Audio Effects Component \u2794 Disable</p> <p>\u2318 + x \u2794 Device Manager \u2794 Sound, video and game controllers</p> <ul> <li>Nahimic Mirroring Device: \u2718</li> <li>Sonic Studio Virtual Mixer: \u2718</li> </ul> <p>Disable Nahimic Services</p> <p>\u2318 \u2794 services.msc \u2794 Nahimic service \u2794 General \u2794 Disabled</p> <p>Stop service.</p> <p>Prevent Nahimic Executables from Starting</p> <p>User Configuration \u2794 Administrative Templates \u2794 System \u2794 Don't run specified Windows applications</p> <ul> <li>Enabled: \u2714</li> <li>List of disallowed applications<ul> <li>c:\\Windows\\System32\\NahimicService.exe</li> <li>c:\\Windows\\System32\\NahimicSvc64.exe</li> <li>c:\\Windows\\SysWOW64\\NahimicSvc32.exe</li> <li>c:\\Windows\\System32\\NhNotifSys.exe</li> <li>c:\\Users{USER}\\AppData\\Local\\NhNotifSys\\NhNotifSys.exe</li> <li>c:\\Users{USER}\\AppData\\Local\\NhNotifSys\\sonicstudio\\NhNotifSys.exe</li> </ul> </li> </ul> <p>Disable Nahimic Scheduled Tasks (tasks may not exist)</p> <p>\u2318 \u2794 Task Scheduler \u2794 Task Scheduler Library</p> <ul> <li>NahimicSvc32Run: \u2718</li> <li>NahimicSvc64Run: \u2718</li> <li>NahimicTask32: \u2718</li> <li>NahimicTask64: \u2718</li> </ul> <p>Delete files that have been placed in C:\\Users{USER}\\AppData\\Local\\NhNotifSys.</p>"},{"location":"os/windows/troubleshooting/#ea-updater-or-other-apps-showing-in-search-results","title":"EA Updater (or other apps) showing in search results","text":"<p>\u2318 + i \u2794 Privacy &amp; Security \u2794 Searching Windows</p> <ul> <li>Classic: \u2714</li> <li>Exclude all drives</li> </ul>"},{"location":"os/windows/troubleshooting/#disable-usb-selective-suspend","title":"Disable USB Selective Suspend","text":"<p>Prevents external drives from being disconnected while in use.</p> <p>\u2318 + x \u2794 Device Manager \u2794 Universal Serial Bus controllers</p> <ul> <li>Right click on each USB Root Hub:<ul> <li>Power Management:<ul> <li>Allow the computer to turn off this device to save power: \u2718</li> </ul> </li> </ul> </li> </ul> <p>\u2318 + i \u2794 System \u2794 Power &amp; Battery</p> <p>Verify current power plan isn't set to aggressively manage USB power.</p>"},{"location":"os/windows/troubleshooting/#prevent-disk-check-on-every-boot","title":"Prevent Disk Check on Every Boot","text":"<p>Dual booting systems encounter this.</p> <p>Disable hybrid boot</p> <p><code>HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Session Manager\\Power</code></p> <p>Key: HiberbootEnabled</p> <p>Type: DWORD</p> <p>Value: 0</p>"},{"location":"os/windows/troubleshooting/#astro-a40s-not-consistently-working","title":"Astro A40's Not Consistently Working","text":"<p>Windows 11 requires DAC to be directly connected to a motherboard USB port and not a hub.</p>"},{"location":"printing/brother_mfcl2750dw/","title":"Brother MFC-L2750DW","text":""},{"location":"printing/brother_mfcl2750dw/#brother-mfc-l2750dw","title":"Brother MFC-L2750DW","text":"<p>Driver Downloads.</p> <p>Use Defense in Depth</p> <p>Disable any printing services not being used. Always set non-default passwords and enforce restrictions on the device as well as firewall rules.</p> <p>It is assumed that the printer is on an isolated VLAN with all Wifi disabled.</p>"},{"location":"printing/brother_mfcl2750dw/#common-endpoints","title":"Common Endpoints","text":"<p>Commonly used endpoints for networking printing.</p> Service Address Web Service http://{HOST}/WebServices/Device IPP/IPPS https://{IP}/ipp/ IPP/IPPS https://{IP}/ipp/port1/ (jetdirect compatibility) <p>Additional enabled endpoints found at: network \u2794 network \u2794 service.</p>"},{"location":"printing/brother_mfcl2750dw/#printer-configuration","title":"Printer Configuration","text":"<p>Tip</p> <p>Any section not listed is left at defaults. Save on each page before moving into sub pages or new tabs.</p>"},{"location":"printing/brother_mfcl2750dw/#login-to-webui","title":"Login to WebUI","text":"<p>Default login is typically on a label on the underside or backside of printer. Common default passwords are initpass or access.</p> AdministratorNetworkNetwork (Wired)Network (Security)GeneralPrintScan <ul> <li> <p>Login Password:</p> <ul> <li>Password: {PASS}</li> </ul> <p>Note</p> <p>New password can be at least 25 characters with all alphanumerics and symbols.</p> </li> <li> <p>User Restriction Function: \u2718</p> </li> <li>Setting Lock: \u2718</li> <li>Date &amp; Time:<ul> <li>Clock Type: 24h Clock</li> <li>Time Zone: {TZ}</li> <li>Auto Daylight: \u2714</li> <li>Synchronize with SNTP server: \u2714</li> </ul> </li> <li>Panel Logout Time: 60 seconds</li> <li>Firmware Update: \u2718</li> <li> <p>Firmware Auto Check: \u2718</p> <p>Warning</p> <p>Do not update unless there are actual issues printing. Recent Brother firmware updates have disabled printers with third-party cartridges.</p> </li> <li> <p>Stored Print Jobs:</p> <ul> <li>Auto Delete: \u2714</li> <li>Day: 0 days</li> <li>Time: 0 hours</li> </ul> </li> </ul> <ul> <li>Interface:<ul> <li>Interface: NC-9300h Ethernet 10/100BASE-TX</li> <li>Wi-fi Direct: \u2718</li> </ul> </li> <li>Protocol:<ul> <li>Web Based Management (Web Server): \u2714<ul> <li>HTTP Server Settings:<ul> <li>Select the Certificate: Preset</li> <li>Web Based Management: \u2008<ul> <li>HTTPS: \u2714</li> <li>HTTP: \u2718</li> </ul> </li> <li>IPP: \u2008<ul> <li>HTTPS: \u2714</li> <li>HTTP: \u2718<ul> <li>Port 80: \u2718</li> <li>Port 631: \u2718</li> </ul> </li> </ul> </li> <li>Web Services:<ul> <li>HTTP: \u2714</li> </ul> </li> </ul> </li> </ul> </li> <li>SNMP: \u2714<ul> <li>Advanced Settings:<ul> <li>SNMP Mode of Operation: SNMPv3 read-write access and v1/v2c read-only access</li> <li>Username: {USER}</li> <li>Key Type: Password</li> <li>Authentication Method: SHA1</li> <li>Authentication Password: {PASS}</li> <li>Privacy Password: {PASS}</li> <li>Context Name: authNoPriv</li> </ul> </li> </ul> </li> <li>Remote Setup: \u2718</li> <li>LPD: \u2718</li> <li>Raw Port (jetdirect): \u2718</li> <li>IPP: \u2714</li> <li>AirPrint: \u2718</li> <li>Mopria: \u2718</li> <li>Web Services (WSD): \u2714<ul> <li>Advanced Settings:<ul> <li>Web Services Name: Brother MFC-L2750DW</li> </ul> </li> </ul> </li> <li>Mobile printing for Windows: \u2718</li> <li>Google Cloud Print: \u2718</li> <li>Proxy: \u2718</li> <li>Network Scan (network scanning device): \u2714</li> <li>PC Fax Receive: \u2718</li> <li>SMTP: \u2718</li> <li>FTP Server: \u2718</li> <li>FTP Client: \u2718</li> <li>TFTP: \u2718</li> <li>CIFS: \u2718</li> <li>mDNS: \u2718</li> <li>LLMNR: \u2718</li> <li>SNTP: \u2714<ul> <li>Advanced Settings:<ul> <li>SNTP Server Method: Static</li> <li>Primary SNTP Server Address: 0.pool.ntp.org</li> <li>Primary SNTP Server Port: 123</li> <li>Secondary SNTP Server Address: 1.pool.ntp.org</li> <li>Secondary SNTP Server Port: 123</li> <li>Synchronization Interval: 24 hours</li> </ul> </li> </ul> </li> </ul> </li> </ul> <ul> <li>TCP/IP (wired):<ul> <li>Boot Method: {DHCP}</li> <li>Enable APIPA: \u2718</li> </ul> </li> <li>NetBIOS (Wired):<ul> <li>NETBIOS/IP: \u2718</li> </ul> </li> <li>IPv6 (Wired):<ul> <li>IPv6: \u2718</li> </ul> </li> <li>Wireless (Personal):<ul> <li>Wireless Network Name (SSID): {RANDOM HASH}</li> <li>Authentication Method: WPA/WPA2-PSK</li> <li>Encryption Mode: TKIP-AES</li> <li>Passphrase: {HASH 63 CHARACTERS}</li> </ul> </li> </ul> <ul> <li>IPv4 Filter:<ul> <li>Use IP Filtering Service: \u2714</li> <li>Accept the following Addresses: \u2714 (Whitelist allowed IPs)</li> </ul> </li> </ul> <ul> <li>Status:<ul> <li>Automatic Refresh: \u2718</li> <li>Web Langauge: Auto</li> </ul> </li> <li>Sleep Time: 1 minute</li> <li>Auto Power Off: 1 hour</li> <li>Volume:<ul> <li>Ring: \u2718</li> <li>Beep: \u2718</li> <li>Speaker: \u2718</li> </ul> </li> <li>Panel:<ul> <li>Backlight: Dark</li> <li>Dim Timer: 30 secs</li> </ul> </li> <li>Replace Toner:<ul> <li>Stop: \u2714</li> </ul> </li> </ul> <ul> <li>Eco Mode: \u2718</li> <li>Toner Save: \u2718</li> <li>Quiet Mode: \u2718</li> <li>Continue Mode: Auto</li> <li>Tray:<ul> <li>Check Size: \u2714</li> </ul> </li> <li>2-sided:<ul> <li>2-sided print: Long Edge</li> <li>Single Image: 2-sided Feed</li> </ul> </li> </ul> <ul> <li>Scan File Name:<ul> <li>File Name Style: Date_Name_Counter</li> <li>If a file with the same name already exists overwrite it: \u2718</li> <li>Date: yyyy/MM/dd</li> <li>time: \u2714</li> <li>Counter: Continuous</li> </ul> </li> <li>Scan from PC:<ul> <li>Pull Scan: \u2714</li> </ul> </li> </ul> <p>Warning</p> <p>SNMP v1/2 must be enabled for scanner to be detected across subnets. Password limit is 16 characters.</p> Password Context auth authNoPriv privacy authPriv context name authNoPriv"},{"location":"printing/linux/","title":"Linux","text":""},{"location":"printing/linux/#linux","title":"Linux","text":""},{"location":"printing/linux/#install-packages","title":"Install Packages","text":"ManjaroDebian <pre><code>pamac install manjaro-printer xsane colord-sane\npamac install brother-mfc-l2750dw brscan4 brscan-skey</code></pre> <p>Debian packages are here.</p>"},{"location":"printing/linux/#enable-cups","title":"Enable CUPS","text":"<pre><code>sudo systemctl enable cups\nsudo systemctl restart --now cups</code></pre>"},{"location":"printing/linux/#add-printer","title":"Add Printer","text":"<p>Tip</p> <p>Verify correct installation by checking the printing resolution which should allow up to 1200dpi.</p> <p>\u2318 \u2794 System Settings \u2794 Printers \u2794 Add Printer</p> <ul> <li>Manual URI: https://{HOST}/ipp/port1<ul> <li>Choose the driver from the list: brother \u203a MFCL2750DW for CUPS<ul> <li>Name: {PRINTER NAME}</li> <li>Name: {PRINTER DESCRIPTION}</li> <li>Share this printer: \u2718</li> </ul> </li> </ul> </li> </ul>"},{"location":"printing/linux/#add-scanner","title":"Add Scanner","text":"<p>Scanner device is added using the brother utility through xsane.</p> <pre><code># Scanning uses TCP port 54921. Max scanning resolution is 1200x1200dpi.\nbrsaneconfig4 -a name=scany model=MFC-L2750DW ip={IP}</code></pre>"},{"location":"printing/linux/#gimp","title":"GIMP","text":"<p>GIMP can be used to scan and export images/PDF's as well. Preferred.</p> ManjaroDebian <pre><code>pamac install colord-sane xsane gimp</code></pre> <pre><code>apt install colord-sane sane-utils xsane gimp</code></pre> <p>File \u2794 Create \u2794 Xsane: Brother{#}:net{#};dev{#}</p> <p>Verify scanning by acquiring a preview from the main xsane window that opens. This may pop under other windows or on different monitors based on GIMP configuration.</p>"},{"location":"printing/linux/#gscan2pdf","title":"gscan2pdf","text":"<p>Utility for processing scans alternative to GIMP.</p> <p>gscan will scan but sometimes it will appear 'black' in the preview. Just save the PDF, it will be saved correctly.</p> ManjaroDebian <pre><code># Install all dependencies.\npamac install gscan2pdf tesseract-data-eng</code></pre> <pre><code>apt install gscan2pdf</code></pre> <p>ctrl + g</p> <p>Verify scanning by refreshing devices, running a scan, and saving it.</p>"},{"location":"printing/linux/#web-services-device-scanner","title":"Web Services Device (Scanner)","text":"<p>Web services may be used to connect the scanner, which is the same method that Windows uses.</p> ManjaroDebian <pre><code>pamac install sane-airscan</code></pre> <pre><code>apt install sane-airscan</code></pre> <p>/etc/sane.d/airscan.conf</p> <p>0644 root:root</p> <pre><code>'Brother MFC-L2750DW' = http://{IP}/WebServices/Device</code></pre>"},{"location":"printing/windows/","title":"Windows","text":""},{"location":"printing/windows/#windows","title":"Windows","text":"<p>Minimal installation to prevent software bloat. Driver Downloads.</p>"},{"location":"printing/windows/#manual-install","title":"Manual Install","text":"<p>Recommended. This will install the printer/scanner via the print management console using only drivers and basic scanning software. Also applies to adding printer across subnets. Requires SNMP and WebServices to be enabled.</p>"},{"location":"printing/windows/#enable-internet-printing-client","title":"Enable Internet Printing Client","text":"<p>\u2318 \u2794 Settings \u2794 Manage Optional Features \u2794 More Windows Features \u2794 Print and Document Services</p> <ul> <li>Internet Printing Client: \u2714</li> </ul>"},{"location":"printing/windows/#add-printer","title":"Add Printer","text":"<p>\u2318 \u2794 run \u2794 PrintManagement.msc \u2794 Print Servers \u2794 (local) \u2794 Printers \u2794 Add Printer \u2794 Add a TCP/IP or Web Services Printer by IP Address or Hostname</p> <ul> <li>Type of device: web services printer</li> <li>Host name or IP address: http://{IP}/WebServices/Device</li> </ul>"},{"location":"printing/windows/#update-driver","title":"Update Driver","text":"<p>Info</p> <p>Requires Printer Driver &amp; Scanner Driver for Local Connection extracted.</p> <p>\u2318 \u2794 run \u2794 PrintManagement.msc \u2794 Print Servers \u2794 (local) \u2794 Printers \u2794 Brother \u2794 RMB \u2794 Properties \u2794 Advanced \u2794 New Driver</p> <ul> <li>Driver: Have Disk</li> </ul>"},{"location":"printing/windows/#remove-generic-driver","title":"Remove Generic Driver","text":"<p>\u2318 \u2794 run \u2794 PrintManagement.msc \u2794 Print Servers \u2794 (local) \u2794 Drivers \u2794 Brother Laser Type1 Class Driver \u2794 RMB \u2794 Delete</p>"},{"location":"printing/windows/#iprint-scan","title":"iPrint &amp; Scan","text":"<p>Enables all scanning options when using the scanning feature.</p> <p>Info</p> <p>Requires Brother iPrint&amp;Scan extracted.</p>"},{"location":"printing/windows/#disable-analytics-reporting","title":"Disable Analytics Reporting","text":"<p>\u2318 \u2794 iPrint &amp; Scan \u2794 Settings \u2794 Product Information</p> <ul> <li>Send information: \u2718</li> <li>Check for software updates: \u2718</li> </ul> <p>Read the disable wording carefully.</p>"},{"location":"printing/windows/#disable-report-sharing","title":"Disable Report Sharing","text":"<p>\u2318 \u2794 iPrint &amp; Scan \u2794 {PRINTER} \u2794 Brother Analytics</p> <ul> <li>Configure: \u2718</li> </ul> <p>Read the disable wording carefully.</p>"},{"location":"printing/windows/#full-install","title":"Full Install","text":"<p>Danger</p> <p>Not Recommended. Installs all additional software and requires SNMP with the device on the local subnet to install correctly. WebServices must be enabled.</p> <p>Enabling SNMP on the printer exposes vulnerabilities which must be mitigated. Allow only access to devices that need it.</p> <p>Info</p> <p>Requires Full Driver &amp; Software Package.</p>"},{"location":"printing/windows/#configure-printer","title":"Configure Printer","text":"<p>Printer WebUI \u2794 Network \u2794 Protocol \u2794 SNMP \u2794 Advanced Settings</p> <ul> <li>SNMPv3 read-write access and v1/v2c read-only access: \u2714</li> <li>User Name: {RANDOM HASH}</li> <li>Key Type: {PASS}</li> <li>Authentication Method: SHA1</li> <li>Authentication Password: {16 CHARACTERS}</li> <li>Privacy Password: {16 CHARACTERS}</li> <li>Context Name: authNoPriv</li> </ul>"},{"location":"printing/windows/#install-software","title":"Install Software","text":"<ul> <li>Full software/driver package.</li> <li>Ethernet.</li> <li>Select machine (requires snmpv1/2 enabled).</li> <li>CUSTOM installation:<ul> <li>Printer Driver</li> <li>Scanner Driver</li> <li>PS Driver</li> <li>Brother iPrint &amp; Scan without desktop icon.</li> </ul> </li> <li>Additional software:<ul> <li>do not install paperport.</li> </ul> </li> <li>Additional options:<ul> <li>Brother Product Research and Support Program:</li> <li>Customize: disable</li> </ul> </li> </ul>"},{"location":"printing/windows/#add-printer_1","title":"Add Printer","text":"<p>\u2318 \u2794 Settings \u2794 Printers \u2794 Add a printer or scanner</p> <p>Printer should be auto detected.</p>"},{"location":"printing/windows/#controlcenter4","title":"ControlCenter4","text":"<p>Advanced post-scanning options. Generally this can be done by other applications. Not recommended.</p> <p>Info</p> <p>Requires Full Driver &amp; Software Package and ControlCenter4 updater tool. Do not install.</p> <ol> <li>Extract packages.</li> <li>Manually install from extracted package: Msi/ControlCenter4.msi.</li> <li>Run ControlCenter4 Updater.</li> <li>Reboot (required to launch).</li> </ol> <p>Set Preferences</p> <p>\u2318 \u2794 Taskbar \u2794 ControlCenter4 \u2794 RMB \u2794 Preferences</p> <ul> <li>Start ControlCenter on computer startup: \u2714</li> </ul> <p>This needs to be left enabled otherwise cannot restart - manage through   TaskManager.</p> <ul> <li>Send Information: \u2718</li> </ul> <p>Disable Auto launch Services</p> <p>\u2318 \u2794 Taskbar \u2794 TaskManager \u2794 Startup</p> <ul> <li>TwDsUiLaunch.exe: \u2718</li> <li>ControlCenter Launcher: \u2718</li> </ul> <p>Re-nable and reboot when control center needs to be used.</p>"},{"location":"printing/windows/#validate-install","title":"Validate Install","text":"<p>\u2318 \u2794 Settings \u2794 Printers \u2794 Brother MFC-L2750DW \u2794 manage</p> <p>Both printer and scanner will be listed in the dropdown.</p> <p>printer (dropdown) \u2794 printer properties: Should open a window with a blue Brother bar.</p> <p>\u2318 \u2794 iPrint &amp; Scan \u2794 Scan \u2794 1200dpi</p> <p>Properly installed scanner will allow &gt; 300dpi scanning and show all settings.</p>"},{"location":"printing/windows/#complete-uninstall","title":"Complete Uninstall","text":"<p>Use the following to clean a system if brother utilities were installed and need to be removed.</p> <p>Info</p> <p>Requires Uninstall Tools downloaded and run.</p>"},{"location":"printing/windows/#remove-driver-with-uninstall","title":"Remove driver with uninstall","text":"<p>\u2318 \u2794 RMB \u2794 device Manager</p> <ul> <li>Printer: brother*</li> <li>Imaging Devices: brother*</li> <li>WSD Print Device: brother*</li> </ul>"},{"location":"printing/windows/#remove-printers","title":"Remove Printers","text":"<p>\u2318 \u2794 Settings -&gt; Printers</p> <ul> <li>brother</li> <li>paperport image printer</li> </ul>"},{"location":"printing/windows/#uninstall-programs","title":"Uninstall Programs","text":"<p>\u2318 \u2794 settings -&gt; Programs</p> <ul> <li>nuance*</li> <li>brother*</li> <li>paperport*</li> <li>httptousb*</li> <li>(look at related installs on the same date)</li> </ul>"},{"location":"printing/windows/#confirm-services-disabled-removed","title":"Confirm Services Disabled / Removed","text":"<p>Taskbar \u2794 RMB \u2794 Task Manager</p> <ul> <li>PaperPort Scan Manager</li> <li>Nuance Imaging Scanner TWAIN Client</li> <li>PDFProFiltSrvPP (PDFPro IFilter Service)</li> <li>Brother MFC Windows Software Standard Debug Log Receive Process</li> <li>agent.exe</li> <li>softwareupdatenotificationservice</li> </ul>"},{"location":"printing/windows/#delete-files-from-disk","title":"Delete Files From Disk","text":"<p>Note</p> <p>If you cannot delete BrBFLogl.dll, ensure it isn't in use with Process Explorer (Find \u2794 Find Handle or DLL) and search for it.</p> <p>Force unload dll </p><pre><code># Force unload dll (run as administrator)\nRegsvr32 /u /s c:\\Program Files (x86)\\brother\\AppLogLib\\BrBFLogl.dll</code></pre><p></p> <p>Then delete normally.</p> <ol> <li>c:\\Program Files (x86)\\brother</li> <li>c:\\Program Files (x86)\\ControlCenter4*</li> <li>c:\\Program Files (x86)\\browny02</li> <li>\u2318 \u2794 run \u2794 cleanmgr.exe (Disk Cleanup)<ul> <li>Cleanup system files.</li> <li>Clean all files.</li> </ul> </li> <li>\u2318 \u2794 run \u2794 PrintManagement.msc \u2794 Print Servers \u2794 (local) \u2794 Drivers \u2794    Brother* \u2794 RMB \u2794 Delete</li> </ol> <p>Reboot to ensure memory is unloaded.</p>"},{"location":"scripts/ansible/","title":"Ansible","text":""},{"location":"scripts/ansible/#ansible","title":"Ansible","text":"<p>Development documentation located at https://r-pufky.github.io/ansible_collection_docs.</p> <p>Roles are self-documented: https://github.com/r-pufky/ansible_*.</p>"},{"location":"scripts/ansible/#vault","title":"Vault","text":"<p>Vault is the built in encryption store for Ansible. GPG (and security key based GPG keys) can be used to encrypt ansible data, enabling ansible deployments with security key touches.</p>"},{"location":"scripts/ansible/#generate-a-random-vault-password-to-use","title":"Generate a random vault password to use","text":"<pre><code>pwgen -n 71 -C | head -n1 | gpg --armor --recipient {GPGID} -e -o ansible.gpg\n\n# Re-key existing vault data with new key if needed.\ngrep -rl '^$ANSIBLE_VAULT.*' . | xargs -t ansible-vault rekey</code></pre>"},{"location":"scripts/ansible/#create-script-to-decrypt-the-password-for-use","title":"Create script to decrypt the password for use","text":"<p>vault-gpg</p> <p>0755 {USER}:{USER}</p> <pre><code>#!/bin/sh\n#\n# See: https://disjoint.ca/til/2016/12/14/encrypting-the-ansible-vault-passphrase-using-gpg/\n#      https://www.cloudsavvyit.com/3902/how-to-use-ansible-vault-to-store-secret-keys/\n#\n# pwgen -n 71 -C | head -n1 | gpg --armor --recipient {GPG ID} -e -o ansible.gpg\n#\ngpg --batch --use-agent --decrypt ../cfg/ansible/ansible.gpg</code></pre> <p>ansible.cfg</p> <p>0644 {USER}:{USER}</p> <pre><code># If set, configures the path to the Vault password file as an alternative to\n# specifying --vault-password-file on the command line. This can also be\n# an executable script that returns the vault password to stdout.\n#\nvault_password_file = vault-gpg</code></pre>"},{"location":"scripts/ansible/#reference","title":"Reference<sup>1</sup><sup>2</sup>","text":"<ol> <li> <p>https://www.cloudsavvyit.com/3902/how-to-use-ansible-vault-to-store-secret-keys \u21a9</p> </li> <li> <p>https://disjoint.ca/til/2016/12/14/encrypting-the-ansible-vault-passphrase-using-gpg \u21a9</p> </li> </ol>"},{"location":"scripts/copying_data/","title":"Copying Data","text":""},{"location":"scripts/copying_data/#copying-data","title":"Copying Data","text":""},{"location":"scripts/copying_data/#copy-data-with-verification","title":"Copy data with verification","text":"<pre><code>apt install md5deep rsync\n\n# -a archive (-rlptgoD).\n# -v verbose.\n# -x don't cross FS boundaries.\n# -h human readable.\n# -H preserve hard links.\n# -A preserve ACL's.\n# -X preserve extended attributes.\n# --progress optionally.\nrsync -avxhHAX {DIR} /Y</code></pre>"},{"location":"scripts/copying_data/#create-hashfile-of-all-original-files-and-sort","title":"Create Hashfile of All Original Files and Sort","text":"<pre><code># -l use relative file paths.\n# -r recursive.\n# -e display progress indicator (not written to hashfile).\nmd5deep -l -r -e {DIR} | sort &gt; /tmp/{DIR}.md5</code></pre>"},{"location":"scripts/copying_data/#verify-copied-files-with-rsync","title":"Verify copied files with rsync","text":"<pre><code># Use MD5 sums to detect file differences.\nmd5deep -l -r -e {DIR} | sort &gt; /tmp/{DIR}2.md5\nmd5sum /tmp/{DIR}.md5 /tmp/{DIR}2.md5\ndiff /tmp/{DIR}.md5 /tmp/{DIR}2.md5</code></pre>"},{"location":"scripts/copying_data/#verifying-copied-files-across-oss-are-accurate","title":"Verifying Copied Files Across OS\u2019s are Accurate","text":"<pre><code># This removes path differences and only compares source hashes to destination\n# hashes. Only non-matching lines (e.g. those hashes that don\u2019t match) should\n# be printed.\ncut -f 1 -d \u2018 \u2018 {SOURCE}.md5 &gt; {SOURCE}-hash-only.md5\ngrep -v -f {SOURCE}-hash-only.md5 {TARGET}.md5</code></pre>"},{"location":"scripts/copying_data/#reference","title":"Reference<sup>1</sup><sup>2</sup><sup>3</sup><sup>4</sup>","text":"<ol> <li> <p>http://md5deep.sourceforge.net/start-md5deep.html#basic \u21a9</p> </li> <li> <p>https://stackoverflow.com/questions/606739/comparison-between-two-big-directories \u21a9</p> </li> <li> <p>https://superuser.com/questions/307541/copy-entire-file-system-hierarchy-from-one-drive-to-another \u21a9</p> </li> <li> <p>https://www.evbackup.com/support/rsync-arguments \u21a9</p> </li> </ol>"},{"location":"scripts/steam/","title":"Steam","text":""},{"location":"scripts/steam/#steam","title":"Steam","text":""},{"location":"scripts/steam/#install-old-game-version","title":"Install Old Game Version","text":"<p>All games on steam are versioned and stored in a repository - this provides a mechanism to install an old version for a game.</p> <ol> <li>Find your game on the Steam DB.</li> <li> <p>Locate the manifests for all versions of a game by navigating to a specific     game version manifest:</p> <p>Game \u2794 APPID \u2794 Packages \u2794 SUBID \u2794 Depots \u2794 Depot ID \u2794 Manifests</p> <p>Example manifest list.</p> </li> <li> <p>Determine the MANIFESTID to use.</p> <p>Example manifest.</p> </li> <li> <p>Open the Steam console from browser:     steam://nav/console. Steam Client Boot strapper should launch.</p> </li> <li> <p>Download old version:</p> <pre><code># download_depot &lt;AppID&gt; &lt;DepotID&gt; &lt;ManifestID&gt;\ndownload_depot 239140 335819 23871677621866113</code></pre> <ul> <li>AppID is found on the main game listing.</li> <li>DepotID &amp; ManifestID found on the manifest listing.</li> <li>On completion the location of the download will be shown.</li> <li>Downloaded to Steam\\steamapps\\content\\app_{APPID}\\depot_{DEPOTID}</li> </ul> </li> <li> <p>Copy the original game files that will be overwritten to another location or    back them up.</p> </li> <li>Copy the old version files into the game directory.</li> <li>Disable the Internet connection before starting the game. Steam will    typically force-update on launch. After launching the Internet connection    can be restored.</li> </ol>"},{"location":"scripts/steam/#references","title":"References<sup>1</sup>","text":"<ol> <li> <p>https://steamcommunity.com/sharedfiles/filedetails/?id=889624474 \u21a9</p> </li> </ol>"},{"location":"scripts/video_tools/","title":"Video Tools","text":""},{"location":"scripts/video_tools/#video-tools","title":"Video Tools","text":"<p>Shell scripts and utilities for editing/converting videos.</p> <pre><code>apt install mencoder ffmpeg mkvtoolnix imagemagick avconv libavcodec-extra-53 libav-tools</code></pre>"},{"location":"scripts/video_tools/#determine-length-in-seconds-of-a-given-video-file","title":"Determine length in seconds of a given video file","text":"<pre><code>ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 \"$1\" | cut -d\\. -f1</code></pre>"},{"location":"scripts/video_tools/#remove-first-x-seconds-from-video-file","title":"Remove first X seconds from video file","text":"<pre><code>ffmpeg -i example.mp4 -ss 00:00:04.000 -acodec copy -vcodec copy -map_metadata -1 example.mp4</code></pre>"},{"location":"scripts/video_tools/#split-mkv-into-smaller-mkvs-based-on-timestamps","title":"Split MKV into Smaller MKV\u2019s Based on Timestamps","text":"<pre><code>mkvmerge -o out.file --split timecodes:00:42:06.000,01:22:20.000 in.file</code></pre>"},{"location":"scripts/video_tools/#cut-and-direct-copy-video-to-new-file","title":"Cut and Direct Copy Video to New File","text":"<pre><code>mencoder [-ss 00:00:00] -endpos 00:15:00 -oac copy -ovc copy in.file -o out.file\nffmpeg -i input.wmv -ss 00:00:00.000 -t 00:15:00.000 -acodec copy -vcodec copy output.wmv</code></pre>"},{"location":"scripts/video_tools/#strip-metadata","title":"Strip metadata","text":"<pre><code>Ffmpeg -map_metadata -1  # Only metadata that is not required.</code></pre>"},{"location":"scripts/video_tools/#generate-copies-at-one-second-intervals-for-bad-encodes","title":"Generate Copies at One Second Intervals (For Bad Encodes)","text":"<pre><code>for x in `seq -w 5 15`;do mencoder -oac copy -ovc copy -ss 11:${x} -endpos 14:00 in.file -o out-${x}.file;done</code></pre>"},{"location":"scripts/video_tools/#merge-video-files-into-a-single-file","title":"Merge Video Files into a Single File","text":"<pre><code>mencoder -oac copy -ovc copy [-noskip] [hr-edl-seek] in1.file in2.file inX.file -o out.file</code></pre>"},{"location":"scripts/video_tools/#insert-a-video-into-a-mkv-container","title":"Insert a Video into a MKV Container","text":"<pre><code>mkvmerge -o out.mkv in.file  # No Video Conversion -- Preferred.</code></pre>"},{"location":"scripts/video_tools/#insert-and-convert-a-video-into-a-mkv-container","title":"Insert and Convert a Video into a MKV Container","text":"<pre><code># Re-encodes then inserts.\nmencoder in.file -o out.mkv -of lavf -oac copy -ovc lavc</code></pre>"},{"location":"scripts/video_tools/#insert-and-convert-videos-in-a-directory-to-mkv-containers","title":"Insert and Convert Videos in a Directory to MKV Containers","text":"<pre><code>find . -name \"*.flv\" -exec mencoder {} -o {}.mkv -of lavf -oac copy -ovc lavc \\;</code></pre>"},{"location":"scripts/video_tools/#convert-entire-directory-to-mkv-containers","title":"Convert Entire Directory to MKV Containers","text":"<pre><code>find . -type f -exec mkvmerge -o {}.mkv {} \\;</code></pre>"},{"location":"scripts/video_tools/#convert-animated-gif-to-avimpg","title":"Convert Animated GIF to AVI/MPG","text":"<pre><code>convert image.gif output%05d.png\nconvert -delay 12 -quality 100 output*png final_movie.mpg\nffmpeg -r 9 -i output%05d.png final_movie.avi</code></pre>"},{"location":"scripts/video_tools/#combine-multiple-video-parts-into-one-video","title":"Combine multiple video parts into one video","text":"<pre><code>mkvmerge -o out.mkv 1.file + 2.file + 3.file + 4.file + 5.file</code></pre>"},{"location":"scripts/video_tools/#rip-mp3-audio-from-flv-file","title":"Rip MP3 Audio from FLV File","text":"<pre><code>avconv -i {FLV FILE} output.mp3</code></pre>"},{"location":"scripts/video_tools/#convert-flv-to-mkv-container","title":"Convert FLV to MKV Container","text":"<pre><code>ffmpeg -i {FLV FILE} -vcodec copy -acodec copy out.mkv</code></pre>"},{"location":"scripts/video_tools/#convert-webm-to-mkv","title":"Convert webm to mkv","text":"<pre><code>ffmpeg -i your_input_filename.webm -qscale 0 your_outfile_name.mkv</code></pre>"},{"location":"scripts/video_tools/#use-ffmpeg-to-download-and-stitch-stream-together","title":"Use ffmpeg to download and stitch stream together","text":"<pre><code>ffmpeg -i https://{URI}.m3u8 -c:v copy -c:a copy -f mpegts output.ts</code></pre>"},{"location":"scripts/video_tools/#ffmpeg-convert-minimizing-quality-loss","title":"ffmpeg Convert Minimizing Quality Loss","text":"<p>Convert file stripping metadata and enabling skipping and scrubbing in video.</p> <pre><code>ffmpeg -i example.mp4 -ss 00:00:10.000 -t 00:51:29.000 -crf 15 -movflags +faststart -pix_fmt yuv420p -map_metadata -1 out.mp4</code></pre>"},{"location":"scripts/video_tools/#download-m3u8-playlist","title":"Download M3U8 Playlist","text":"<p>For videos that are stitched together in short increments, usually TS (video stream).</p> <p>Turn on developer tools (Chrome):</p> <ul> <li>\u22ee \u2794 More Tools \u2794 Developer Tools</li> <li>Load Video URL.</li> <li>Developer Tools \u2794 Network \u2794 All</li> <li>Filter by m3u8.</li> <li>Determine stream URL to use.</li> <li>RMB \u2794 Copy \u2794 Copy link address</li> </ul>"},{"location":"scripts/video_tools/#reference","title":"Reference<sup>1</sup><sup>2</sup><sup>3</sup><sup>4</sup><sup>5</sup><sup>6</sup><sup>7</sup><sup>8</sup><sup>9</sup><sup>10</sup><sup>11</sup><sup>12</sup><sup>13</sup><sup>14</sup><sup>15</sup><sup>16</sup>","text":"<ol> <li> <p>http://www.mplayerhq.hu/DOCS/HTML/en/mencoder.html \u21a9</p> </li> <li> <p>http://www.mplayerhq.hu/DOCS/HTML/en/menc-feat-selecting-codec.html \u21a9</p> </li> <li> <p>https://www.linuxquestions.org/questions/linux-general-1/how-to-merge-2-avi-together-424988/ \u21a9</p> </li> <li> <p>http://brovienas.tripod.com/mencoder_editing.html \u21a9</p> </li> <li> <p>http://www.misterhowto.com/index.php?category=Computers&amp;subcategory=Video&amp;article=trim_or_split_with_mencoder \u21a9</p> </li> <li> <p>https://www.joeldare.com/wiki/video:cut_video_with_ffmpeg \u21a9</p> </li> <li> <p>https://techjourney.net/convert-flash-video-flv-files-to-mpg-or-avi-and-other-media-formats/ \u21a9</p> </li> <li> <p>http://jupiter.ethz.ch/~pjt/makingMovies.html \u21a9</p> </li> <li> <p>https://stackoverflow.com/questions/3212821/animated-gif-to-avi-on-linux \u21a9</p> </li> <li> <p>https://catswhocode.com/ffmpeg-commands/ \u21a9</p> </li> <li> <p>http://www.imagemagick.org/discourse-server/viewtopic.php?f=1&amp;t=14743&amp;view=next \u21a9</p> </li> <li> <p>https://mkvtoolnix.download/doc/mkvmerge.html \u21a9</p> </li> <li> <p>https://askubuntu.com/questions/637074/how-to-merge-multiple-more-than-two-videos-on-ubuntu \u21a9</p> </li> <li> <p>https://askubuntu.com/questions/59383/extract-part-of-a-video-with-a-one-line-command \u21a9</p> </li> <li> <p>https://superuser.com/questions/542989/getting-the-video-frame-number-in-vlc \u21a9</p> </li> <li> <p>https://www.linuxuprising.com/2018/07/how-to-stream-netflix-videos-at-1080p.html \u21a9</p> </li> </ol>"},{"location":"scripts/wiping_data/","title":"Wiping Data","text":""},{"location":"scripts/wiping_data/#wiping-data","title":"Wiping Data","text":"<p>Securely delete data.</p>"},{"location":"scripts/wiping_data/#shred","title":"shred","text":"<p>Tool to overwrite single file contents and optionally delete files.</p> <pre><code># 35 pass random data, zero then remove file.\nshred --iterations=35 --verbose --zero --remove {FILE}\n\n# Recursively overwrite file data.\nfind . -type f -exec shred --iterations=35 --verbose --zero --remove {} \\;</code></pre>"},{"location":"scripts/wiping_data/#wipe","title":"wipe","text":"<p>Tool to securely delete files and block devices.</p> <pre><code>apt install wipe\n\n# Recursively delete files, 35 pass random data.\nwipe -r -c -f -Q 35 {FILE OR DIR}\n\n# Wipe a block device, 35 pass random data.\nwipe -k -Q 35 {BLOCK DEVICE}</code></pre>"},{"location":"scripts/wiping_data/#dd","title":"dd","text":"<p>Using dd to zero disks. Good for testing/setup of new drives.</p> <pre><code># Writing all Zero\u2019s to Drive.\ndd if=/dev/zero of=/dev/sdX bs=1M &amp;\n\n# Writing all One\u2019s to Drive.\ntr '\\000' '\\377' &lt; /dev/zero | dd of=/dev/sdX bs=1M &amp;\n\n# Checking Status on DD.\nps -ef | grep dd\nkill -USR1 {PID}</code></pre>"},{"location":"scripts/wiping_data/#dban-boot-nuke","title":"DBAN Boot &amp; Nuke","text":"<p>Live ISO image specifically for data destruction.</p> <p>Download and run DoD 3 pass.</p>"},{"location":"scripts/wiping_data/#reference","title":"Reference<sup>1</sup><sup>2</sup><sup>3</sup>","text":"<ol> <li> <p>https://how-to.fandom.com/wiki/How_to_wipe_a_hard_drive_clean_in_Linux \u21a9</p> </li> <li> <p>https://www.commandlinefu.com/commands/view/6483/fill-a-hard-drive-with-ones-like-zero-fill-but-the-opposite- \u21a9</p> </li> <li> <p>https://www.vidarholen.net/~vidar/overwriting_hard_drive_data.pdf \u21a9</p> </li> </ol>"},{"location":"scripts/youtube/","title":"Youtube","text":""},{"location":"scripts/youtube/#youtube","title":"Youtube","text":"<p>Download and extract data from youtube videos. yt-dlp is an actively maintained fork of the defunct yt-dl.</p>"},{"location":"scripts/youtube/#install","title":"Install","text":"LinuxWindows <pre><code>curl -L https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp -o /usr/local/bin/yt-dlp\nchmod a+rx /usr/local/bin/yt-dlp\n\nyt-dlp --update</code></pre> <pre><code># libav-tools may be required: Copy all dll/exe files from\n# libav-tools/win64/usr/bin to location of yt-dlp.exe.\n#\n#   http://builds.libav.org/windows/release-gpl\nwinget install yt-dlp</code></pre>"},{"location":"scripts/youtube/#extract-320kbps-mp3-audio-from-video","title":"Extract 320kbps MP3 Audio From Video","text":"<pre><code>yt-dlp --extract-audio --audio-format mp3 --audio-quality 320K --keep-video --add-metadata {URL}</code></pre>"},{"location":"scripts/youtube/#extract-flac-audio-from-video","title":"Extract FLAC Audio From Video.","text":"<pre><code>yt-dlp --extract-audio --audio-format flac --audio-quality 0 --add-metadata {URL}</code></pre>"},{"location":"scripts/youtube/#list-all-formats-for-a-video-and-select-the-best-ones","title":"List all formats for a video and select the best ones.","text":"<pre><code>yt-dlp -F {URL}\nyt-dlp -f ###+### {URL}</code></pre>"},{"location":"scripts/youtube/#download-only-the-1080p-videoaudio-stream-from-a-video","title":"Download only the 1080p video/audio stream from a video.","text":"<pre><code>yt-dlp -f \"bestvideo[height&lt;=1080]+bestaudio/best[height&lt;=1080]\" {URL}</code></pre>"},{"location":"scripts/youtube/#download-a-playlist","title":"Download a playlist.","text":"<pre><code>yt-dlp https://youtube.com/playlist?list={PLAYLIST ID} --yes-playlist</code></pre>"},{"location":"scripts/youtube/#track-downloaded-videos-for-archiving","title":"Track Downloaded Videos for Archiving.","text":"<pre><code># This downloads only videos not listed in file and adds any downloaded videos\n# to the given file.\nyt-dlp --download-archive {FILE}</code></pre>"},{"location":"scripts/youtube/#azure-media-services","title":"Azure Media Services","text":"<p>These can be downloaded by forcing a m3u8 stream and downloading. This works for MS streaming videos and other services using Azure Media Service backends.</p> <ol> <li>ctrl + shift + i u2794 network \u2794 all</li> <li>Load the video/stream page.</li> <li>Locate the manifest(format=...) URI in Chrome Dev Tools.</li> <li>RMB \u2794 copy \u2794 copy link address</li> <li>Use with yt-dlp changing manifest portion of the URI to    manifest(format=m3u8-aapl-v3)</li> </ol>"},{"location":"scripts/youtube/#references","title":"References<sup>1</sup><sup>2</sup><sup>3</sup><sup>4</sup><sup>5</sup><sup>6</sup>","text":"<ol> <li> <p>https://github.com/ytdl-org/yt-dlp/releases \u21a9</p> </li> <li> <p>https://rg3.github.io/yt-dlp/download.html \u21a9</p> </li> <li> <p>http://linuxaria.com/recensioni/how-to-download-youtube-video-or-audio-tracks-from-the-linux-terminal \u21a9</p> </li> <li> <p>https://www.linuxjournal.com/content/grabbing-your-music-youtube-do-it-your-way \u21a9</p> </li> <li> <p>https://askubuntu.com/questions/323944/convert-webm-to-other-formats \u21a9</p> </li> <li> <p>https://anduin.aiursoft.com/post/2020/5/15/download-any-azure-media-service-video-or-live-stream-with-ffmpeg \u21a9</p> </li> </ol>"},{"location":"service/","title":"Services","text":""},{"location":"service/#services","title":"Services","text":"<p>Info</p> <p>A majority of services are now managed via ansible collections. See specific service for the collection to use.</p>"},{"location":"service/bluebubbles/","title":"BlueBubbles","text":""},{"location":"service/bluebubbles/#bluebubbles","title":"BlueBubbles","text":"<p>Opensource iMessages.</p>"},{"location":"service/bluebubbles/#setup","title":"Setup","text":"<p>VM's may be used but are fragile and complicated. It is better to use actual hardware to prevent flagging your Apple account.</p> <p>Install Chrome.</p> <p>Install BlueBubbles.</p>"},{"location":"service/bluebubbles/#installation-notes","title":"Installation Notes","text":"<p>Follow the instructions on the site and Disable SIP.</p> <p>BlueBubbles \u2794 Settings</p> <ul> <li>Connection Settings:<ul> <li>Messages Private API: \u2714</li> <li>FaceTime Private API: \u2714</li> <li>FaceTime Calling: \u2714</li> </ul> </li> <li>Features:<ul> <li>Open FindMy App on Startup: \u2714</li> <li>Keep MacOS Awake: \u2714</li> <li>Auto Start Method: Launch Agent</li> <li>Start Minimized: \u2714</li> <li>Show Dock Badge: \u2714</li> <li>Hide Dock Icon: \u2714</li> </ul> </li> <li>Update Settings:<ul> <li>Check for Updates on Startup: \u2714</li> <li>Use OLED Black Dark Mode: \u2714</li> </ul> </li> </ul> <p>\u2318 \u2794 System Settings \u2794 Users &amp; Groups</p> <ul> <li>Automatically log in as: {USER}</li> </ul>"},{"location":"service/bluebubbles/#enable-ssh","title":"Enable SSH","text":"<p>\u2318 \u2794 System Settings \u2794 Sharing \u2794 Remote Login</p> <ul> <li>Remote Login: \u2714<ul> <li>Allow full disk access for remote users: \u2714</li> <li>Allow access for: {USER}</li> </ul> </li> </ul> <p>/etc/ssh/sshd_config</p> <p>0644 root:root</p> <pre><code># Setup authorized_keys before disabling passwords.\nPasswordAuthentication no\n\n# This option appears only in new versions of macOS\nKbdInteractiveAuthentication no\n\n# This option appears only in old versions of macOS\nChallengeResponseAuthentication no</code></pre>"},{"location":"service/dropbear/","title":"Dropbear","text":""},{"location":"service/dropbear/#dropbear","title":"Dropbear","text":"<p>Remote unlock encrypted root filesystems over SSH on boot.</p> <p>Migrated to ansible collection</p> <p>Use r_pufky.deb.dropbear.</p> <p>Warning</p> <p>Most systems do not encrypt /boot and therefore dropbear keys should be considered compromised/untrusted; use separate keys when using dropbear!</p> <p>Tip</p> <ul> <li>Dropbear host identification keys are a special format, not a standard   SSH keypair.</li> <li>Dropbear host keys are binary files and cannot be stored encrypted in the   {host,group}_vars directory. Ansible will try to automatically decrypt   this file and fail due to UTF-8 encoding issues. Storing within ansible   but outside of {host,group}_vars to prevent decryption until the binary   file is copied, wherein the decryption happens correctly.</li> <li>Remote Unlock using the dropbear key ssh -i ~/.ssh/dropbear   root@remote_host.</li> </ul> <p>See Wireguard to enable wireguard service on boot for fully encrypted remote boot root FS unlock.</p>"},{"location":"service/dropbear/#reference","title":"Reference<sup>1</sup>","text":"<ol> <li> <p>https://linuxconfig.org/how-to-install-and-configure-dropbear-on-linux \u21a9</p> </li> </ol>"},{"location":"service/imapsync/","title":"imapsync","text":""},{"location":"service/imapsync/#imapsync","title":"imapsync","text":"<p>Sync gmail to local imap server.</p>"},{"location":"service/imapsync/#setup","title":"Setup","text":"<pre><code>git clone https://github.com/imapsync/imapsync\n\n# Dependency / Pre-requisite list.\nimapsync/INSTALL.d/prerequisities_imapsync\n\n# Perl dependencies\napt install libio-tee-perl libmail-imapclient-perl libterm-readkey-perl libunicode-string-perl libcrypt-openssl-rsa-perl libdata-uniqid-perl libjson-perl liblwp-online-perl libreadonly-perl libfile-copy-recursive-perl libio-socket-inet6-perl libsys-meminfo-perl libregexp-common-perl libfile-tail-perl libauthen-ntlm-perl libcgi-pm-perl libclass-load-perl libcrypt-ssleay-perl libdigest-hmac-perl libdist-checkconflicts-perl libencode-imaputf7-perl libio-compress-perl libio-socket-ssl-perl libmodule-scandeps-perl libnet-dbus-perl libnet-ssleay-perl libpar-packer-perl libtest-fatal-perl libtest-mock-guard-perl libtest-mockobject-perl libtest-pod-perl libtest-requires-perl libtest-simple-perl liburi-perl libtest-nowarnings-perl libtest-deep-perl libtest-warn-perl libjson-webtoken-perl cpanminus make\n\n# Create password files.\ntouch .ssh/imapsync_{gmail,personal}\nchmod 0600 .ssh/imapsync_{gmail,personal}\n\n# Set gmail Application password and lockdown file.\n# https://security.google.com/settings/security/apppasswords\nchmod 0400 .ssh/imapsync_gmail\n\n# Set personal mail server password and lock file.\nchmod 0400 .ssh/imapsync_personal</code></pre>"},{"location":"service/imapsync/#test-sync","title":"Test Sync","text":"<pre><code>./imapsync --dry \\\n  --host1 imap.gmail.com --port1 993 --user1 {GMAIL EMAIL USER} \\\n    --passfile1 ~/.ssh/imapsync_gmail --ssl1 \\\n  --host2 {YOUR IMAP SERVER} --port2 993 --user2 {YOUR IMAP USER} \\\n    --passfile2 ~/.ssh/imapsync_personal --ssl2 \\\n  --subfolder2 gmail-archive --minage 30 --exitwhenover 2500000000 \\\n  --delete --expunge1</code></pre> <ul> <li>This will sync mail older than 30 days, and remove it from   gmail.</li> <li>Gmail has a download limit of 2.5GB a day. Will safely exit when reached.</li> <li>Ensure connections work, folders are identified, and local folder is set   properly.</li> </ul>"},{"location":"service/imapsync/#install-service","title":"Install Service","text":"<pre><code>sudo git checkout-index -a -f --prefix=/opt/imapsync/\nchmod +x /opt/imapsync/imapsync</code></pre> <p>~/bin/gmail_to_imap_sync</p> <p>0755 {USER}:{USER}</p> <pre><code>#!/bin/bash\n\n/opt/imapsync/imapsync \\\n--host1 imap.gmail.com --port1 993 --user1 {GMAIL EMAIL USER} \\\n  --passfile1 ~/.ssh/imapsync_gmail --ssl1 \\\n--host2 {YOUR IMAP SERVER} --port2 993 --user2 {YOUR IMAP USER} \\\n  --passfile2 ~/.ssh/imapsync_personal --ssl2 \\\n--subfolder2 gmail-archive --minage 30 --exitwhenover 2500000000 \\\n--delete --expunge1 \\\n--nolog &amp;&gt;/dev/null</code></pre> <pre><code># Add to local crontab to run nightly.\ncrontab -e\n&gt; * 3 * * * ~/bin/gmail_to_imap_sync</code></pre>"},{"location":"service/imapsync/#reference","title":"Reference<sup>1</sup><sup>2</sup><sup>3</sup>","text":"<ol> <li> <p>https://askubuntu.com/questions/539102/error-install-imapsync \u21a9</p> </li> <li> <p>https://en.wikipedia.org/wiki/Cron \u21a9</p> </li> <li> <p>https://blog.christosoft.de/2015/03/maildir-remove-duplicates \u21a9</p> </li> </ol>"},{"location":"service/mariadb/","title":"MariaDB","text":""},{"location":"service/mariadb/#mariadb","title":"MariaDB","text":"<p>MariaDB is an opensource relational database based on MySQL.</p> <p>Migrated to ansible collection</p> <p>Use r_pufky.srv.maria.</p>"},{"location":"service/mariadb/#creating-a-database","title":"Creating a Database","text":"<p>Create new DB user and database. </p><pre><code>mysql -u root -p\n\nCREATE USER IF NOT EXISTS '{USER}'@'{DOMAIN}' IDENTIFIED BY '{PASS}';\nCREATE DATABASE IF NOT EXISTS {DB};\n\nGRANT ALL PRIVILEGES ON {DB}.* TO '{USER}'@'{DOMAIN}';\nFLUSH PRIVILEGES;</code></pre><p></p>"},{"location":"service/mariadb/#import-a-database","title":"Import a Database","text":"<p>Import DB and set appropriate DB permissions. </p><pre><code>mysql -u {USER} -p {DATABASE} &lt; database-dump.sql\n\nALTER DATABASE {DB USER} OWNER TO {DB USER};\nGRANT ALL PRIVILEGES ON DATABASE {DB USER} TO {DB USER};</code></pre><p></p>"},{"location":"service/mariadb/#database-backup","title":"Database Backup","text":"<p>This will dump all databases, users and permissions. Remember to pull the data from the instance or the data directory. </p><pre><code>mysqldump --user=root --password --lock-tables --all-databases &gt; {DATABASES}.sql</code></pre><p></p> <p>Backup a specific database. Permissions will need to be restored with database. </p><pre><code>mysql -u root -p {DATABASE} &gt; {DATABASE}.sql</code></pre><p></p>"},{"location":"service/pihole/","title":"Pi-Hole","text":""},{"location":"service/pihole/#pi-hole","title":"Pi-Hole","text":"<p>Pi-Hole DNS Server.</p> <p>Migrated to ansible collection</p> <p>Use r_pufky.srv.pihole.</p>"},{"location":"service/pihole/#setup","title":"Setup","text":"<p>Clients will send DNS requests to Pi-Hole. Pi-Hole will either block, resolve or forward those requests to the router. The router will be able to resolve local DNS names and forward remaining unknown queries to upstream DNS servers.</p> <p>Optionally, if the router supports destination NAT, all DNS traffic will be routed directly to Pi-Hole. This catches hard-coded DNS servers that many phone apps, IoT devices, and applications use.</p> <ol> <li>Router upstream DNS servers set to 1.1.1.1, 8.8.8.8.</li> <li>Router DHCP Assigns Pi-Hole as primary DNS server for clients.</li> <li>Router uses Destination NAT - DNAT to force all DNS requests to    Pi-Hole (optional).</li> <li>Pi-Hole upstream DNS server set to router.</li> </ol>"},{"location":"service/pihole/#set-admin-password","title":"Set Admin Password","text":"<pre><code>pihole -a -p</code></pre>"},{"location":"service/roundcube/","title":"Roundcube","text":""},{"location":"service/roundcube/#roundcube","title":"Roundcube","text":""},{"location":"service/roundcube/#setup","title":"Setup","text":""},{"location":"service/roundcube/#import-roundcube-db-schema","title":"Import Roundcube DB schema","text":"<pre><code>psql -U roundcube -f SQL/postgres.initial.sql roundcube</code></pre>"},{"location":"service/roundcube/#fail2ban","title":"Fail2Ban","text":"<p>Custom filter to match roundcube log messages in syslog, with roundcube operating behind a proxy.</p> <p>/data/filter.d/mail_roundcube.conf</p> <p>0644 root:root</p> <pre><code>[INCLUDES]\n\nbefore = common.conf\n\n[Definition]\n\nprefregex = ^\\s*(\\[\\])?(%(__hostname)s\\s*(?:roundcube(?:\\[(\\d*)\\])?:)?\\s*.*(&lt;[\\w]+&gt;)? IMAP Error)?: &lt;F-CONTENT&gt;.+&lt;/F-CONTENT&gt;$\n\nfailregex = ^(?:FAILED login|Login failed) for &lt;F-USER&gt;.*&lt;/F-USER&gt; against .*X-Forwarded-For: &lt;HOST&gt;.*$\n            ^(?:&lt;[\\w]+&gt; )?Failed login for &lt;F-USER&gt;.*&lt;/F-USER&gt; against .*X-Forwarded-For: &lt;HOST&gt; .*$\n\nignoreregex =\n\njournalmatch = SYSLOG_IDENTIFIER=roundcube</code></pre> <p>/data/filter.d/mail_roundcube.conf</p> <p>0644 root:root</p> <pre><code>[mail-roundcube]\nenabled  = true\nport     = http,https\nfilter   = mail-roundcube\nlogpath  = /var/log/syslog\nbantime  = -1\nfindtime = 86400\nmaxretry = 3</code></pre>"},{"location":"service/roundcube/#reverse-proxy","title":"Reverse Proxy","text":"<p>Roundcube should be run via a Reverse Proxy, allowing you to isolate and wrap connections in SSL. See NGINX for more details. See Base Proxy Control for basic proxy configuration.</p> <p>Use the explicit Common Name (FQDN) for IMAP host URI. PHP requires certificate validation by default now; and should match the explicit FQDN on the certificate that the mail server uses. roundcube_upload_max_filesize should match the max file size defined on the mail server POSTFIX_MESSAGE_SIZE_LIMIT - accepted standard is now 25MB.</p> <p>/etc/nginx/conf.d/reverse_proxy.conf</p> <p>0644 root:root</p> <pre><code># Subdomain\nserver {\n  listen       443 ssl http2;\n  server_name  roundcube.{DOMAIN} roundcube;\n\n  location / {\n    proxy_pass http://roundcube;\n    include    /etc/nginx/conf.d/proxy-control.conf;\n  }\n}</code></pre> <p>/etc/nginx/conf.d/reverse_proxy.conf</p> <p>0644 root:root</p> <pre><code># Subpath\nserver {\n  location /roundcube/ {\n    proxy_pass http://roundcube;\n    include    /etc/nginx/conf.d/proxy-control.conf;\n  }\n}</code></pre>"},{"location":"service/roundcube/#reference","title":"Reference<sup>1</sup>","text":"<ol> <li> <p>https://github.com/roundcube/roundcubemail/wiki/FAQ \u21a9</p> </li> </ol>"},{"location":"service/ca/","title":"Certificate Authority","text":""},{"location":"service/ca/#certificate-authority","title":"Certificate Authority","text":"<p>TODO</p> <p>This section is 2 versions out of date and requires updating. General instructions remain the same though specifics may now be incorrect.</p> <p>Run your own Certificate Authority which provides authentication and authorization for services you own. An excellent reference for basic CA setup and usage is here and should be well understood before proceeding.</p> <p>This will setup a functional root CA, intermediate CA and client/server certificate signing.</p> <p>Tip</p> <p>Only minimal certificate fields are used, any actual public usage should provide all fields.</p>"},{"location":"service/ca/#reference","title":"Reference<sup>1</sup>","text":"<ol> <li> <p>https://www.openssl.org \u21a9</p> </li> </ol>"},{"location":"service/ca/certificate_revocation_list/","title":"Certificate Revocation Lists","text":""},{"location":"service/ca/certificate_revocation_list/#certificate-revocation-lists","title":"Certificate Revocation Lists","text":"<p>Certificate Revocation Lists (CRLs) are used to invalidate certificates in the wild which have been compromised. This covers server-side revocation enforcement. A CRL should include all of the CRL's up to the Root CA.</p> <p>Note</p> <p>Run these commands to regenerate the CRL's automatically with a new serial number and expiry date. Expired CRL's will lead to certificate authentication failures!</p> <pre><code># Create CRL.\nopenssl ca -config /root/ca/root/root.ca -gencrl -out /root/ca/root/crl/root.crl.pem\nopenssl ca -config /root/ca/inter/inter.ca -gencrl -out /root/ca/inter/crl/inter.crl.pem\ncat /root/ca/root/crl/root.crl.pem /root/ca/inter/crl/inter.crl.pem &gt; /root/ca/ca-chain.crl.pem\n\n# Check Current CRL Status.\nopenssl crl -in /root/ca/root/crl/root.crl.pem -noout -text\nopenssl crl -in /root/ca/inter/crl/inter.crl.pem -noout -text\nopenssl crl -in /root/ca/ca-chain.crl.pem -noout -text</code></pre>"},{"location":"service/ca/certificate_revocation_list/#revoking-certificates","title":"Revoking Certificates","text":"<p>This will prevent a compromised certificate (which is still valid) from being used.</p> <pre><code># Revoke Certificate and Update CRL.\nopenssl ca -config /root/ca/inter/inter.ca -revoke /root/ca/inter/certs/{TARGET}.cert.pem\nopenssl ca -config /root/ca/inter/inter.ca -gencrl -out /root/ca/inter/crl/inter.crl.pem\ncat /root/ca/root/crl/root.crl.pem /root/ca/inter/crl/inter.crl.pem &gt; /root/ca/ca-chain.crl.pem</code></pre> <ul> <li>The new CRL needs to be deployed to any service using the Intermediate CA.</li> <li>This can also be applied at the Root CA level to revoke intermediate CA's.</li> <li>The combined CRL needs to be re-created as well.</li> </ul>"},{"location":"service/ca/certificate_revocation_list/#reference","title":"Reference<sup>1</sup>","text":"<ol> <li> <p>https://jamielinux.com/docs/openssl-certificate-authority/certificate-revocation-lists.html \u21a9</p> </li> </ol>"},{"location":"service/ca/certificates/","title":"Certificates","text":""},{"location":"service/ca/certificates/#certificates","title":"Certificates","text":""},{"location":"service/ca/certificates/#server-certificates","title":"Server Certificates","text":"<p>Used for providing SSL connections with services / servers. The Root CA must be in the trusted Root CAs or the ca-chain deployed with clients for servers presenting SSL connections using these certificates to be validated (green lock). These certificates only have serverAuth extensions added.</p> <p>Let's encrypt certificates should be used here instead of self-signed certs.</p> <p>Warning</p> <p>Requiring a password -aes256 for the private key will require that password to be entered every time the certificate is used (e.g. service is started). Given the short lived nature of these certificates, generally no password is used and CRL/OSCP are used to invalidate any exposed certificates.</p>"},{"location":"service/ca/certificates/#create-server-private-key-and-certificate-signing-request","title":"Create Server Private Key and Certificate Signing Request","text":"<pre><code>openssl genrsa -out /root/ca/inter/private/{SERVER}.key.pem 4096\nchmod 0400 /root/ca/inter/private/{SERVER}.key.pem\nopenssl req -config /root/ca/inter/inter.ca -key /root/ca/inter/private/{SERVER}.key.pem -new -sha512 -out /root/ca/inter/csr/{SERVER}.csr.pem\n&gt; Country Name (2 letter code): [XX]\n&gt; State or Province Name: [XX]\n&gt; Locality Name: [XX]\n&gt; Organization Name: [{CA NAME}]\n&gt; Organizational Unit Name: [{CA NAME} Certificate Authority]\n&gt; Common Name: [{CA NAME} Intermediate CA], *.example.com\n&gt; Email Address: [XX]</code></pre>"},{"location":"service/ca/certificates/#sign-certificate-signing-request","title":"Sign Certificate Signing Request","text":"<p>Server certificates should be much shorter lifetime that CA's. Typically a little over a year. Both ca-chain.cert.pem and {SERVER}.cert.pem need to be distributed if Root CA is not in the trusted CA store.</p> <pre><code>openssl ca -config /root/ca/inter/inter.ca -extensions server_cert -days 375 -notext -md sha512 -in /root/ca/inter/csr/{SERVER}.csr.pem -out /root/ca/inter/certs/{SERVER}.cert.pem\nchmod 444 /root/ca/inter/certs/{SERVER}.cert.pem\nopenssl x509 -noout -text -in /root/ca/inter/certs/{SERVER}.cert.pem\n# Should return 'OK'.\nopenssl verify -CAfile /root/ca/inter/certs/ca-chain.cert.pem /root/ca/inter/certs/{SERVER}.cert.pem</code></pre>"},{"location":"service/ca/certificates/#machine-certificates","title":"Machine Certificates","text":"<p>Special type of client certificate used to validate a machine hardware identity. These are tied to a specific machine and only have clientAuth extensions added.</p> <p>Warning</p> <p>Requiring a password -aes256 for the private key will require that password to be entered every time the certificate is used (e.g. authenticating to a service). Given the short lived nature of these certificates and that it is providing a machine identity, generally no password is used and CRL/OSCP are used to invalidate any exposed certificates to prevent access.</p>"},{"location":"service/ca/certificates/#create-machine-private-key-and-certificate","title":"Create Machine Private Key and Certificate","text":"<pre><code>openssl genrsa -out /root/ca/inter/private/{MACHINE}.key.pem 4096\nchmod 0400 /root/ca/inter/private/{MACHINE}.key.pem\nopenssl req -config /root/ca/inter/inter.ca -key /root/ca/inter/private/{MACHINE}.key.pem -new -sha512 -out /root/ca/inter/csr/{MACHINE}.csr.pem\n&gt; Country Name (2 letter code): [XX]\n&gt; State or Province Name: [XX]\n&gt; Locality Name: [XX]\n&gt; Organization Name: [{CA NAME}], {MACHINE}\n&gt; Organizational Unit Name: [{CA NAME} Certificate Authority], machine\n&gt; Common Name: [{CA NAME} Intermediate CA], {MACHINE}.machine\n&gt; Email Address: [XX]</code></pre>"},{"location":"service/ca/certificates/#sign-certificate-signing-request_1","title":"Sign certificate signing request","text":"<p>Machine certificates should be much shorter lifetime that CA's. They should be revoked and re-created whenever a machine is new or re-installed. Both ca-chain.cert.pem and {MACHINE}.cert.pem need to be distributed if Root CA is not in the trusted CA store.</p> <pre><code>openssl ca -config /root/ca/inter/inter.ca -extensions machine_cert -days 375 -notext -md sha512 -in /root/ca/inter/csr/{MACHINE}.csr.pem -out /root/ca/inter/certs/{MACHINE}.cert.pem\nchmod 444 /root/ca/inter/certs/{MACHINE}.cert.pem\nopenssl x509 -noout -text -in /root/ca/inter/certs/{MACHINE}.cert.pem\n# Should return 'OK'.\nopenssl verify -CAfile /root/ca/inter/certs/ca-chain.cert.pem /root/ca/inter/certs/{MACHINE}.cert.pem</code></pre>"},{"location":"service/ca/certificates/#client-certificates","title":"Client Certificates","text":"<p>Client certificate to validate client identity. These are tied to a specific user and only have clientAuth and emailProtection extensions added.</p> <p>Warning</p> <p>This identifies a user and needs to contain enough information to identify that person. Certificate should also require a password to prevent identity impersonation.</p>"},{"location":"service/ca/certificates/#create-client-private-key-and-certificate-signing-request","title":"Create Client Private Key and Certificate Signing Request","text":"<pre><code>openssl genrsa -aes256 -out /root/ca/inter/private/{USER EMAIL}.key.pem 4096\nchmod 0400 /root/ca/inter/private/{USER EMAIL}.key.pem\nopenssl req -config /root/ca/inter/inter.ca -key /root/ca/inter/private/{USER EMAIL}.key.pem -new -sha512 -out /root/ca/inter/csr/{USER EMAIL}.csr.pem\n&gt; Country Name (2 letter code): [XX]\n&gt; State or Province Name: [XX]\n&gt; Locality Name: [XX]\n&gt; Organization Name: [{CA NAME}], {ORG OR CA NAME}\n&gt; Organizational Unit Name: [{CA NAME} Certificate Authority], {ORG OR CA NAME}\n&gt; Common Name: [{CA NAME} Intermediate CA], {USER}\n&gt; Email Address: [XX], {EMAIL}</code></pre>"},{"location":"service/ca/certificates/#sign-certificate-signing-request_2","title":"Sign certificate signing request","text":"<p>Client certificates should be much shorter lifetime that CA's. Clients can create their own CSR requests to be signed, meaning that the CA never needs to see the client private key. Both ca-chain.cert.pem and {USER EMAIL}.cert.pem need to be distributed if Root CA is not in the trusted CA store.</p> <pre><code>openssl ca -config /root/ca/inter/inter.ca -extensions user_cert -days 375 -notext -md sha512 -in /root/ca/inter/csr/{USER EMAIL}.csr.pem -out /root/ca/inter/certs/{USER EMAIL}.cert.pem\nchmod 444 /root/ca/inter/certs/{USER EMAIL}.cert.pem\nopenssl x509 -noout -text -in /root/ca/inter/certs/{USER EMAIL}.cert.pem\n# Should return 'OK'.\nopenssl verify -CAfile /root/ca/inter/certs/ca-chain.cert.pem /root/ca/inter/certs/{USER EMAIL}.cert.pem</code></pre> <p>See Cert Based Authentication to setup auto selection of client certificate for matched sites.</p>"},{"location":"service/ca/certificates/#exporting-certificates","title":"Exporting Certificates","text":"<p>PKCS #12 PFX (Personal Information Exchange Certificate) is an encrypted singular file archive format used to distribute a bundle of certificates securely to a client. This is used to securely distribute key/cert material to clients.</p>"},{"location":"service/ca/certificates/#pack-client-certificates-and-private-keys-into-pfx","title":"Pack client certificates and private keys into PFX","text":"<pre><code>openssl pkcs12 -legacy -export -out /root/ca/pfx/{CLIENT}.pfx -inkey /root/ca/inter/private/{CLIENT}.key.pem -in /root/ca/inter/certs/{CLIENT}.cert.pem -certfile /root/ca/inter/certs/ca-chain.cert.pem</code></pre> <ul> <li>Set a strong export password different from and private key password   to prevent bundle from being installed and used without knowing password.</li> <li>ca-chain is included to provide chain of trust to the client using the   certificate and validate the server.</li> <li>-legacy is required for SSLv3.</li> </ul> <p>See Cert Based Authentication to setup auto selection of client certificate for matched sites.</p>"},{"location":"service/ca/certificates/#extract-publicprivate-keys-from-pfx","title":"Extract Public/Private Keys from PFX","text":"<p>Keys can be extracted from the PFX file for use if needed.</p> <pre><code># Extract RSA private key.\nopenssl pkcs12 -in {CLIENT}.pfx -nocerts -nodes | openssl rsa -out rsa.key\n\n# Extract RSA public key.\nopenssl pkcs12 -in {CLIENT}.pfx -clcerts -nokeys | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p' &gt; rsa.pub</code></pre>"},{"location":"service/ca/certificates/#reference","title":"Reference<sup>1</sup>","text":"<ol> <li> <p>https://jamielinux.com/docs/openssl-certificate-authority/sign-server-and-client-certificates.html \u21a9</p> </li> </ol>"},{"location":"service/ca/setup/","title":"Setup","text":""},{"location":"service/ca/setup/#setup","title":"Setup","text":""},{"location":"service/ca/setup/#locations","title":"Locations","text":"<p>Assumed locations for configuration.</p> Path Data /root/ca/root Root CA data (Assumes all CA data stored in /root) /root/ca/inter Intermediate CA data /root/ca/inter/certs Certificates signed by Intermediate CA /root/ca/inter/crl Certification Revocation List for Intermediate CA /root/ca/pfx Exported and encrypted pkcs#12 pfx files for client distribution"},{"location":"service/ca/setup/#create-structure","title":"Create Structure","text":"<pre><code># Setup basic structure required to operate CA for client authentication and revocation lists.\nmkdir -p /root/ca/root/{certs,crl,newcerts,private} /root/ca/inter/{certs,crl,csr,newcerts,private} /root/ca/pfx\nchmod 0700 /root/ca/{root,inter}/private\ntouch /root/ca/{root,inter}/index.txt\necho 1000 | tee /root/ca/root/serial /root/ca/inter/serial\necho 'unique_subject = no' | tee /root/ca/root/index.txt.attr /root/ca/inter/index.txt.attr\necho 1000 &gt; /root/ca/inter/crlnumber</code></pre>"},{"location":"service/ca/setup/#root-ca","title":"Root CA","text":"<p>The root CA should never be used other than to create or revoke intermediate CAs. It should always be kept offline and secured once intermediate CAs are setup. A compromise of the root CA key will compromise all child certificates.</p>"},{"location":"service/ca/setup/#create-root-ca-openssl-configuration","title":"Create Root CA OpenSSL Configuration","text":"<p>A good default is here. This configuration should only contain relevant sections for the required Root CA actions. Configuration file must be specified when issuing Root CA operations otherwise the systemwide openssl.conf default configuration will be used.</p> /root/ca/root/root.ca <p>0600 root:root</p> <pre><code># OpenSSL root CA configuration file.\n# Stripped down to just Root CA functionality.\n# https://jamielinux.com/docs/openssl-certificate-authority/create-the-root-pair.html\n\n[ ca ]\ndefault_ca                     = CA_default\n\n[ CA_default ]\n# Directory and file locations.\ndir                            = /root/ca/root\ncerts                          = $dir/certs\ncrl_dir                        = $dir/crl\nnew_certs_dir                  = $dir/newcerts\ndatabase                       = $dir/index.txt\nserial                         = $dir/serial\nRANDFILE                       = $dir/private/.rand\n\n# The root key and root certificate.\nprivate_key                    = $dir/private/root.key.pem\ncertificate                    = $dir/certs/root.cert.pem\n\n# For certificate revocation lists.\ncrlnumber                      = $dir/crlnumber\ncrl                            = $dir/crl/root.crl.pem\ncrl_extensions                 = crl_ext\ndefault_crl_days               = 375\n\ndefault_md                     = sha512\nname_opt                       = ca_default\ncert_opt                       = ca_default\ndefault_days                   = 375\npreserve                       = no\npolicy                         = policy_strict\n\n[ policy_strict ]\n# The root CA should only sign intermediate certificates that match.\ncountryName                    = match\nstateOrProvinceName            = match\norganizationName               = match\norganizationalUnitName         = optional\ncommonName                     = supplied\nemailAddress                   = optional\n\n[ req ]\n# Applied when creating / signing certificates.\ndefault_bits                   = 4096\ndistinguished_name             = req_distinguished_name\nstring_mask                    = utf8only\ndefault_md                     = sha512\nx509_extensions                = v3_ca\n\n[ req_distinguished_name ]\n# CSR information required, prompts and defaults.\ncountryName                    = Country Name (2 letter code)\nstateOrProvinceName            = State or Province Name\nlocalityName                   = Locality Name\n0.organizationName             = Organization Name\norganizationalUnitName         = Organizational Unit Name\ncommonName                     = Common Name\nemailAddress                   = Email Address\n\n# Default values for certification generation.\ncountryName_default            = XX\nstateOrProvinceName_default    = XX\nlocalityName_default           = XX\n0.organizationName_default     = {CA NAME}\norganizationalUnitName_default = {CA NAME} Certificate Authority\ncommonName_default             = {CA NAME} Root CA\nemailAddress_default           = XX\n\n[ v3_ca ]\n# Root CA extenstions: man x509v3_config '-extensions v3_ca'\nsubjectKeyIdentifier           = hash\nauthorityKeyIdentifier         = keyid:always,issuer\nbasicConstraints               = critical, CA:true\nkeyUsage                       = critical, digitalSignature, cRLSign, keyCertSign\n\n[ v3_intermediate_ca ]\n# Intermediate CA extensions: man x509v3_config '-extensions v3_intermediate_ca'\nsubjectKeyIdentifier           = hash\nauthorityKeyIdentifier         = keyid:always,issuer\nbasicConstraints               = critical, CA:true, pathlen:0\nkeyUsage                       = critical, digitalSignature, cRLSign, keyCertSign\n\n[ crl_ext ]\n# Certificate revocation list extensions: man x509v3_config\nauthorityKeyIdentifier         = keyid:always\n\n[ ocsp ]\n# OCSP signing certificate extensions: man ocsp\nbasicConstraints               = CA:FALSE\nsubjectKeyIdentifier           = hash\nauthorityKeyIdentifier         = keyid,issuer\nkeyUsage                       = critical, digitalSignature\nextendedKeyUsage               = critical, OCSPSigning</code></pre>"},{"location":"service/ca/setup/#create-root-ca-private-key-and-certificate","title":"Create Root CA Private Key and Certificate","text":"<p>Should be done on an air-gapped machine and stored encrypted offline once the intermediate CA is setup. Root CA should rarely be used.</p> <p>A long lifetime (7300 days, 20 years) for an offline Root CA is OK. When Root CA expires, all child certificates become invalid.</p> <pre><code># Create the private key.\nopenssl genrsa -aes256 -out /root/ca/root/private/root.key.pem 4096\nchmod 0400 /root/ca/root/private/root.key.pem\n\n# Create the Root CA Certificate.\n# Defaults from root.ca will autofill CA certificate fields.\nopenssl req -config /root/ca/root/root.ca -key /root/ca/root/private/root.key.pem -new -x509 -days 7300 -sha512 -extensions v3_ca -out /root/ca/root/certs/root.cert.pem\nchmod 444 /root/ca/root/certs/root.cert.pem\nopenssl x509 -noout -text -in /root/ca/root/certs/root.cert.pem</code></pre>"},{"location":"service/ca/setup/#intermediate-ca","title":"Intermediate CA","text":"<p>The Intermediate CA is the workhorse for certificate authorities. This will be the main CA used for issuing and revoking server / client certificates.</p>"},{"location":"service/ca/setup/#create-intermediate-ca-openssl-configuration","title":"Create Intermediate CA Openssl Configuration","text":"<p>A good default is here. This configuration should only contain relevant sections for the required Intermediate CA actions. Configuration file must be specified when issuing Intermediate CA operations otherwise the systemwide openssl.conf default configuration will be used.</p> /root/ca/inter/inter.ca <p>0600 root:root</p> <pre><code># OpenSSL intermediate CA configuration file.\n# Stripped down to just Intermediate CA functionality.\n# https://jamielinux.com/docs/openssl-certificate-authority/create-the-intermediate-pair.html\n\n[ ca ]\ndefault_ca                     = CA_default\n\n[ CA_default ]\n# Directory and file locations.\ndir                            = /root/ca/inter\ncerts                          = $dir/certs\ncrl_dir                        = $dir/crl\nnew_certs_dir                  = $dir/newcerts\ndatabase                       = $dir/index.txt\nserial                         = $dir/serial\nRANDFILE                       = $dir/private/.rand\n\n# The root key and root certificate.\nprivate_key                    = $dir/private/inter.key.pem\ncertificate                    = $dir/certs/inter.cert.pem\n\n# For certificate revocation lists.\ncrlnumber                      = $dir/crlnumber\ncrl                            = $dir/crl/inter.crl.pem\ncrl_extensions                 = crl_ext\ndefault_crl_days               = 375\n\ndefault_md                     = sha512\nname_opt                       = ca_default\ncert_opt                       = ca_default\ndefault_days                   = 375\npreserve                       = no\npolicy                         = policy_loose\n\n[ policy_loose ]\n# Allow the intermediate CA to sign a more diverse range of certificates.\ncountryName                    = optional\nstateOrProvinceName            = optional\nlocalityName                   = optional\norganizationName               = optional\norganizationalUnitName         = optional\ncommonName                     = supplied\nemailAddress                   = optional\n\n[ req ]\n# Options for the 'openssl req' tool: man req\ndefault_bits                   = 4096\ndistinguished_name             = req_distinguished_name\nstring_mask                    = utf8only\ndefault_md                     = sha512\nx509_extensions                = machine_cert\n\n[ req_distinguished_name ]\n# CSR information required, prompts and defaults.\ncountryName                    = Country Name (2 letter code)\nstateOrProvinceName            = State or Province Name\nlocalityName                   = Locality Name\n0.organizationName             = Organization Name\norganizationalUnitName         = Organizational Unit Name\ncommonName                     = Common Name\nemailAddress                   = Email Address\n\n# Default values for certification generation.\ncountryName_default            = XX\nstateOrProvinceName_default    = XX\nlocalityName_default           = XX\n0.organizationName_default     = {CA NAME}\norganizationalUnitName_default = {CA NAME} Certificate Authority\ncommonName_default             = {CA NAME} Intermediate CA\nemailAddress_default           = XX\n\n[ user_cert ]\n# User certificate extensions: man x509v3_config '-extensions user_cert'\nbasicConstraints               = CA:FALSE\nnsCertType                     = client, email\nnsComment                      = \"OpenSSL Generated Client Certificate\"\nsubjectKeyIdentifier           = hash\nauthorityKeyIdentifier         = keyid,issuer\nkeyUsage                       = critical, nonRepudiation, digitalSignature, keyEncipherment\nextendedKeyUsage               = clientAuth, emailProtection\n\n[ machine_cert ]\n# Machine certificate extensions: man x509v3_config '-extensions machine_cert'\nbasicConstraints               = CA:FALSE\nnsCertType                     = client\nnsComment                      = \"OpenSSL Generated Client Certificate\"\nsubjectKeyIdentifier           = hash\nauthorityKeyIdentifier         = keyid,issuer\nkeyUsage                       = critical, nonRepudiation, digitalSignature, keyEncipherment\nextendedKeyUsage               = clientAuth\n\n[ server_cert ]\n# Server certificate extensions: man x509v3_config '-extensions server_cert'\nbasicConstraints               = CA:FALSE\nnsCertType                     = server\nnsComment                      = \"OpenSSL Generated Server Certificate\"\nsubjectKeyIdentifier           = hash\nauthorityKeyIdentifier         = keyid,issuer:always\nkeyUsage                       = critical, digitalSignature, keyEncipherment\nextendedKeyUsage               = serverAuth\n\n[ crl_ext ]\n# Certificate revocation list extensions: man x509v3_config\nauthorityKeyIdentifier         = keyid:always\n\n[ ocsp ]\n# Extension for OCSP signing certificates: man ocsp\nbasicConstraints               = CA:FALSE\nsubjectKeyIdentifier           = hash\nauthorityKeyIdentifier         = keyid,issuer\nkeyUsage                       = critical, digitalSignature\nextendedKeyUsage               = critical, OCSPSigning</code></pre>"},{"location":"service/ca/setup/#create-intermediate-ca-private-key-and-certificate","title":"Create Intermediate CA Private Key and Certificate","text":"<p>Private key should be kept offline of live services, but accessible to enable changes. Lifetimes for Intermediate CAs should be shorter than Root CAs.</p> <p>The Root CA is used to sign the Intermediate CA. This creates a chain of trust. Lifetime is half (3650 days, 10 years) for an Intermediate CA. When the Intermediate CA expires, all child certificates become invalid.</p> <pre><code># Create the private key.\nopenssl genrsa -aes256 -out /root/ca/inter/private/inter.key.pem 4096\nchmod 0400 /root/ca/inter/private/inter.key.pem\n\n# Create the Intermediate CA Certificate.\n# Defaults from inter.ca will autofill CA certificate fields.\nopenssl req -config /root/ca/inter/inter.ca -new -sha512 -key /root/ca/inter/private/inter.key.pem -out /root/ca/inter/csr/inter.csr.pem\nopenssl ca -config /root/ca/root/root.ca -extensions v3_intermediate_ca -days 3650 -notext -md sha512 -in /root/ca/inter/csr/inter.csr.pem -out /root/ca/inter/certs/inter.cert.pem\nchmod 444 /root/ca/inter/certs/inter.cert.pem\nopenssl x509 -noout -text -in /root/ca/inter/certs/inter.cert.pem\n# Should return **OK**. This means that the Intermediate certificate is valid.\nopenssl verify -CAfile /root/ca/root/certs/root.cert.pem /root/ca/inter/certs/inter.cert.pem</code></pre>"},{"location":"service/ca/setup/#create-intermediate-chain-of-trust","title":"Create Intermediate Chain of Trust","text":"<p>The chain of trust is used to validate all certificates up to the Root CA. This is usually deployed with server/client certificates if the Root CA is not added to each machine's Trusted CA store.</p> <pre><code># Create Intermediate Chain of Trust.\ncat /root/ca/inter/certs/inter.cert.pem /root/ca/root/certs/root.cert.pem &gt; /root/ca/inter/certs/ca-chain.cert.pem\nchmod 444 /root/ca/inter/certs/ca-chain.cert.pem</code></pre>"},{"location":"service/forgejo/","title":"Forgejo","text":""},{"location":"service/forgejo/#forgejo","title":"Forgejo","text":"<p>Forgejo (GIT) Server.</p> <p>Migrated to ansible collection</p> <p>Use r_pufky.srv.forgejo.</p>"},{"location":"service/forgejo/#repository-management","title":"Repository Management","text":""},{"location":"service/forgejo/#importing-git-repositories","title":"Importing Git Repositories","text":"<p>You can import other git repositories including local and cloned ones:</p> <ul> <li>Create an aptly named repository and initialize it empty.</li> <li>Push a mirror to this repository. All information will be retained.</li> <li>Disable SSL verification if using self-signed certs.</li> </ul> <pre><code># Push mirror to Forgejo.\ncd my-repo-to-import\ngit push --mirror https://{IP}:3000/{USER}/{REPO}.git</code></pre> <p>As this is a mirror, you want to commit the git metadata and not just the files. The Forgejo repository is stored in forgejo_repository_root as a standard git repository. Importing this way sets up the Forgejo frontend database metadata for the project.</p>"},{"location":"service/forgejo/#mirrors","title":"Mirrors","text":"<p>Forgejo mirrors can automatically manage upstream mirror syncs if setup to do so. This will also allow for local forking of those mirrors for individual use.</p> <p>Create Mirror \u2794 + \u2794 New Migration</p> <ul> <li>Migrate / Clone from URL: {REMOTE REPOSITORY URL}</li> <li>Owner: {ORGANIZATION OWNER}</li> <li>Repository Name: {SAME REPO NAME}</li> <li>Visibility: Make Repository Private</li> <li>Migration Type: This repository will be a mirror</li> <li>Description: {DESCRIPTION}</li> </ul>"},{"location":"service/forgejo/#reverse-proxy","title":"Reverse Proxy","text":"<p>Forgejo should be run via a Reverse Proxy, allowing you to isolate and wrap connections in SSL. See NGINX for more details. See Base Proxy Control for basic proxy configuration.</p>"},{"location":"service/forgejo/#subdomains","title":"Subdomains","text":"<p>This requires a hard IP resolution. Hairpin NAT / NAT reflection will result in the web front working but git pull/push/clones failing. This is due to the way Forgejo handles these requests with custom written handlers. Setup DNS resolution or add to hosts file.</p> <p>/etc/nginx/conf.d/reverse_proxy.conf</p> <p>0644 root:root</p> <pre><code># Subdomain\nserver {\n  listen                 443 ssl http2;\n  server_name            gitea.{DOMAIN} gitea;\n\n  location / {\n    proxy_pass           http://gitea:3000;\n    client_max_body_size 1024m;  # Expected max size of data in a git change.\n  }\n}</code></pre>"},{"location":"service/forgejo/#subpath","title":"Subpath","text":"<p>/etc/nginx/conf.d/reverse_proxy.conf</p> <p>0644 root:root</p> <pre><code># Subpath\nserver {\n  location /gitea/ {\n    proxy_pass           http://gitea:3000/;\n    client_max_body_size 1024m;  # Expected max size of data in a git change.\n  }\n}</code></pre>"},{"location":"service/forgejo/troubleshooting/","title":"Troubleshooting","text":""},{"location":"service/forgejo/troubleshooting/#troubleshooting","title":"Troubleshooting","text":""},{"location":"service/forgejo/troubleshooting/#migration-fails","title":"Migration Fails","text":"<p>The initial migration ran past the default timeouts; or a previous migration or mirror of the same name failed during import.</p> <p>pq: duplicate key value violates unique constraint \"{DB TABLE}_pkey\"</p> <p>The DB sequential IDs have a new ID but not created, so creating a new key results in a duplicate unique key.</p> <pre><code>[git.timeout]\nDEFAUlT = 360\nMIGRATE = 1200\nMIRROR = 1200\nCLONE = 300\nPULL = 300\nGC = 60</code></pre> <p>Backup Forgejo and rebuild database tables. </p><pre><code>forgejo dump -c /etc/forgejo/forgejo.ini -t /data/forgejo/tmp/ -V\nforgejo doctor recreate-table -c /etc/forgejo/forgejo.ini</code></pre><p></p>"},{"location":"service/forgejo/troubleshooting/#mirror-fails-with-could-not-read-username","title":"Mirror Fails with could not read Username","text":"<p>The source repository is no longer public or has been deleted.</p> <p>[E] Failed to update mirror repository &amp;{272 10 {USER}  {REPO} {REPO} Mirror of https://github.com/{USER}/{REPO}. \u00a02 https://github.com/{USER}/{REPO} master 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 true false false true  0 map[] map[] []  false 0  false 0  35674663   false false [] default \u00a01582936274 1573978478}:   Stdout: Fetching origin</p> <p>Stderr: fatal: could not read Username for 'https://github.com': terminal prompts disabled   error: Could not fetch origin</p> <p>Err: </p> <p>Disable sync by setting Migration Interval to 0.</p>"},{"location":"service/mail/","title":"Mail","text":""},{"location":"service/mail/#mail","title":"Mail","text":"<p>Note</p> <p>All examples use example.com replace with your DNS domain name.</p>"},{"location":"service/mail/#dns","title":"DNS","text":"<p>Setup DNS with DNSSEC/DANE using Google Cloud DNS.</p> <p>Warning</p> <p>Captive DNS services must be configured to handle DNSSEC verification or validation will break.</p> <p>Disable captive DNS for mail server to test DNSSEC verification works.</p>"},{"location":"service/mail/#static-dns-resolvers","title":"Static DNS Resolvers","text":"<p>/etc/resolv.conf</p> <p>0644 root:root </p><pre><code>search example.com.\n\n# Use cloudflare - does not sell user data.\nnameserver 1.1.1.1\nnameserver 1.0.0.1\n\n# Enable extended DNS attributes and propagate authenticated domain trust.\noptions edns0 trust-ad</code></pre><p></p>"},{"location":"service/mail/#set-mail-hostname","title":"Set Mail Hostname","text":"<p>Mail servers are generally hosted on a mail subdomain to enable transparent backend changes as well as main domain separation. A mail hostname does not need to match the machine hostname to server mail.</p> <p>console.cloud.google.com \u2794 ctrl + o \u2794 {DNS} \u2794 Network Services \u2794 Cloud DNS \u2794 {DOMAIN} \u2794 Edit</p> <ul> <li>DNSSEC: On</li> </ul> <p>console.cloud.google.com \u2794 ctrl + o \u2794 {DNS} \u2794 Network Services \u2794 Cloud DNS \u2794 {DOMAIN}</p> <ul> <li>Add standard:<ul> <li>DNS name: mail.example.com</li> <li>Resource control type: A</li> <li>TTL: 5</li> <li>TTL Unit: minutes</li> <li>IPv4 Address: {PUBLIC_IP}</li> </ul> </li> </ul> <p>See r_pufky.srv.gcp_ddns for automatically updating your public IP.</p> <pre><code># Verify DNSSEC from mail server.\n\n# RRSIG must appear for DNSSEC/DANE mail configuration.\ndelv mail.example.com.\n&gt; ; fully validated\n&gt; mail.example.com.     300 IN  A   50.39.134.131\n&gt; mail.example.com.     300 IN  RRSIG   A 8 3 300 20251210160823 20251118160823 59571 example.com. {HASH}/c {HASH}/fb k4w=\n\n# AD (authenticated domain) must appear for DNS entry.\ndig mail.example.com\n\n# Additionally test local DNS resolver if running.\ndig @127.0.0.1 mail.example.com\n\n# ad must appear in flags.\n&gt; ; &lt;&lt;&gt;&gt; DiG 9.20.15-1~deb13u1-Debian &lt;&lt;&gt;&gt; mail.example.com\n&gt; ;; global options: +cmd\n&gt; ;; Got answer:\n&gt; ;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 53402\n&gt; ;; flags: qr rd ra ad; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1\n&gt;\n&gt; ;; OPT PSEUDOSECTION:\n&gt; ; EDNS: version: 0, flags:; udp: 512\n&gt; ;; QUESTION SECTION:\n&gt; ;mail.example.com.            IN  A\n&gt;\n&gt; ;; ANSWER SECTION:\n&gt; mail.example.com.     300 IN  A   50.39.134.131\n&gt;\n&gt; ;; Query time: 88 msec\n&gt; ;; SERVER: 1.1.1.1#53(1.1.1.1) (UDP)\n&gt; ;; WHEN: Thu Nov 20 21:09:44 UTC 2025\n&gt; ;; MSG SIZE  rcvd: 59</code></pre> <p>Verify Mox resolves the same. </p><pre><code>mox -loglevel debug dns lookup a mail.example.com\n\n# authentic=true and 'with dnssec' must be returned to validate.\n&gt; debug: dns lookup result; pkg=dns; type=ip; network=ip4; host=mail.example.com.; resp=[X.X.X.X]; authentic=true; duration=81.866448ms\n&gt; records (1, with dnssec):\n&gt; - X.X.X.X</code></pre><p></p>"},{"location":"service/mail/#traefik","title":"Traefik","text":"<p>Pass traffic through proxy without modification. This allows the mail server to change on the backend without needing to changing firewall rules on the router. See ACME Behind Traefik for detailed information.</p> <p>Forward ports to traefik TCP: 25, 465, 587, 143, 993</p> <p>/etc/traefik/traefik.yml</p> <p>0644 root:root </p><pre><code>entryPoints:\n  # Defer TLS requirements to routers.\n  web:\n    address: ':80'\n  webs:\n    address: ':443'\n    asDefault: true\n  # Passthrough mail routing.\n  smtp:\n    address: ':25'\n  smtps:\n    address: ':465'\n  submission:\n    address: ':587'\n  imap:\n    address: ':143'\n  imaps:\n    address: ':993'</code></pre><p></p> /etc/traefik/dynamic/mail.yml <p>0644 root:root </p><pre><code>http:\n  routers:\n    mail_http01:\n      rule: 'PathPrefix(`/.well-known/acme-challenge/`) &amp;&amp; (Host(`mail.example.com`) || Host(`autoconfig.example.com`) || Host(`mta-sts.example.com`))'\n      entryPoints:\n        - 'web'\n      priority: 1000\n      service: 'mail_http01_service'\n\n    mail_webmail:\n      rule: 'ClientIP(`10.2.2.80`) &amp;&amp; Host(`mail.example.com`) &amp;&amp; PathPrefix(`/webmail`)'\n      entryPoints:\n        - 'webs'\n      tls:\n        certResolver: 'lets_encrypt'\n        domains:\n          - main: 'example.com'\n            sans: '*.example.com'\n      middlewares:\n        - 'redirect_to_https'\n      service: 'mail_webmail_service'\n\n    mail_admin:\n      rule: 'ClientIP(`10.2.2.80`) &amp;&amp; Host(`mail.example.com`) &amp;&amp; PathPrefix(`/admin`)'\n      entryPoints:\n        - 'webs'\n      tls:\n        certResolver: 'lets_encrypt'\n        domains:\n          - main: 'example.com'\n            sans: '*.example.com'\n      middlewares:\n        - 'redirect_to_https'\n      service: 'mail_admin_service'\n\n  middlewares:\n    redirect_to_https:\n      redirectScheme:\n        scheme: 'https'\n        permanent: true\n\n  services:\n    mail_http01_service:\n      loadBalancer:\n        servers:\n          - url: 'http://10.5.5.240:80'\n\n    mail_webmail_service:\n      loadbalancer:\n        servers:\n          - url: 'https://10.5.5.240/webmail'\n\n    mail_admin_service:\n      loadbalancer:\n        servers:\n          - url: 'https://10.5.5.240/admin'\n\ntcp:\n  routers:\n    mail_smtp:\n      rule: 'HostSNI(`*`)'\n      entryPoints:\n        - 'smtp'\n      service: 'mail_smtp_service'\n\n    mail_smtps:\n      rule: 'HostSNI(`*`)'\n      entryPoints:\n        - 'smtps'\n      service: 'mail_smtps_service'\n\n    mail_submission:\n      rule: 'HostSNI(`*`)'\n      entryPoints:\n        - 'submission'\n      service: 'mail_submission_service'\n\n    mail_imap:\n      rule: 'HostSNI(`*`)'\n      entryPoints:\n        - 'imap'\n      service: 'mail_imap_service'\n\n    mail_imaps:\n      rule: 'HostSNI(`*`)'\n      entryPoints:\n        - 'imaps'\n      service: 'mail_imaps_service'\n\n  services:\n    mail_smtp_service:\n      loadbalancer:\n        servers:\n          - address: '10.5.5.240:25'\n\n    mail_smtps_service:\n      loadbalancer:\n        servers:\n          - address: '10.5.5.240:465'\n\n    mail_submission_service:\n      loadbalancer:\n        servers:\n          - address: '10.5.5.240:587'\n\n    mail_imap_service:\n      loadbalancer:\n        servers:\n          - address: '10.5.5.240:143'\n\n    mail_imaps_service:\n      loadbalancer:\n        servers:\n          - address: '10.5.5.240:993'</code></pre><p></p>"},{"location":"service/mail/#mox","title":"Mox","text":"<p>Tip</p> <p>Increase TTL for configured entries after mail service is confirmed to work.</p> <p>Warning</p> <p>Mox quickstart will not overwrite existing directories and files. If regenerating a quickstart configuration all directories and files must be deleted.</p>"},{"location":"service/mail/#generate-mail-configuration","title":"Generate mail configuration","text":"<p>Configuration and certificates are generated in quickstart. Initial passwords are logged in quickstart.log. </p><pre><code>mox quickstart -hostname mail.example.com postmaster@example.com</code></pre> See troubleshooting to resolve quickstart issues.<p></p>"},{"location":"service/mail/#update-dns-records","title":"Update DNS Records","text":"<p>Use the generated mox certificates to configure DNS.</p>"},{"location":"service/mail/#dane-tls-associations","title":"DANE TLS Associations","text":"<p>These only need to be created for the first hosted domain (machine based).</p> <p>console.cloud.google.com \u2794 ctrl + o \u2794 {DNS} \u2794 Network Services \u2794 Cloud DNS \u2794 {DOMAIN}</p> <ul> <li>Add standard:<ul> <li>DNS name: _25._tcp.mail.example.com.</li> <li>Resource control type: TLSA</li> <li>TTL: 5</li> <li>TTL Unit: minutes</li> <li>DANE TLS Association 1: 3 1 1 {HASH}</li> <li>DANE TLS Association 2: 3 1 1 {HASH}</li> </ul> </li> </ul>"},{"location":"service/mail/#relax-dmarc-spf-for-postmaster-messages","title":"Relax DMARC SPF for postmaster messages","text":"<p>These only need to be created for the first hosted domain (machine based).</p> <p>console.cloud.google.com \u2794 ctrl + o \u2794 {DNS} \u2794 Network Services \u2794 Cloud DNS \u2794 {DOMAIN}</p> <ul> <li>Add standard:<ul> <li>DNS name: mail.example.com.</li> <li>Resource control type: TXT</li> <li>TTL: 5</li> <li>TTL Unit: minutes</li> <li>TXT data: \"v=spf1 a -all\"</li> </ul> </li> </ul> <p>Must use double quotes for TXT data.</p>"},{"location":"service/mail/#enable-tls-failure-reporting","title":"Enable TLS Failure Reporting","text":"<p>These only need to be created for the first hosted domain (machine based).</p> <p>console.cloud.google.com \u2794 ctrl + o \u2794 {DNS} \u2794 Network Services \u2794 Cloud DNS \u2794 {DOMAIN}</p> <ul> <li>Add standard:<ul> <li>DNS name: _smtp._tls.mail.example.com.</li> <li>Resource control type: TXT</li> <li>TTL: 5</li> <li>TTL Unit: minutes</li> <li>TXT data: \"v=TLSRPTv1; rua=mailto:tlsreports@mail.example.com\"</li> </ul> </li> </ul> <p>Must use double quotes for TXT data.</p>"},{"location":"service/mail/#email-delivery-host-this-mail-server","title":"Email delivery host (this mail server)","text":"<p>console.cloud.google.com \u2794 ctrl + o \u2794 {DNS} \u2794 Network Services \u2794 Cloud DNS \u2794 {DOMAIN}</p> <ul> <li>Add standard:<ul> <li>DNS name: example.com.</li> <li>Resource control type: MX</li> <li>TTL: 5</li> <li>TTL Unit: minutes</li> <li>Preference and mail server 1: 10 mail.example.com.</li> </ul> </li> </ul> <p>Additional secondary mail servers may be added (e.g. aspmx.l.google.com.) to continue to accept mail on Google hosted mail until service is setup.</p>"},{"location":"service/mail/#dkim-outgoing-message-signing-keys","title":"DKIM outgoing message signing keys","text":"<p>console.cloud.google.com \u2794 ctrl + o \u2794 {DNS} \u2794 Network Services \u2794 Cloud DNS \u2794 {DOMAIN}</p> <ul> <li> <p>Add standard:</p> <ul> <li>DNS name: 2025a._domainkey.example.com.</li> <li>Resource control type: TXT</li> <li>TTL: 5</li> <li>TTL Unit: minutes</li> <li>TXT data: \"{2025A_KEY}\"</li> </ul> </li> <li> <p>Add standard:</p> <ul> <li>DNS name: 2025a._domainkey.example.com.</li> <li>Resource control type: TXT</li> <li>TTL: 5</li> <li>TTL Unit: minutes</li> <li>TXT data: \"{2025B_KEY}\"</li> </ul> </li> </ul> <p>Add all quoted lines to TXT field.</p> <p>TODO - this record MUST be updated when IP changes.</p>"},{"location":"service/mail/#spf-softfail","title":"SPF Softfail","text":"<p>Tag any email failing SPF checks (accept mail from old mail servers).</p> <p>console.cloud.google.com \u2794 ctrl + o \u2794 {DNS} \u2794 Network Services \u2794 Cloud DNS \u2794 {DOMAIN}</p> <ul> <li>Add standard:<ul> <li>DNS name: example.com.</li> <li>Resource control type: TXT</li> <li>TTL: 5</li> <li>TTL Unit: minutes</li> <li>TXT data: \"v=spf1 ip4:{IP} mx ~all\"</li> </ul> </li> </ul>"},{"location":"service/mail/#reject-dmarc-failures-and-request-reports","title":"Reject DMARC failures and Request Reports","text":"<p>console.cloud.google.com \u2794 ctrl + o \u2794 {DNS} \u2794 Network Services \u2794 Cloud DNS \u2794 {DOMAIN}</p> <ul> <li>Add standard:<ul> <li>DNS name: _dmarc.example.com.</li> <li>Resource control type: TXT</li> <li>TTL: 5</li> <li>TTL Unit: minutes</li> <li>TXT data: \"v=DMARC1;p=reject;rua=mailto:dmarcreports@example.com!10m\"</li> </ul> </li> </ul>"},{"location":"service/mail/#enable-mta-sts-tls-certificate-validation","title":"Enable MTA-STS TLS Certificate Validation","text":"<p>console.cloud.google.com \u2794 ctrl + o \u2794 {DNS} \u2794 Network Services \u2794 Cloud DNS \u2794 {DOMAIN}</p> <ul> <li>Add standard:<ul> <li>DNS name: mta-sts.example.com.</li> <li>Resource control type: CNAME</li> <li>TTL: 5</li> <li>TTL Unit: minutes</li> <li>Canonical name: mail.example.com.</li> </ul> </li> </ul> <p>console.cloud.google.com \u2794 ctrl + o \u2794 {DNS} \u2794 Network Services \u2794 Cloud DNS \u2794 {DOMAIN}</p> <ul> <li>Add standard:<ul> <li>DNS name: _mta-sts.example.com.</li> <li>Resource control type: TXT</li> <li>TTL: 5</li> <li>TTL Unit: minutes</li> <li>TXT data: \"v=STSv1; id=20251120T223212\"</li> </ul> </li> </ul>"},{"location":"service/mail/#enable-client-autodiscovery","title":"Enable Client Autodiscovery","text":"<p>console.cloud.google.com \u2794 ctrl + o \u2794 {DNS} \u2794 Network Services \u2794 Cloud DNS \u2794 {DOMAIN}</p> <ul> <li> <p>Add standard:</p> <ul> <li>DNS name: autoconfig.example.com.</li> <li>Resource control type: CNAME</li> <li>TTL: 5</li> <li>TTL Unit: minutes</li> <li>Canonical name: mail.example.com.</li> </ul> </li> <li> <p>Add standard:</p> <ul> <li>DNS name: _autodiscover._tcp.example.com.</li> <li>Resource control type: SRV</li> <li>TTL: 5</li> <li>TTL Unit: minutes</li> <li>SRV data 1: 0 1 443 mail.example.com.</li> </ul> </li> </ul>"},{"location":"service/mail/#enable-imap-autodiscovery","title":"Enable IMAP Autodiscovery","text":"<p>console.cloud.google.com \u2794 ctrl + o \u2794 {DNS} \u2794 Network Services \u2794 Cloud DNS \u2794 {DOMAIN}</p> <ul> <li> <p>Add standard:</p> <ul> <li>DNS name: _imaps._tcp.example.com.</li> <li>Resource control type: SRV</li> <li>TTL: 5</li> <li>TTL Unit: minutes</li> <li>SRV data 1: 0 1 993 mail.example.com.</li> </ul> </li> <li> <p>Add standard:</p> <ul> <li>DNS name: _submissions._tcp.example.com.</li> <li>Resource control type: SRV</li> <li>TTL: 5</li> <li>TTL Unit: minutes</li> <li>SRV data 1: 0 1 465 mail.example.com.</li> </ul> </li> </ul> <p>Note trailing S signifies encryption.</p>"},{"location":"service/mail/#disable-unencrypted-submission-discovery","title":"Disable Unencrypted Submission Discovery","text":"<p>Extend DNS lifetimes as these services should never be enabled again.</p> <p>console.cloud.google.com \u2794 ctrl + o \u2794 {DNS} \u2794 Network Services \u2794 Cloud DNS \u2794 {DOMAIN}</p> <ul> <li> <p>Add standard:</p> <ul> <li>DNS name: _imap._tcp.example.com.</li> <li>Resource control type: SRV</li> <li>TTL: 1</li> <li>TTL Unit: weeks</li> <li>SRV data 1: 0 0 0 .</li> </ul> </li> <li> <p>Add standard:</p> <ul> <li>DNS name: _submission._tcp.example.com.</li> <li>Resource control type: SRV</li> <li>TTL: 1</li> <li>TTL Unit: weeks</li> <li>SRV data 1: 0 0 0 .</li> </ul> </li> <li>Add standard:<ul> <li>DNS name: _pop3._tcp.example.com.</li> <li>Resource control type: SRV</li> <li>TTL: 1</li> <li>TTL Unit: weeks</li> <li>SRV data 1: 0 0 0 .</li> </ul> </li> <li>Add standard:<ul> <li>DNS name: _pop3s._tcp.example.com.</li> <li>Resource control type: SRV</li> <li>TTL: 1</li> <li>TTL Unit: weeks</li> <li>SRV data 1: 0 0 0 .</li> </ul> </li> </ul>"},{"location":"service/mail/#require-lets-encrypt-certificates-for-tls-signatures","title":"Require Let's Encrypt Certificates for TLS Signatures","text":"<p>console.cloud.google.com \u2794 ctrl + o \u2794 {DNS} \u2794 Network Services \u2794 Cloud DNS \u2794 {DOMAIN}</p> <ul> <li>Add standard:<ul> <li>DNS name: example.com.</li> <li>Resource control type: CAA</li> <li>TTL: 5</li> <li>TTL Unit: minutes</li> <li>Certificate Authority Authorization 1: 0 issue \"letsencrypt.org\"</li> </ul> </li> </ul>"},{"location":"service/mail/#verify-dns-records","title":"Verify DNS Records","text":"<pre><code># Confirm DNS propagated for DNSSEC/DANE.\ndig +dnssec +noall +answer +multi _25._tcp.mail.example.com. TLSA\n_25._tcp.mail.example.com. 300 IN   TLSA 3 1 1 (\n                {HASH}\n        )\n_25._tcp.mail.example.com. 300 IN   TLSA 3 1 1 (\n                {HASH}\n        )\n_25._tcp.mail.example.com. 300 IN   RRSIG TLSA 8 5 300 (\n                20251210160823 20251118160823 59571 example.com.\n                {HASH}\n        )</code></pre>"},{"location":"service/mail/#confirm-configuration","title":"Confirm Configuration","text":"<p>TODO - setup letsencrypt</p> <p>!!! abstract /data/mail/mox/config/mox.config     0660 mox:mox     ``` yaml     Listeners:         internal:         # Internal/Private IP's only.             IPs:                 - 127.0.0.1                 - ::1 public:     IPs:       # Use 0.0.0.0 and :: for all IPv4/IPv6 addresses.       #       # This should be your host IP.       - {IP}</p> <pre><code># Update whenever public IP changes.\n    NATIPs:\n        - {EXTERNAL_IP}\n\n    # Use HTTP\n    WebserverHTTP:\n        Enabled: true\n\n    # Use HTTPS\n    WebserverHTTPS:\n        Enabled: true</code></pre> <p>TODO: /data/mail/mox/mox.config NEEDS TO BE UPDATED WHEN PUBLIC IP CHANGES!.</p>"},{"location":"service/mail/#reference","title":"Reference<sup>1</sup>","text":"<ol> <li> <p>https://community.hetzner.com/tutorials/install-and-configure-mailserver-mox-on-debian \u21a9</p> </li> </ol>"},{"location":"service/mail/postfix/","title":"Postfix","text":""},{"location":"service/mail/postfix/#postfix","title":"Postfix","text":"<p>Email testing for classic postfix stack.</p> <p>Migrated to ansible collection</p> <p>Use r_pufky.srv.mox.</p> <p>The classic postfix stack has been archived: https://github.com/r-pufky/ansible_mail</p>"},{"location":"service/mail/postfix/#verify-services-locked-down","title":"Verify Services Locked Down","text":"<pre><code># Test SASL service.\ntelnet localhost 25\nehlo localhost\n\n# Should see '250 auth plain login' after issuing command. This means that SASL\n# dovecot is setup correctly.\n\n# Press 'ctrl + ]' to quit.</code></pre>"},{"location":"service/mail/postfix/#verify-non-encrypted-connections-fail","title":"Verify non-encrypted connections fail","text":"<pre><code>telnet localhost 143  # IMAP\ntelnet localhost 110  # POP\ntelnet localhost 995  # POP\n\n# All unencrypted connections should fail with: Unable to connect to remote\n# host: Connection refused.\n\n# Verify IMAPS connections succeed.\n``` bash\nopenssl s_client -connect localhost:993\n\n# Should get '* OK [{CAPABILITY LIST}] Dovecot ready'. Verify the certificate\n# listed is the correct Let's Encrypt certificate for the domain used.\n\n# 'C logout {ENTER}' to quit.</code></pre>"},{"location":"service/mail/postfix/#verify-encrypted-smtp-connections-succeed","title":"Verify encrypted SMTP connections succeed","text":"<pre><code>openssl s_client -starttls smtp -crlf -connect localhost:587\n\n# Verify the certificate listed is the correct Let's Encrypt certificate for\n# domain used.\n\n# 'crtl + c' to quit.</code></pre>"},{"location":"service/mail/postfix/#test-email-delivery","title":"Test Email Delivery","text":"<p>Ensure that users can receive mail. Test for users and alias cases.</p> <p>Tip</p> <p>{USER} and {PASS} should be base64 encoded.</p>"},{"location":"service/mail/postfix/#telnet-smtp-and-send-test-emails","title":"Telnet SMTP and send test emails","text":"<pre><code>telnet localhost 25\nehlo localhost\nauth login  # Should recieve 220.\nVXNlcm5hbWU6\n{USER}\nUGFzc3dvcmQ6\n{PASS}\nmail from: root@localhost\nrcpt to: {USER}@{DOMAIN}\ndata\nSubject: postfix text\ntesting mail from postfix\n.\nquit</code></pre>"},{"location":"service/mail/postfix/#verify-ssltls-smtp-can-send","title":"Verify SSL/TLS SMTP can send","text":"<pre><code>openssl s_client -starttls smtp -crlf -connect mail.{DOMAIN}:587\nehlo mail.{DOMAIN}\nauth login  # Should recieve 220.\nVXNlcm5hbWU6\n{USER}\nUGFzc3dvcmQ6\n{PASS}\nmail from: root@localhost\nrcpt to: {USER}@{DOMAIN}\ndata\nSubject: postfix text\ntesting mail from SSL/TLS SMTP\n.\nquit</code></pre>"},{"location":"service/mail/postfix/#verify-proper-mail-configuration","title":"Verify Proper Mail Configuration","text":"<p>Tests must be green or the mail server will be blacklisted by major email services.</p> <p>Use https://mxtoolbox.com to validate settings and ensure ports (25,587) are exposed for testing.</p> <ol> <li> <p>Test {DOMAIN} and `mail.{DOMAIN} MX records.</p> <ul> <li>All results must be green.</li> <li>The correct IP must be shown.</li> </ul> </li> <li> <p>SMTP Test after looking up the MX record.</p> <ul> <li>All results must be green, except PTR lookup.</li> </ul> </li> </ol> <p>Note</p> <p>The PTR record maps an IP address to a DNS name. This is used by other mail servers to verify mail received from your server is a valid email.</p> <p>This must be green if there is any intent to send mail to other services. Your ISP generally controls this, which implies that you have your ISP set this up for you or setup a hosted solution where you control the IP space.</p>"},{"location":"service/mail/troubleshooting/","title":"Troubleshooting","text":""},{"location":"service/mail/troubleshooting/#troubleshooting","title":"Troubleshooting","text":""},{"location":"service/mail/troubleshooting/#reverse-names-do-not-match-hostname","title":"Reverse names do not match hostname","text":"<p>ISP's generally control reverse DNS lookups.</p> <p>WARNING: reverse name(s) {IP}.bvtn.or.ptr.{DOMAIN} for ip {IP} do not match hostname mail.example.com, which will cause other mail servers to reject incoming messages from this IP.</p> <p>Mail may still be received but sending mail likely will be rejected. Move mail server to a hosted solution where reverse DNS lookups are controlled.</p>"},{"location":"service/mail/troubleshooting/#connecting-to-gmail-smtp-inlgooglecom-dial-tcp-io-timeout","title":"Connecting to gmail-smtp-in.l.google.com dial tcp i/o timeout","text":"<p>Outgoing SMTP connection failed.</p> <p>ERROR: connecting to gmail-smtp-in.l.google.com.:25: dial tcp {IP}:25: i/o timeout</p> <p>WARNING: Could not verify outgoing smtp connections can be made, outgoing delivery may not be working. Many providers block outgoing smtp connections by default, requiring an explicit request or a cooldown period before allowing outgoing smtp connections. To send through a smarthost, configure a \"Transport\" in mox.conf and use it in \"Routes\" in domains.conf. See \"mox config example transport\".</p> <pre><code>NOTE: Quickstart used the IPs of the host name of the mail server, but only\nfound private IPs on the machine. This indicates this machine is behind a NAT,\nso the host IPs were configured in the NATIPs field of the public listeners. If\nyou are behind a NAT that does not preserve the remote IPs of connections, you\nwill likely experience problems accepting email due to IP-based policies. For\nexample, SPF is a mechanism that checks if an IP address is allowed to send\nemail for a domain, and mox uses IP-based (non)junk classification, and IP-based\nrate-limiting both for accepting email and blocking bad actors (such as with too\nmany authentication failures).</code></pre>"},{"location":"service/nfs/","title":"NFS","text":""},{"location":"service/nfs/#nfs","title":"NFS","text":"<p>Network File System: The venerable king of network shares. Now in NFSv4 flavors.</p> <p>Migrated to ansible collection</p> <p>Use r_pufky.deb.nfs.</p> <p>Migrate to NFSv4</p> <p>NFSv4 removes a lot of cruft focusing on supporting single socket local file copies, state, authentication, and encryption. Configuration is now in /etc/nfs.conf.d/ and actively migrated to this location if detected.</p>"},{"location":"service/nfs/#client","title":"Client","text":"<pre><code>apt install nfs-common\nsystemctl list-dependencies {UNIT}  # Confirm no other dependencies.\n\n# RPC/sockets not needed in NFSv4.\nsystemctl mask rpcbind rpcbind.socket\nsystemctl stop rpcbind rpcbind.socket\nsystemctl mask rpc-statd rpc-statd-notify\nsystemctl stop rpc-statd rpc-statd-notify</code></pre>"},{"location":"service/nfs/#server","title":"Server","text":"<pre><code>apt install nfs-kernel-server\nsystemctl stop nfs-server\nsystemctl list-dependencies {UNIT}  # Confirm no other dependencies.\n\n# RPC/sockets not needed in NFSv4.\nsystemctl mask rpcbind rpcbind.socket\nsystemctl stop rpcbind rpcbind.socket\nsystemctl mask rpc-statd rpc-statd-notify\nsystemctl stop rpc-statd rpc-statd-notify</code></pre> <p>Tip</p> <p>PVE clusters can safely remove these services as well.</p>"},{"location":"service/nfs/#disable-nfsv3-support","title":"Disable NFSv3 support","text":"<p>/etc/systemd/system/nfs-server.service.d/override.conf</p> <p>0644 root:root</p> <pre><code># Alternatively: systemctl edit nfs-server\n#\n# Version 2 is explicitly disabled in Debian - adding\n# '--no-nfs-version 2' will cause the service to fail to start.\n[Service]\nExecStart=\nExecStart=/usr/sbin/rpc.nfsd --no-nfs-version 3</code></pre>"},{"location":"service/nfs/#disable-nfsv2-support-on-mounts","title":"Disable NFSv2 support on mounts","text":"<p>/etc/systemd/system/nfs-mountd.service.d/override.conf</p> <p>0644 root:root</p> <pre><code># Alternatively: systemctl edit nfs-mountd\n[Service]\nExecStart=\nExecStart=/usr/sbin/rpc.mountd --no-nfs-version 2 --no-nfs-version 3</code></pre>"},{"location":"service/nfs/#enforce-nfsv42-only","title":"Enforce NFSv4.2 only","text":"<pre><code>cp /etc/nfs.conf /etc/nfs.conf.d/local.conf</code></pre> <p>/etc/nfs.conf.d/local.conf</p> <p>0644 root:root</p> <pre><code># Only specified options are changed.\nmanage-gids=y  # Map restricted UID/GID's to server.\nvers3=n\nvers4=y  # Major version must be enabled to enable minor versions.\nvers4.0=n\nvers4.1=n\nvers4.2=y</code></pre>"},{"location":"service/nfs/#start-nfs","title":"Start NFS","text":"<pre><code>systemctl restart nfs-server nfs-mountd\ncat /proc/fs/nfsd/versions\n&gt; -3 +4 -4.0 -4.1 +4.2\n\n# Only TCP port 2049 is required in NFSv2.\nss -lutpn\n&gt; tcp  LISTEN  0  64  0.0.0.0:2049  0.0.0.0:*\n&gt; tcp  LISTEN  0  64     [::]:2049     [::]:*</code></pre>"},{"location":"service/nfs/#reference","title":"Reference<sup>1</sup><sup>2</sup><sup>3</sup><sup>4</sup><sup>5</sup><sup>6</sup><sup>7</sup>","text":"<ol> <li> <p>https://orca.pet/nfs4debian \u21a9</p> </li> <li> <p>https://www.suse.com/support/kb/doc/?id=000019530 \u21a9</p> </li> <li> <p>https://github.com/zilexa/Homeserver/tree/master/Filesystems-guide/networkshares_HowTo-NFSv4.2 \u21a9</p> </li> <li> <p>https://forum.proxmox.com/threads/nfsv4-server-disabled-under-pve-8.129803/ \u21a9</p> </li> <li> <p>https://old.reddit.com/r/linux/comments/sb05kw/nfs_v42_and_serverside_copying_and_how_i_got_it/ \u21a9</p> </li> <li> <p>https://wiki.archlinux.org/title/NFS \u21a9</p> </li> <li> <p>https://wiki.debian.org/NFSServerSetup \u21a9</p> </li> </ol>"},{"location":"service/nfs/exports/","title":"Exports (Shares)","text":""},{"location":"service/nfs/exports/#exports-shares","title":"Exports (Shares)","text":"<p>Tip</p> <p>A unified export directory is automatically created in NFSv4.2.</p> <p>Info</p> <p>See export options for export option details.</p>"},{"location":"service/nfs/exports/#zfs-nfs-exports","title":"ZFS NFS Exports","text":"<p>Tip</p> <p>Recommend keeping all NFS operations in NFS to minimize confusion.</p> <p>ZFS will export datasets directly to nfs-kernel-server on the host enabling portable NFS configurations with the respective datasets. This has no performance benefits in linux as ZFS just auto exports basic configurations to /etc/exportfs.d/zfs.exports.</p> <p>Each ZFS dataset has it's own unique FSID, so it does not need to be specified unless there are sub-directories inside that dataset that are shared as well.</p>"},{"location":"service/nfs/exports/#enable-extended-attributes","title":"Enable Extended Attributes","text":"<p>Reduces I/O requests and latency via enabling larger inode allocations for attributes. Enable large dynamic inode sizes (&gt;512B) for all exported datasets.</p> <pre><code># large_dnode is automatically enabled when dnodesize != legacy.\nzfs set xattr=sa dnodesize=auto {POOL}/{DATASET}</code></pre>"},{"location":"service/nfs/exports/#create-nfs-exports-on-zfs-filesystem","title":"Create NFS exports on ZFS filesystem.","text":"<p>Specify rw=, ro= before other options. Use mountpoint to automatically export based on the dataset mount point.</p> <p>Tip</p> <p>Commas (,) should be used to separate multiple rw=, ro= host definitions. These will be auto-exported as separate lines in /etc/exports.d/zfs.exports.</p> <pre><code># ZFS mount point required.\nzfs set mountpoint=/d/backup {POOL}/backup\n\n# zfs set sharenfs=\"{HOST},{HOST_N},{OPTION},{OPTION_N}\" {POOL}/{DATASET}\nzfs set sharenfs=\"rw=10.10.10.0/24,sec=sys,fsc,mountpoint,no_all_squash,crossmnt,nohide,no_subtree_check,anonuid=65534,anongid=65534\" {POOL}/backup\nzfs share {POOL}/backup</code></pre> <ul> <li>Exports are restricted based on the host restrictions; ensure networks are   wire isolated or use full encryption (sec=krbp).</li> <li>Exported directory is the ZFS mountpoint not the ZFS dataset name.</li> </ul> <p>Refresh ZFS NFS exports if the haven't automatically been refreshed. </p><pre><code>systemctl restart zfs-share.service  # Automatically runs 'exportfs -a'.\nexportfs  # Show currently exported filesystems.</code></pre><p></p>"},{"location":"service/nfs/exports/#exports-via-etcexports","title":"Exports via /etc/exports","text":"<p>Traditional NFS exports. Prefer ZFS Exports.</p> <p>/etc/exports</p> <p>0644 root:root</p> <pre><code># {EXPORT} {HOST}({OPTIONS}) ... {HOST_N}({OPTIONS})\n/exported 10.10.10.0/24(sec=sys,fsc,no_all_squash,crossmnt,nohide,no_subtree_check,anonuid=65534,anongid=65534)</code></pre> <p>Refresh exports. </p><pre><code>exportfs -a  # Refresh NFS kernel server exports (done automatically).\nexportfs  # Show currently exported filesystems.</code></pre><p></p>"},{"location":"service/nfs/exports/#reference","title":"Reference<sup>1</sup><sup>2</sup><sup>3</sup><sup>4</sup><sup>5</sup>","text":"<ol> <li> <p>https://wiki.debian.org/ZFS \u21a9</p> </li> <li> <p>https://www.ronny-mueller.com/2017/02/18/howto-kerberos-nfsv4-zfs-kerberized-nfs \u21a9</p> </li> <li> <p>https://github.com/openzfs/zfs/issues/3738 \u21a9</p> </li> <li> <p>https://github.com/openzfs/zfs/issues/386f0 \u21a9</p> </li> <li> <p>https://klarasystems.com/articles/nfs-shares-with-zfs \u21a9</p> </li> </ol>"},{"location":"service/nfs/mounts/","title":"Mounts","text":""},{"location":"service/nfs/mounts/#mounts","title":"Mounts","text":"<p>Info</p> <p>See export options for export option details.</p>"},{"location":"service/nfs/mounts/#systemd-automount","title":"Systemd Automount","text":"<p>Preferred as these will automatically mount when needed and unmount after idle.</p> <p>The mount unit defines how to mount the remote filesystem, automount unit triggers the mount unit.</p> <p>Tip</p> <p>Unit names must match where using only valid systemd unit characters. Typically just replace / with -, and drop root.</p> <p>/mnt/path \u2794 mnt-path</p> <p>/etc/systemd/system/mnt-client_test.mount</p> <p>0644 root:root</p> <pre><code>[Unit]\nDescription=NFS mount 127.0.0.1:/home/vagrant\n\n[Mount]\nWhat=127.0.0.1:/home/vagrant\nWhere=/mnt/client_test\nType=nfs\nOptions=nfsvers=4,minorversion=2,proto=tcp,fsc,noauto,nofail\nTimeoutSec=30\n\n[Install]\nWantedBy=multi-user.target</code></pre> <p>/etc/systemd/system/mnt-client_test.automount</p> <p>0644 root:root</p> <pre><code>[Unit]\nDescription=Automount NFS 127.0.0.1:/home/vagrant\n\n[Automount]\nWhere=/mnt/client_test\n\n[Install]\nWantedBy=multi-user.target</code></pre> <p>Enable. </p><pre><code>systemctl daemon-reload\nsysctmctl enable mnt-client_test.mount mnt-client_test.automount</code></pre><p></p>"},{"location":"service/nfs/mounts/#fstab","title":"FSTab","text":"<p>Traditional NFS share mounting.</p> <p>The root directory must existing for NFS mounts. Options may be tested with manual NFS mount before adding to fstab.</p> <pre><code>mkdir /autofs/{EXPORT}  # Repeat for all mounts.\n\n# Set unmounted directory immutable to prevent unmounted write attempts.\nchown root:root /autofs/{EXPORT}\nchmod 0755 /autofs/{EXPORT}\nchattr +i /autofs/{EXPORT}\n\n# Mount will override directory permissions.\nmount -t nfs -o nfsvers=4,minorversion=2,proto=tcp,fsc,rsize=1048576,wsize=1048576,nocto 10.10.10.8:/home/vagrant /autofs/home/vagrant</code></pre> <p>/etc/fstab</p> <p>0644 root:root</p> <pre><code># nfs4 enables automounting.\n# _netdev specifies mount is a network device and forces fstab to delay\n# mounting until after required networks are up.\n10.10.10.8:/home/vagrant /autofs/home/vagrant nfs4 rw,nfsvers=4,minorversion=2,proto=tcp,fsc,rsize=1048576,wsize=1048576,nocto,_netdev 0 0</code></pre> <p>Mount all exports. </p><pre><code>systemctl daemon-reload\nmount -a</code></pre><p></p>"},{"location":"service/nfs/optimizations/","title":"Optimizations","text":""},{"location":"service/nfs/optimizations/#optimizations","title":"Optimizations","text":"<p>Speed up NFS shares.</p> <p>Tip</p> <p>Double check any guidance that does not explicitly specify NFSv4.2. The massive changes in NFSv4.2 means most guidance no longer applies, or should be applied only after reconsideration.</p>"},{"location":"service/nfs/optimizations/#server","title":"Server","text":""},{"location":"service/nfs/optimizations/#use-slog-for-exported-zfs-datasets","title":"Use SLOG for exported ZFS datasets","text":"<p>More than a 12x throughput improvement by using synchronous flush based log for ZIL writes. See ZFS increase write throughput.</p>"},{"location":"service/nfs/optimizations/#set-large-chunk-size","title":"Set large chunk size","text":"<p>A large chunk size will minimize network traffic.</p> <p>/etc/nfs.conf.d/local.conf</p> <p>0644 root:root</p> <pre><code># Use 15MB chunks to optimize for streaming large files.\nnfs_conf_nfsrahead_nfsv4: 15360 # 15 * 1024KB (minimum chunk size).\nnfs_conf_nfsrahead_default: 15360</code></pre>"},{"location":"service/nfs/optimizations/#allow-more-threads","title":"Allow More Threads","text":"<p>/etc/nfs.conf.d/local.conf</p> <p>0644 root:root</p> <pre><code># number of shares * mounts + 8\nnfs_conf_nfsd_threads: 75</code></pre>"},{"location":"service/nfs/optimizations/#client","title":"Client","text":""},{"location":"service/nfs/optimizations/#set-1mb-read-and-write-sizes","title":"Set 1MB read and write sizes","text":"<p>A large chunk size will minimize network traffic.</p> <pre><code># NFS mount command\n... nfs4 ... rsize=1048576,wsize=1048576 ...</code></pre>"},{"location":"service/nfs/optimizations/#reference","title":"Reference<sup>1</sup><sup>2</sup><sup>3</sup><sup>4</sup><sup>5</sup><sup>6</sup>","text":"<ol> <li> <p>https://linux.die.net/man/5/nfs \u21a9</p> </li> <li> <p>https://cromwell-intl.com/open-source/performance-tuning/nfs.html \u21a9</p> </li> <li> <p>https://www.ibm.com/docs/en/aix/7.2?topic=tuning-tcpip-guidelines-nfs-performance \u21a9</p> </li> <li> <p>https://www.admin-magazine.com/HPC/Articles/Useful-NFS-Options-for-Tuning-and-Management \u21a9</p> </li> <li> <p>https://www.truenas.com/community/threads/slow-nfs-read-performance-over-10-gbe.90759/ \u21a9</p> </li> <li> <p>https://forum.netgate.com/topic/131645/10gbe-tuning-do-net-inet-tcp-recvspace-kern-ipc-maxsockbuf-etc-matter \u21a9</p> </li> </ol>"},{"location":"service/nfs/options/","title":"Options","text":""},{"location":"service/nfs/options/#options","title":"Options","text":"<p>Commonly used NFS options.</p> <p>See man page for all options.</p> <p>Tip</p> <p>async increases write speed only - do not use for RO mounts as it will have no effect.</p> Option Purpose all_squash[no_all_squash] Map all UID/GIDs to anonymous user; this is nobody for Debian. anonuid Anonymous user ID. anongid Anonymous group ID. async Violate NFS protocol and reply before changes committed (unsafe). sync Reply after changes are committed to disk (safe). crossmnt Enable traversing of directories below exported root. fsc Use filesystem cache. NFS will not use cache unless explicitly set. fsid root or 0 has special meaning in which all other exports are mounted underneath it. Root should only be used if the filesystem does not have a UUID. Modern systems shouldn't use this. mountpoint Only export if successfully mounted first (ZFS only). no_subtree_check Disable checking if file is in exported subtree (slow) this is disabled by default. nohide Do not hide sub-exports on same filesystems. rw Read/write. ro Readonly. root_squash[no_root_squash] Map UID/GID 0 to anonymous user; this is nobody (65534) for debian. sec=sys Use local UIDs/GIDs authentication. sec=krb5 Kerberos authentication only. sec=krb5i Kerberos authentication and secure checksums. sec=krb5p Kerberos authentication, secure checksums, NFS traffic encryption. nocto lose-to-open consistency - client trusts freshness of its view of the file and directory until cache attribute timers (actimo) elapses. Improves performance for read-only mounts only if ata changes occasionally. Reduces getattr access calls ~65-70%. cto close-to-open consistency (default) - ensures that on open the most recent data for a file is always presented to the application. actimo Sets acregmin, acregmax, acdirmin, acdirmax. actimo=600 additionally reduces getattr access calls ~20-25% with nocto. noatime Disable inode access time update on read. Implies nodiratime. nodiratime Disable directory inode access time update on read."},{"location":"service/nfs/options/#reference","title":"Reference:<sup>1</sup><sup>2</sup><sup>3</sup><sup>4</sup><sup>5</sup><sup>6</sup><sup>7</sup>","text":"<ol> <li> <p>https://man7.org/linux/man-pages/man5/nfs.5.html \u21a9</p> </li> <li> <p>https://www.thegeekdiary.com/common-nfs-mount-options-in-linux/ \u21a9</p> </li> <li> <p>https://learn.microsoft.com/en-us/azure/azure-netapp-files/performance-linux-mount-options \u21a9</p> </li> <li> <p>https://www.admin-magazine.com/HPC/Articles/Useful-NFS-Options-for-Tuning-and-Management \u21a9</p> </li> <li> <p>https://wiki.archlinux.org/title/NFS \u21a9</p> </li> <li> <p>https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/4/html/reference_guide/s2-nfs-client-config-options#s2-nfs-client-config-options \u21a9</p> </li> <li> <p>https://unix.stackexchange.com/questions/427597/implications-of-using-nfsv4-fsid-0-and-exporting-the-nfs-root-to-entire-lan-or \u21a9</p> </li> </ol>"},{"location":"service/nfs/troubleshooting/","title":"Troubleshooting","text":""},{"location":"service/nfs/troubleshooting/#troubleshooting","title":"Troubleshooting","text":""},{"location":"service/nfs/troubleshooting/#mounting-nfs-shares-in-lxc-containers","title":"Mounting NFS shares in LXC containers","text":"<p>Mounting NFS shares require elevated privileges. A better pattern is to mount the NFS shares on the cluster node and map the mount point directly in the container. These should be mapped with minimum permissions.</p> <p>On the proxmox node mount NFS shares using FSTab instead of the WebGUI. Mounts created using the WebGUI are only mounted on first use, which generally leads to container mounting failures due to timeouts on the PVE host.</p>"},{"location":"service/nfs/troubleshooting/#pve-all-nodes","title":"PVE (All Nodes)","text":"<p>/etc/fstab</p> <p>0644 root:root</p> <pre><code>10.10.10.8:/d/backup /autofs/backup nfs4 ro,nfsvers=4,minorversion=2,proto=tcp,fsc,rsize=1048576,wsize=1048576,nocto,_netdev 0 0</code></pre>"},{"location":"service/nfs/troubleshooting/#lxc-container","title":"LXC Container","text":"<p>Add a standard container mountpoint directed at the NFS mount.</p> <p>/etc/pve/lxc/{ID}.conf</p> <p>0644 root:root</p> <pre><code>mp0: volume=/autofs/backup,mp=/data/backup,ro=1</code></pre>"},{"location":"service/nfs/troubleshooting/#blocklayout-failed","title":"blocklayout failed","text":"<p>Message may be ignored.</p> <p>open pipe file /run/rpc_pipefs/nfs/blocklayout failed: No such file or directory</p> <p>Loading the blocklayoutdriver resolves the message but creates another one. Upstream bug is closed as will not fix.</p>"},{"location":"service/nfs/troubleshooting/#reference","title":"Reference<sup>1</sup><sup>2</sup>","text":"<ol> <li> <p>https://github.com/zilexa/Homeserver/tree/master/Filesystems-guide/networkshares_HowTo-NFSv4.2 \u21a9</p> </li> <li> <p>https://forum.proxmox.com/threads/best-practise-sharing-nfs-to-proxmox-cluster.145590 \u21a9</p> </li> </ol>"},{"location":"service/nginx/","title":"NGINX","text":""},{"location":"service/nginx/#nginx","title":"NGINX","text":"<p>Advanced Load Balancer, Web Server, Reverse Proxy, and Streaming.</p> <p>Migrated to ansible collection</p> <p>Use r_pufky.srv.nginx</p>"},{"location":"service/nginx/#manual-configuration","title":"Manual Configuration","text":"<p>This provides a way to place services behind a proxy and enforce SSL for those applications, as well as being able to offer a clean namespace for multiple microservices.</p> <p>This setup will focus on creating a reverse proxy, enforcing SSL for all connections using Let's Encrypt; and enforcing client certificate authentication.</p> <p>A detailed Nginx Administration Handbook is here</p>"},{"location":"service/nginx/#reference","title":"Reference<sup>1</sup>","text":"<ol> <li> <p>https://www.nginx.com \u21a9</p> </li> </ol>"},{"location":"service/nginx/troubleshooting/","title":"Troubleshooting","text":""},{"location":"service/nginx/troubleshooting/#troubleshooting","title":"Troubleshooting","text":""},{"location":"service/nginx/troubleshooting/#debug-nginx-configs","title":"Debug NGINX configs","text":"<p>There is no existing logging functionality in NGINX to write directly to logs from configuration files. Work around by directly injecting debugging headers in configuration files to dump information to logs. NGINX variables may be used as well.</p> <pre><code>add_header X-debug-message \"some message to write $ssl_client_s_dn\" always;</code></pre> <p>Headers are found in the page response.</p> <p></p>"},{"location":"service/nginx/troubleshooting/#if-is-evil","title":"If is Evil","text":"<p>Within a location block the only safe operations are</p> <p>If operates as a rewrite and is inherently misunderstood.</p> <ul> <li>return.</li> <li>rewrite.</li> </ul> <p>All if operations must be explicitly tested for appropriate behavior.</p>"},{"location":"service/nginx/troubleshooting/#dump-loaded-nginx-configuration","title":"Dump Loaded NGINX Configuration","text":"<p>Dump the currently loaded configuration in config file formatting. Useful to inspect current nginx state.</p> <pre><code>nginx -T</code></pre>"},{"location":"service/nginx/troubleshooting/#nginx-queries-originate-from-wrong-gateway","title":"NGINX Queries Originate from Wrong Gateway","text":"<p>NGINX express this bug by forwarding/proxying any traffic over the default gateway for the first lexical named network that appears. This results in non-deterministic source IP routing.</p> <p>Set an appropriate default gateway in the networking config.</p>"},{"location":"service/nginx/troubleshooting/#forward-traffic-via-specific-interfaces","title":"Forward Traffic via Specific Interfaces","text":"<p>NGINX can forward traffic via specific interfaces for location definitions.</p> <p>Use IPv4 address in proxy_bind command for specific locations.</p> <pre><code>location / {\n  proxy_bind {NGINX NETWORK IP};\n  proxy_pass ...\n}</code></pre>"},{"location":"service/nginx/manual/","title":"Basic NGINX Reverse Proxy Use","text":""},{"location":"service/nginx/manual/#basic-nginx-reverse-proxy-use","title":"Basic NGINX Reverse Proxy Use","text":"<p>This will cover the basic usage of NGINX as a reverse proxy; covering services on the URI path, not as a custom subdomain. See subdomain reverse proxy for setting up subdomains.</p> <p>Use reference documentation and location block references for additional information.</p> <p>Location blocks should be placed in the server block.</p>"},{"location":"service/nginx/manual/#service-gotchas","title":"Service Gotchas","text":"<p>Ensure the services running behind the proxy are in a known configuration:</p> <ul> <li>Running on expected protocols (http or https) and ports.</li> <li>Have firewalls setup to only allow traffic in/out of those ports to and from   the proxy.</li> </ul>"},{"location":"service/nginx/manual/#trailing-slash-gotchas","title":"Trailing Slash Gotchas","text":"<ul> <li>Services already using URI paths for the services should leave off   trailing slashes in location and proxy_pass.</li> <li>Services using no additional URI paths for services should use trailing   slashes in location and proxy_pass.</li> </ul> <p>If the proxy_pass directive is specified with a URI, then when a request is passed to the server, the part of a normalized request URI matching the location is replaced by a URI specified in the directive:</p> Trailing slashNo trailing slash <pre><code>location /name/ {\n  proxy_pass http://app/remote/;\n}</code></pre> <ul> <li>Assume request: http://proxy/name/path?params=1.</li> <li>http://app/remote/ sees request as   https://app/remote/path?params=1.</li> <li>Essentially the matched URI path is removed and the rest is passed as   though it was called from app's page.</li> </ul> <p>If proxy_pass is specified without a URI, the request URI is passed to the server in the same form as sent by a client when the original request is processed, or the full normalized request URI is passed when processing the changed URI.</p> <pre><code>location /name/ {\n    proxy_pass http://app/remote;\n}</code></pre> <ul> <li>Assume request: http://proxy/name/path?params=1.</li> <li>http://app/remote/ sees request as   https://app/remote/name/path?params=1.</li> <li>Essentially the URI path is concatenated to the end of the remote   path.</li> </ul>"},{"location":"service/nginx/manual/#regex-versus-trailing-slashes","title":"Regex Versus Trailing Slashes","text":"<p>Most examples on the web use regex, but regex is generally slow, error prone and hard to read. In NGINX most regexes may be replaced with trailing slash to replace the matched URI path instead. It's cleaner and easier to read, and usually covers the regex case.</p> <p>Do this</p> <p>Using trailing slashes (good) proxies /nzbget to https://nzbget:6791/.</p> <pre><code>location /nzbget/ {\n  proxy_pass            https://nzbget:6791/;\n  include               /etc/nginx/conf.d/proxy.conf;\n  proxy_set_header Host $host;\n}</code></pre> <p>Do not do this</p> <p>Web Regex Example proxies /nzbget to https://nzbget:6791/. </p><pre><code>location ~ ^/nzbget$ {\n  return                302 $scheme://$host$request_uri/;\n}\nlocation ~ ^/nzbget($|./*) {\n  rewrite               /nzbget/(.*) /$1 break;\n  proxy_pass            https://nzbget:6791;\n  include               /etc/nginx/conf.d/proxy.conf;\n  proxy_set_header Host $host;\n}</code></pre><p></p> <ul> <li>First rule regex matches nzbget and returns a 302 to the same URI   with a trailing slash.</li> <li>Second rule accepts /nzbget with parameters and proxies to the service.</li> <li>This results in two proxy hits and two regex comprehensions; it's also hard   to understand what the regex is doing immediately.</li> </ul>"},{"location":"service/nginx/manual/#redirect-path-to-base-uri","title":"Redirect Path to Base URI","text":"<p>For applications that serve https://app/. </p><pre><code>location /gogs/ {\n  proxy_pass https://gogs:3000/;\n}</code></pre><p></p> <p>Note</p> <p>Note trailing slashes.</p>"},{"location":"service/nginx/manual/#redirect-path-to-service-uri-path","title":"Redirect Path to Service URI Path","text":"<p>For applications that serve https://app/path. </p><pre><code>location /sonarr {\n  proxy_pass http://sonarr:8989/sonarr;\n  include /etc/nginx/conf.d/proxy_control.conf;\n}</code></pre><p></p> <p>Note</p> <p>Note no trailing slashes.</p>"},{"location":"service/nginx/manual/#custom-path-for-service","title":"Custom Path for Service","text":"<p>Enable different paths to the same service. </p><pre><code>location /tv {\n  return     301 $scheme://$host/sonarr/;\n}\nlocation /sonarr {\n  proxy_pass http://sonarr:8989/sonarr;\n  include    /etc/nginx/conf.d/proxy_control.conf;\n}</code></pre><p></p> <p>Note</p> <p>tv will automatically redirect to sonarr.</p>"},{"location":"service/nginx/manual/#enable-websockets","title":"Enable Websockets","text":"<p>Allow for apps requiring websockets to be used. </p><pre><code>location /crashplan/ {\n  proxy_pass                    https://crashplan:5800/;\n  include                       /etc/nginx/conf.d/proxy_control.conf;\n\n  location /crashplan/websockify {\n    proxy_pass                  https://crashplan:5800/websockify/;\n    include                     /etc/nginx/conf.d/proxy_control.conf;\n    proxy_set_header Upgrade    $http_upgrade;\n    proxy_set_header Connection $connection_upgrade;\n  }\n}</code></pre><p></p> <ul> <li>Upgrade and Connection must be used, and pass values through the websocket   map to enable the connection upgrade or close the connection.</li> <li>proxy_http_version 1.1 is required, but included in   proxy_control.conf.</li> </ul>"},{"location":"service/nginx/manual/#rewrite-responses-with-subpath","title":"Rewrite Responses with Subpath","text":"<p>Some applications are not URI Path aware and will re-write all responses behind the proxy using a static relative path or hostname; which will cause 404 errors and the app to break. Partially fixed using http_sub_module.</p> <p>Note</p> <p>Re-writing the proxy response generally won't fix a complicated application   as there will be a large number of unknown responses that need to be   re-written. Usually this is resolved using a sub-domain instead.</p> <pre><code>sub_filter      https://app:port/ https://reverse-proxy-server/subpath/;\nsub_filter      'href=\"/' 'href=\"https://reverse-proxy-server/subpath/';\nsub_filter_once off;</code></pre> <ul> <li>First rule rewrites responses from the app: https://app:port/page.html to   https://reverse-proxy-server/subpath/page.html.</li> <li>Second rules rewrites relative responses href=\"/other-page.html\" to   href=\"https://reverse-proxy-server/subpath/other-page.html\".</li> </ul>"},{"location":"service/nginx/manual/#enable-nginx-startrunning-with-backends-down","title":"Enable NGINX Start/Running with Backends Down","text":"<p>By design NGINX will prevent startup or running if upstream backends are down as it is interpreted to be a configuration error.</p> <p>Services which are down may not resolve via DNS, and therefore will trigger this condition, requiring all services to be up for NGINX to function.</p> <p>Another expression is a long running NGINX server where a backend has been restarted. This will mark the backend as bad and NGINX will no longer serve it even though the service may be running now.</p> <p>By specifying an explicit IP no DNS lookup is required which prevents the service health check, allowing NGINX to start or run with backends down. This will show 502 errors when the service is down. Does not affect cert-based authentication setups.</p> <p>Static IP for upstream service. </p><pre><code>upstream my-backend {\n  server {IP}:{PORT};\n}\n\nserver {\n  listen 443 ssl http2;\n  server_name myservice.example.com myservice;\n\n  location / {\n    proxy_pass http://my-backend;\n  }\n}</code></pre><p></p>"},{"location":"service/nginx/manual/#reference","title":"Reference<sup>1</sup><sup>2</sup><sup>3</sup>","text":"<ol> <li> <p>https://community.home-assistant.io/t/nginx-reverse-proxy-set-up-guide-docker/54802 \u21a9</p> </li> <li> <p>https://docs.nginx.com/nginx/admin-guide/installing-nginx/installing-nginx-open-source/ \u21a9</p> </li> <li> <p>https://www.digitalocean.com/community/tutorials/understanding-nginx-server-and-location-block-selection-algorithms \u21a9</p> </li> </ol>"},{"location":"service/nginx/manual/best_practices/","title":"Best Practices","text":""},{"location":"service/nginx/manual/best_practices/#best-practices","title":"Best Practices","text":""},{"location":"service/nginx/manual/best_practices/#one-proxy-file-per-site","title":"One Proxy File Per Site","text":"<p>Minimizes errors by keeping proxy configuration in one location. Useful when needing the same proxy config multiple times in a site.</p> <p>Create a proxy directory. </p><pre><code>mkdir /etc/nginx/conf.d/include/proxy</code></pre><p></p> <p>Add each site proxy config to /etc/nginx/conf.d/include/proxy/{SITE}. These can be imported in server/location blocks as needed.</p> <p>/etc/nginx/conf.d/include/server/{SITE}</p> <p>0644 root:root</p> <pre><code>server {\n  include /etc/nginx/conf.d/include/proxy/{SITE};\n}</code></pre>"},{"location":"service/nginx/manual/best_practices/#one-server-site-per-config-file","title":"One Server Site Per Config File","text":"<p>Keep one site per configuration file to focus only on that site. This will help reduce errors and allow fast lookup / disable of configurations.</p> <p>Create a server directory. </p><pre><code>mkdir /etc/nginx/conf.d/include/server</code></pre><p></p> <p>Add each site to /etc/nginx/conf.d/include/server/{SITE}. Then modify default config to auto import sites / services.</p> <p>/etc/nginx/conf.d/default.conf</p> <p>0644 root:root</p> <pre><code>include /etc/nginx/conf.d/include/server/*;</code></pre> <p>Adding a site in services and restarting NGINX will now automatically pickup that site.</p>"},{"location":"service/nginx/manual/best_practices/#password-authentication-basic-auth","title":"Password Authentication (Basic Auth)","text":"<p>Basic auth uses a file to authenticate users for NGINX locations.</p> <p>Install password utilities and generate a user/password. </p><pre><code>apt install apache2-utils\nsudo htpasswd -c /etc/nginx/{SITE}.pass {USER}</code></pre><p></p> <p>nginx/conf.d/reverse_proxy.conf</p> <p>0644 root:root</p> <pre><code>server {\n  listen 443 ssl http2;\n  server_name {SITE}.{DOMAIN} {SITE};\n\n  location / {\n    allow {TRUSTED NETWORK}/{TRUSTED NETWORK MASK};\n    allow {TRUSTED IP};\n    deny all;\n    auth_basic '{SITE}';\n    auth_basic_user_file /etc/nginx/{SITE}.pass;\n\n    proxy_pass https://{SITE}/;\n    include /etc/nginx/conf.d/proxy-control.conf;\n  }\n}</code></pre> <p>Note</p> <p>This will allow specific subnets and trusted IP's to access location without authentication, and force all others to authenticate, prompting with {SITE}.</p>"},{"location":"service/nginx/manual/best_practices/#site-wide-auth-file","title":"Site-wide Auth File","text":"<p>Keep authentication definitions for different services to one file to maintain authentication consistency across multiple sites.</p> <p>Create an authentication block, and store in a file.</p> <p>/etc/nginx/conf.d/site_auth.conf</p> <p>0644 root:root</p> <pre><code># Allow all on 10.1.1.0/24 through, and force auth for everyone else.\nsatisfy              any;\nallow                10.1.1.0/24;\ndeny                 all;\nauth_basic           'Your Site';\nauth_basic_user_file /etc/nginx/conf.d/your_site.pass</code></pre> <p>Include authentication block where authentication would be required.</p> <p>/etc/nginx/conf.d/service/my_site.conf</p> <p>0644 root:root</p> <pre><code>location / {\n  include    /etc/nginx/conf.d/site_auth.conf;\n  proxy_pass ...\n}</code></pre>"},{"location":"service/nginx/manual/best_practices/#remove-auth-requirement-for-proxies","title":"Remove Auth Requirement for Proxies","text":"<p>NGINX may be whitelisted to allow dashboards and services to communicate with each other using FQDNs without needing basic auth.</p>"},{"location":"service/nginx/manual/best_practices/#whitelist-all-containers","title":"Whitelist All Containers","text":"<p>Add IP range to the authorization file.</p> <p>/etc/nginx/conf.d/site_auth.conf</p> <p>0644 root:root</p> <pre><code>allow 172.18.0.0/16;</code></pre>"},{"location":"service/nginx/manual/best_practices/#whitelist-single-container","title":"Whitelist Single Container","text":"<p>Whitelist specific IP in the authorization file.</p> <p>/etc/nginx/conf.d/site_auth.conf</p> <p>0644 root:root</p> <pre><code>allow 172.18.0.101;</code></pre>"},{"location":"service/nginx/manual/best_practices/#disable-auth-for-a-specific-location","title":"Disable Auth for a specific location","text":"<p>Explicitly disable auth and allow all to remove any auth enforcement for a specific location. This is for proxied sites that do their own authentication (e.g. git) or for specific locations which shouldn't be auth'ed.</p> <p>Explicitly set no authentication and allow all to prevent any configuration carried over from the default site.</p> <p>/etc/nginx/conf.d/service/my_site.conf</p> <p>0644 root:root</p> <pre><code>location / {\n  auth_basic off;\n  allow      all;\n  proxy_pass ...\n}</code></pre>"},{"location":"service/nginx/manual/best_practices/#classify-networks-to-variables","title":"Classify Networks to Variables","text":"<p>Determine remote address subnet / IP and set variable specifically for match. Enables use of logic within NGINX to make decisions based on remote IP address.</p> <pre><code>geo $client {\n  default        default;\n  172.1.1.1      nginx-proxy-host;\n  172.10.0.0/16  subnet-one;\n  172.11.0.0/16  subnet-two;\n}</code></pre> <ul> <li>$client will store a value based on the most specific match and can be   checked in other sections.</li> <li>There is essentially no cost for a large list of matches; only evaluated when   used.</li> </ul> <pre><code>server {\n  location / {\n    if ($client = subnet-one) {\n      return 403;\n      break;\n    }\n  }\n}</code></pre>"},{"location":"service/nginx/manual/best_practices/#rate-limiting","title":"Rate Limiting","text":"<p>Restrict the amount of requests a user can simultaneously issue to the NGINX proxy and determine how to throttle or drop requests over that limit. Read in-depth documentation reference to fully understand rate limiting.</p> <pre><code>limit_req_zone $binary_remote_addr zone=binip:10m rate=10r/s;</code></pre> <ul> <li>Place this in the http context block, outside of server blocks.</li> <li>10 MB of memory is reserved in the zone binip to match the binary ip   address requests. This is shared across all threads.</li> <li>The rate limit specified is 10 requests / second. (1 request every 100   milliseconds). No bursting is defined here so requests between 100 millisecond   increments will be dropped.</li> </ul> <pre><code>location / {\n    limit_req zone=binip burst=20 nodelay;\n}</code></pre> <ul> <li>Enable bursting of up to 20 requests a second and immediate queue those   requests without delay. This will handle requests between 100 millisecond   increments, however, the 21st request will be delayed until the queue has   space.</li> <li>delay=10 will enable bursting of up to 10 requests a second, then delay   any request amount over 10 until the queue is cleared. Excessive queries will   be dropped.</li> </ul>"},{"location":"service/nginx/manual/cert_based_authentication/","title":"Cert Based Authentication","text":""},{"location":"service/nginx/manual/cert_based_authentication/#cert-based-authentication","title":"Cert Based Authentication","text":"<p>Configure NGINX to verify client certificate before responding to requests. This provides another security layer to NGINX enabling only known certificates access to make requests for the proxy. Generally, these should be considered machine certificates as they do not identify a particular user, just a machine with a certificate.</p> <p>See Certificate Authority for instructions on setting up required certificates used here. An excellent reference for basic certificate usage and should be well understood before proceeding.</p>"},{"location":"service/nginx/manual/cert_based_authentication/#nginx-configuration","title":"Nginx Configuration","text":"<p>If the default_server is set to not require cert-based authentication and additional server blocks do, clients that do not support it will fall back to the default_server and be able to make valid requests. Therefore the default server should act as a catch all for non-cert based requests and specifically respond to those requests. In this case we will respond immediately with a 403.</p> <p>Danger</p> <p>You are entering a dangerous space. Once a client has a valid SSL connection, certificate validation needs to be explicitly enforced; otherwise a client can access other SSL areas (due to a pre-existing valid SSL connection).</p> <p>ALWAYS explicitly check for valid client certificates and do penetration testing to verify your assumptions.</p> /etc/nginx/conf.d/server_cert_authentication.conf <p>0644 root:root</p> <pre><code># Setup NGINX SSL server with client cert authentication.\nserver {\n  # Security-related headers (cross-site/domain, referrer)\n  # https://geekflare.com/http-header-implementation/\n  # https://geekflare.com/nginx-webserver-security-hardening-guide/\n  # https://www.cyberciti.biz/tips/linux-unix-bsd-nginx-webserver-security.html\n  add_header X-Content-Type-Options            nosniff;\n  add_header X-XSS-Protection                  \"1; mode=block\";\n  add_header X-Robots-Tag                      none;\n  add_header X-Download-Options                noopen;\n  add_header X-Permitted-Cross-Domain-Policies none;\n  add_header Referrer-Policy                   no-referrer;\n  add_header Strict-Transport-Security         \"max-age=15768000; includeSubDomains; preload;\";\n\n  # Enable basic SSL security settings.\n  ssl_certificate                              /etc/nginx/ssl/letsencrypt-fullchain.pem;\n  ssl_certificate_key                          /etc/nginx/ssl/letsencrypt-privkey.pem;\n  ssl_trusted_certificate                      /etc/nginx/ssl/letsencrypt-chain.pem;\n  ssl_dhparam                                  /etc/nginx/ssl/letsencrypt-ssl-dhparams.pem;\n\n  # Enable OCSP stapling https://en.wikipedia.org/wiki/OCSP_stapling.\n  ssl_stapling                                 on;\n  ssl_stapling_verify                          on;\n\n  # make client certificate verification optional, so we can display a 403\n  # message to those who fail authentication. All loctions **must** explicitly\n  # validate ssl_client_verify for restricted access to work. Alternatively the\n  # ``on`` option will force client auth for all connections, including error\n  # pages.\n  ssl_client_certificate                       /etc/nginx/auth/ca-chain.cert.pem;\n  ssl_crl                                      /etc/nginx/auth/ca-chain.crl.pem;\n  ssl_verify_client                            optional;\n\n  # One error page for everything. Does not require client cert.\n  root       /www;\n  error_page 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 421 422 423 424 426 428 429 431 451 500 501 502 503 504 505 506 507 508 510 511 /error.html;\n  location = /error.html {\n    allow    all;\n    internal;\n    root     /www;\n  }\n\n  # If no cert auth is used, 403.\n  location /secured_site {\n    # Disable client certificate authentication for a specific host. See geo\n    # module for catching subnets.\n    if ($remote_addr = 10.10.10.10) {\n      proxy_pass http://some-backend;\n      break;\n    }\n\n    if ($ssl_client_verify != SUCCESS) {\n      return     403;\n      break;\n    }\n    proxy_pass   http://some-backend;\n  }\n}</code></pre> <ul> <li>This provices Authentication (authn) See Certificate Authorization   for authorization setup.</li> <li>If statements should only be used to for rewrite and return   (proxy_pass is a rewrite statement). See if-is-evil.</li> <li>Access can be provided based on client certificate presented as well (e.g.   specific access for specific certificates.</li> <li>Disabling for a specific host may be required for backend hosts communicating   with each other via the proxy. Most backend services do not support client   authentication. The address here should be the proxy gateway address as   that is where those proxied requests will be coming from. This will only   allow traffic originating from the proxy through, not proxied requests   from clients. Always be sure to enforce client verification and test   assumptions.</li> <li>The Certificate Revocation List must include all CRL's up to the Root CA for   the CRL to work, otherwise all CRL checks will be invalid and block access   even for valid clients.</li> </ul>"},{"location":"service/nginx/manual/cert_based_authentication/#proxy-specific-client-certificate","title":"Proxy-specific Client Certificate","text":"<p>For cases where a backend requires a certificate but the client using the proxy does not have one. This is dangerous if used without layering additional security measures. Explicitly specify a certificate that the proxy will use to authenticate to backends for requests.</p> <p>Create a client certificate as normal and configure NGINX with. </p><pre><code>server {\n  proxy_ssl_certificate         /etc/nginx/auth/nginx.crt.pem;\n  proxy_ssl_certificate_key     /etc/nginx/auth/nginx.key.pem;\n  proxy_ssl_trusted_certificate /etc/nginx/auth/{BACKEND}.crt.pem;\n}</code></pre><p></p>"},{"location":"service/nginx/manual/cert_based_authentication/#certificate-authorization-authz","title":"Certificate Authorization (authz)","text":"<p>Enable specific site access to client certificates.</p> <p>/etc/nginx/conf.d/default.conf</p> <p>0644 root:root</p> <pre><code>include /etc/nginx/conf.d/include/context/map-hash-size-optimal;\ninclude /etc/nginx/conf.d/include/context/map-client-blacklist;</code></pre> <p>/etc/nginx/conf.d/include/context/map-hash-size-optimal</p> <p>0644 root:root</p> <pre><code># Increase hash table size for optimal map lookups.\nmap_hash_max_size 1024;\nmap_hash_bucket_size 128;</code></pre> <p>/etc/nginx/conf.d/include/context/map-client-blacklist</p> <p>0644 root:root</p> <pre><code>map $ssl_client_s_dn $cert_authz {\n  default SUCCESS;\n  \"emailAddress=XX,CN=XX,OU=XX,O=XX,L=XX,ST=XX,C=XX\" FAILURE;\n}</code></pre> <p>Note</p> <p>Subject DN can be found by inspecting the certificate:</p> <pre><code>openssl x509 -text -noout -in {CERT}</code></pre> <p>Order of Subject DN can be found by inspecting the response headers. See Debug Headers.</p> <p>/etc/nginx/conf.d/include/authz/enforce-blacklist</p> <p>0644 root:root</p> <pre><code># Blacklisted authz certs should 403.\nif ($cert_authz != SUCCESS) {\n  return 403;\n  break;\n}</code></pre> <p>/etc/nginx/conf.d/include/proxy/site</p> <p>0644 root:root</p> <pre><code>include /etc/nginx/conf.d/include/authn/cert/force-all-connections;\ninclude /etc/nginx/conf.d/include/authz/enforce-blacklist;</code></pre> <p>Note</p> <p>force-all-connections provides the authentication step. enforce-blacklist provides the authorization step.</p>"},{"location":"service/nginx/manual/cert_based_authentication/#git-configuration","title":"Git Configuration","text":"<p>Accessing a https based git repository behind a NGINX proxy requiring client certificate authentication is supported both locally and via URI matching.</p>"},{"location":"service/nginx/manual/cert_based_authentication/#git-cert-auth-for-repo-site","title":"Git Cert Auth for Repo Site","text":"<p>~/.gitconfig</p> <p>0400 {USER}:{USER}</p> <pre><code>[http \"https://git.example.com\"]\nsslCert = /home/user/{MACHINE}.crt.pem\nsslKey = /home/user/{MACHINE}.key.pem</code></pre>"},{"location":"service/nginx/manual/cert_based_authentication/#git-cert-auth-for-specific-repo","title":"Git Cert Auth for Specific Repo","text":"<pre><code>git config --local http.sslCert \"/home/user/{MACHINE}.crt.pem\"\ngit config --local http.sslKey \"/home/user/{MACHINE}.key.pem\"</code></pre> <p>Note</p> <p>--global will force certification authentication for all repositories. This is probably not what you want to do.</p> <p>.. _service-nginx-chrome-client-certificate:</p>"},{"location":"service/nginx/manual/cert_based_authentication/#chrome-client-certificate","title":"Chrome Client Certificate","text":"<p>Setup chrome to auto present correct certificate when challenged by proxy server.</p> <p>Import Client Certificate to Chrome</p> <p>chrome://settings \u2794 Settings \u2794 Advanced \u2794 Privacy and security \u2794 Manage certificates \u2794 Import</p> <ul> <li>Enable strong private key protection: \u2718</li> <li>Mark this key as exportable: \u2718</li> <li>Include all extended properties: \u2714</li> <li>Place all certificates in the following store: Personal \u2714</li> </ul> <p>Note</p> <p>Use export password to decrypt and import.</p> <p>Restart Chrome. Navigate to a proxied site and the certificate prompt should appear to select which cert to authenticate with. If NGINX has been reloaded and setup, then this should allow you to passthrough.</p>"},{"location":"service/nginx/manual/cert_based_authentication/#auto-select-client-certificate","title":"Auto-select Client Certificate","text":"<p>Auto selecting the correct certificate will enable transparent authentication for proxied sites. Enabled via Group Policy or Registry.</p> WindowsLinux <p>Auto-select Client Certificate (Windows)</p> <p><code>HKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Google\\Chrome\\AutoSelectCertificateForUrls</code></p> <p>Key: 1  # Resolution order for multiple certificates.</p> <p>Type: SZ</p> <p>Value: {\"pattern\":\"https://[*.]example.com\",\"filter\":{\"ISSUER\":{\"O\":\"{SERVER}\"}}}</p> <ul> <li>O is used to match the Organizational Name of the server CA   {SERVER}. This will use this certificate for all {SERVER} cert auth   requests.</li> </ul> <p>Regedit files require proper escaping</p> <pre><code>\"1\"=\"{\\\"pattern\\\":\\\"https://[*.]example.com\\\",\\\"filter\\\":{\\\"ISSUER\\\":{\\\"O\\\":\\\"{SERVER}\\\"}}}\"</code></pre> <p>/etc/opt/chrome/policies/managed/auto_select_certificate.json</p> <p>0644 root:root</p> <pre><code>{\n  \"AutoSelectCertificateForUrls\": [\n    \"{\\\"pattern\\\":\\\"https://[*.]example.com\\\",\\\"filter\\\":{\\\"ISSUER\\\":{\\\"O\\\":\\\"{SERVER}\\\"}}}\"\n  ]\n}</code></pre> <p>All directories on path must be readable by others.</p> <p>Restarting chrome will pickup the configuration changes.</p>"},{"location":"service/nginx/manual/cert_based_authentication/#firefox-client-certificate","title":"Firefox Client Certificate","text":"<p>Setup Firefox to auto present correct certificate when challenged by proxy server.</p> <p>Import Client Certificate to Firefox</p> <p>about:preferences#privacy \u2794 Certificates \u2794 OSCP \u2794 View Certificates \u2794 Your Certificates \u2794 Import</p> <p>Use export password to decrypt and import.</p> <p>Disable client certificate syncing</p> <p>about:config \u2794 Accept the Risk and Continue \u2794 services.sync.prefs.sync.security.default_personal_cert</p> <p>Value: False.</p> <p>Restart Firefox. Navigate to a proxied site and the certificate prompt should appear to select which cert to authenticate with. If NGINX has been reloaded and setup, then this should allow you to passthrough. Remember decision to prevent additional certificate prompts on revisit.</p>"},{"location":"service/nginx/manual/custom_error_pages/","title":"Custom Error Pages","text":""},{"location":"service/nginx/manual/custom_error_pages/#custom-error-pages","title":"Custom Error Pages","text":"<p>Setup a custom error page to serve all errors.</p> <p>Warning</p> <p>The root for web serving must be set for both the http and https server, otherwise it will default to what NGINX was built with. This will produce hard to debug errors if the page does not load.</p> <p>Set root web folder for http server. </p><pre><code>server {\n  ...\n  root /www;\n  ...\n}</code></pre><p></p> <p>Note</p> <p>This assumes http is redirected to https; so no error block needed.</p> <p>Set root web folder for https server and redirect all errors to custom page. </p><pre><code>server {\n  root       /www;\n  error_page 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 421 422 423 424 426 428 429 431 451 500 501 502 503 504 505 506 507 508 510 511 /error.html;\n  location = /error.html {\n    allow    all;\n    internal;\n    root     /www;\n  }\n}</code></pre><p></p> <ul> <li>Must be defined for each server block.</li> <li>Define in the server block before other rules.</li> <li>internal marks the location as internal redirect only.</li> <li>root is defined to enable image file serving for the error. Static error   pages do not need this, but a root should be defined regardless for   predictable behavior.</li> </ul> <p>source/error.html</p> <p>0644 root:root</p> <pre><code>&lt;html&gt;\n&lt;head&gt;\n&lt;style type=text/css&gt;\ndiv {\n  text-align: center;\n  font-family: sans-serif;\n  font-weight: bold;\n  font-size: 3em;\n  position: absolute;\n  top: 410px;\n  width: 100%;\n}\nbody {\n  background-repeat: no-repeat;\n  background-position: center top;\n  background-image: 1.png;\n}\n&lt;/style&gt;\n&lt;script type='text/javascript'&gt;\nfunction background(){\n  var BG = Math.ceil(Math.random() * 12);\n  document.body.background = 'https://example.com/img/' + BG + '.png';\n}\n&lt;/script&gt;\n&lt;/head&gt;\n&lt;/html&gt;\n&lt;body onload='background();'&gt;\n&lt;div&gt;Whoops.&lt;/div&gt;\n&lt;/html&gt;</code></pre> <p>Note</p> <p>This example randomly loads a background image when the page is loaded.</p>"},{"location":"service/nginx/manual/setup/","title":"Setup","text":""},{"location":"service/nginx/manual/setup/#setup","title":"Setup","text":"<p>This will setup a basic reverse-proxy that</p> <ul> <li>Forces HTTP to HTTPS connections for IPv4/6 with a permanent redirect.</li> <li>Serves traffic only over SSL (443).</li> <li>Enables HTTP2 if the service behind the proxy supports it.</li> <li>Ability to upgrade a connection to a websocket if a service requires it.</li> <li>Direct requests to the proxy cannot contain data.</li> <li>Import SSL certificate settings used in Let's Encrypt for strong   validation of certificate usage.</li> </ul> <p>Automatic generator to generate base configuration templates.</p>"},{"location":"service/nginx/manual/setup/#setup-base-reverse-proxy","title":"Setup Base Reverse Proxy","text":"<p>/etc/nginx/conf.d/reverse_proxy.conf</p> <p>0644 root:root</p> <pre><code># Forward all HTTP IPv4/6 traffic to HTTPS.\nserver {\n  listen                 80 default_server;\n  listen                 [::]:80 default_server;\n  server_name            {SERVER DNS NAME};\n  return                 301 https://$server_name$request_uri;\n}\n\n# Websockets: remap http_upgrade to 'upgrade' or 'close' based on\n# connection_upgrade being set.\nmap $http_upgrade $connection_upgrade {\n  default                upgrade;\n  ''                     close;\n}\n\nserver {\n  listen                  443 ssl http2;\n\n  # Import SSL certificate options from letsencrypt\n  ssl_certificate         /etc/nginx/ssl/live/{DOMAIN NAME}/fullchain.pem;\n  ssl_certificate_key     /etc/nginx/ssl/live/{DOMAIN NAME}/privkey.pem;\n  ssl_trusted_certificate /etc/nginx/ssl/live/{DOMAIN NAME}/chain.pem;\n  ssl_dhparam             /etc/nginx/ssl/ssl-dhparams.pem;\n  include                 /etc/nginx/ssl/options-ssl-nginx.conf;\n\n  # Enable OCSP stapling https://en.wikipedia.org/wiki/OCSP_stapling.\n  ssl_stapling            on;\n  ssl_stapling_verify     on;\n  resolver                127.0.0.1;\n\n  client_max_body_size    0;\n}</code></pre> <ul> <li>The SERVER DNS NAME should be in the SSL certificate; a wildcard   certificate will work.</li> <li>ssl-dhparams.pem may be generated with <code>openssl dhparam -out   ssl-dhparams.pem 4096</code>.</li> <li>resolver should be set to a DNS resolver. localhost, gateway or pihole   are all viable options. Check logs to ensure resolution works.</li> </ul>"},{"location":"service/nginx/manual/setup/#setup-base-proxy-control","title":"Setup Base Proxy Control","text":"<p>A proxy control template will enable complex proxy configurations to be consistently applied to multiple proxy sites.</p> <p>/etc/nginx/conf.d/proxy_control.conf</p> <p>0644 root:root</p> <pre><code>client_max_body_size               10m;\nclient_body_buffer_size            128k;\n\n#Timeout if the real server is dead\nproxy_next_upstream                error timeout invalid_header http_500 http_502 http_503;\n\n# Advanced Proxy Config\nsend_timeout                       5m;\nproxy_read_timeout                 240;\nproxy_send_timeout                 240;\nproxy_connect_timeout              240;\n\n# Basic Proxy Config\nproxy_set_header Host              $host:$server_port;\nproxy_set_header X-Real-IP         $remote_addr;\nproxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;\nproxy_set_header X-Forwarded-Proto https;\nproxy_redirect                     http://  $scheme://;\nproxy_http_version                 1.1;\nproxy_set_header Connection        '';\nproxy_cache_bypass                 $cookie_session;\nproxy_no_cache                     $cookie_session;\nproxy_buffers                      32 4k;</code></pre> <p>Reload nginx configuration while running. </p><pre><code>nginx -s reload</code></pre><p></p>"},{"location":"service/postgres/","title":"PostgresQL","text":""},{"location":"service/postgres/#postgresql","title":"PostgresQL","text":"<p>Postgres is an opensource object-relational database.</p> <p>Migrated to ansible collection</p> <p>Use r_pufky.srv.postgres.</p>"},{"location":"service/postgres/#creating-a-database","title":"Creating a Database","text":"<p>Create new DB user and database. </p><pre><code>psql -U {ADMIN USER} -d postgres\n\nCREATE USER {DB USER} PASSWORD '{DB USER PASS}';\nCREATE DATABASE {DB USER};\n\nALTER DATABASE {DB USER} OWNER TO {DB USER};\nGRANT ALL PRIVILEGES ON DATABASE {DB USER} TO {DB USER};</code></pre><p></p>"},{"location":"service/postgres/#import-a-database","title":"Import a Database","text":"<p>Database dumps may be imported, but explicit table permissions need to be set for the DB user to access the data.</p> <p>Note</p> <p>Permissions need to be set if DB is not imported as the DB user. This assumes the database has already been created.</p> <p>Import DB and set appropriate DB permissions (download). </p><pre><code>psql -v ON_ERROR_STOP=1 --username {DB ADMIN} {DB} &lt; {DB DUMP}\npsql -U {ADMIN USER} -d postgres\n\nALTER DATABASE {DB USER} OWNER TO {DB USER};\nGRANT ALL PRIVILEGES ON DATABASE {DB USER} TO {DB USER};\n\\q\n\nfor tbl in `psql -U {DB ADMIN} -qAt -c \"select tablename from pg_tables where schemaname = 'public';\" {DB}`; do psql -U {DB ADMIN} -c \"alter table \\\"$tbl\\\" owner to {DB USER}\" {DB}; done\nfor tbl in `psql -U {DB ADMIN} -qAt -c \"select sequence_name from information_schema.sequences where sequence_schema = 'public';\" {DB}`; do psql -U {DB ADMIN} -c \"alter sequence \\\"$tbl\\\" owner to {DB USER}\" {DB}; done\nfor tbl in `psql -U {DB ADMIN} -qAt -c \"select table_name from information_schema.views where table_schema = 'public';\" {DB}`; do psql -U {DB ADMIN} -c \"alter view \\\"$tbl\\\" owner to {DB USER}\" {DB}; done</code></pre><p></p>"},{"location":"service/postgres/#database-backup","title":"Database Backup","text":"<p>This will dump all databases, users and permissions. Remember to pull the data from the instance or the data directory. </p><pre><code>pg_dumpall &gt; {DUMP FILE}.sql</code></pre><p></p> <p>Backup a specific database. Permissions will need to be restored with database. </p><pre><code>pg_dump -U {DB ADMIN} --no-owner {DB} &gt; {DUMP FILE}.sql</code></pre><p></p>"},{"location":"service/postgres/#query-active-connections","title":"Query Active Connections","text":"<p>Display client sessions that are currently connected to database.</p> <pre><code>select pid as process_id,\n     usename as username,\n     datname as database_name,\n     client_addr as client_address,\n     application_name,\n     backend_start,\n     state,\n     state_change\nfrom pg_stat_activity;</code></pre>"},{"location":"service/postgres/troubleshooting/","title":"Troubleshooting","text":""},{"location":"service/postgres/troubleshooting/#troubleshooting","title":"Troubleshooting","text":""},{"location":"service/postgres/troubleshooting/#collation-version-mismatch","title":"Collation Version Mismatch","text":"<p>Collation version changed on upgrade. Rebuild indexes.</p> <p>WARNING:  database \"{DB}\" has a collation version mismatch DETAIL:  The database was created using collation version 2.36, but the operating system provides version 2.41.</p> <pre><code># Update collation and re-index.\npsql -d \"{DB}\"\n\nALTER DATABASE \"{DB}\" REFRESH COLLATION VERSION;\n&gt; NOTICE:  changing version from 2.36 to 2.41\n&gt; ALTER DATABASE\n\nREINDEX DATABASE \"{DB}\";\n&gt; REINDEX</code></pre>"},{"location":"service/secure_boot/","title":"Secure Boot","text":""},{"location":"service/secure_boot/#secure-boot","title":"Secure Boot","text":"<p>Migrated to ansible collection</p> <p>Use r_pufky.deb.secure_boot.</p>"},{"location":"service/secure_boot/#manual-enable-secure-boot","title":"Manual Enable Secure Boot","text":"<pre><code>mokutil --sb-state\n&gt; SecureBoot disabled\n&gt; Platform is in Setup Mode\n\nmokutil --test-key /var/lib/dkms/mok.pub\n&gt; /var/lib/dkms/mok.pub is not enrolled\n\nmokutil --import /var/lib/dkms/mok.pub\nmokutil --list-new\nmokutil --enable-validation\nmokutil --timeout -1\nreboot</code></pre> On reboot enter the same password and confirm the new keys to be loaded. The system will reboot again with the new keys. <p>DKMS will automatically use keys from /var/lib/dkms/mok.* with the default Debian configuration /etc/dkms/framework.conf.</p>"},{"location":"service/secure_boot/#secure-boot-mok-password","title":"Secure Boot (MOK) Password","text":"<p>The mokutil password is not stored directly as plain text -- it is stored as a hashed value within the shim database on the system, which is accessed by the mokutil utility to manage Machine Owner Keys (MOKs) used for Secure Boot. When you enter the password, it is hashed and compared against the stored hash in the shim database.</p> <p>Password:</p> <ul> <li>Must be between 8-16 alphanumeric characters.</li> <li>Manually entered on console hardware for confirming secure boot changes.</li> <li>This is the password to enroll keys on the secure boot loader during boot.</li> <li>This is the password to enable/disable secure boot.</li> <li>Unique as it is stored hashed in firmware.</li> </ul>"},{"location":"service/secure_boot/#enrollment-process","title":"Enrollment Process","text":"<p>After enrolling a certificate (MOK) on reboot, Secure Boot will first validate Microsoft's shimx64.efi Secure Boot loader signature, then shimx64.efi will detect a MOK enrollment request. Boot process is interrupted and the blue MOK Manager screen appears. The password must be entered to completed the MOK enrollment and store the certificate in firmware. Reboot is forced to load the new certificate.</p> <p>Validates</p> <ul> <li>You are the user that started the process.</li> <li>You really want to complete the MOK registration process.</li> </ul>"},{"location":"service/secure_boot/#commands","title":"Commands","text":"<p>Commands which change state (validation, reset, enrollment, etc) require a reboot and manual confirmation of changes.</p>"},{"location":"service/secure_boot/#-sb-state","title":"--sb-state","text":"<p>Returns the current hardware state</p> <pre><code>mokuil --sb-state\n&gt; SecureBoot disabled\n&gt; Platform is in Setup Mode</code></pre> <ul> <li>SecureBoot can be either enabled or disabled; this is signature   validation.</li> <li>Platform ... shows firmware state; setup mode means BIOS enrollment   is in setup mode; meaning that secure boot options can be configured in the   BIOS. This should be set to <code>enabled</code>.</li> </ul>"},{"location":"service/secure_boot/#-test-key","title":"--test-key","text":"<p>Check if a key is enrolled.</p> <pre><code>mokutil --test-key /var/lib/dkms/mok.pub\n&gt; /var/lib/dkms/mok.pub is already enrolled</code></pre> <p>Exit Codes:</p> <ul> <li>0: not enrolled.</li> <li>1: already enrolled.</li> <li>255: invalid x509 format.</li> </ul>"},{"location":"service/secure_boot/#-generate-hash","title":"--generate-hash","text":"<p>Generate a valid password hash which may be loaded into firmware</p> <pre><code>mokutil --generate-hash={PASS}\n&gt; $6$DtG...$6Xjc...</code></pre>"},{"location":"service/secure_boot/#-import","title":"--import","text":"<p>Enrolls key secure boot. The key must be loaded before secure boot is enabled; otherwise the system may fail to boot. You can enroll and enable before rebooting, allowing this to be completed in one step.</p> <pre><code>mokutil --import /var/lib/dkms/mok.pub</code></pre>"},{"location":"service/secure_boot/#-enable-validation","title":"--enable-validation","text":"<p>Enables secure boot signature validation. System will halt when unsigned modules are loaded.</p> <p>A system can have secure boot enabled but not enforce signature verification. </p><pre><code>mokutil --enable-validation\nmokutil --disable-validation</code></pre><p></p>"},{"location":"service/secure_boot/#manually-generate-mok","title":"Manually generate MOK","text":"<p>DKMS automatically generates a MOK key when secure boot is enabled and modules require it; a key may not exist until these conditions are met.</p> <p>Manually generate a key with the same parameters. </p><pre><code>  openssl req -nodes -new -x509 -newkey rsa:2048 -outform DER -days 36500 -subj \"/CN=DKMS module signing key/\" -keyout mok.key -out mok.pub</code></pre><p></p>"},{"location":"service/secure_boot/#list-mok-certificate","title":"List MOK certificate","text":"<p>Useful to determine the current auto generated MOK key constraints or verifying keys.</p> <pre><code>openssl x509 -inform der -noout -text -in mok.pub</code></pre>"},{"location":"service/secure_boot/#set-timeout","title":"Set timeout","text":"<p>Skipping enrollment will cause enrollment requests to be deleted and potentially putting the system into an unbootable state until secure boot is disabled and the keys are re-enrolled. Disable timeout when MOK Manager has changes to process, preventing the system from skipping enrollment.</p> <pre><code>mokutil --timeout -1</code></pre>"},{"location":"service/secure_boot/#reference","title":"Reference<sup>1</sup><sup>2</sup><sup>3</sup><sup>4</sup><sup>5</sup><sup>6</sup><sup>7</sup>","text":"<ol> <li> <p>https://mjg59.dreamwidth.org/70348.html \u21a9</p> </li> <li> <p>https://old.reddit.com/r/linuxquestions/comments/1euuha4/please_help_error_message_verifying_shim_sbat/ \u21a9</p> </li> <li> <p>https://en.opensuse.org/openSUSE:UEFI#Reset_SBAT_string_for_booting_to_old_shim_in_old_Leap_image \u21a9</p> </li> <li> <p>https://forums.linuxmint.com/viewtopic.php?t=427297 \u21a9</p> </li> <li> <p>https://wiki.debian.org/SecureBoot#DKMS_and_secure_boot \u21a9</p> </li> <li> <p>https://github.com/jiazhang0/meta-efi-secure-boot/blob/master/README.md#mokutil-and-mok-manager \u21a9</p> </li> <li> <p>https://media.defense.gov/2023/Mar/20/2003182401/-1/-1/0/CTR-UEFI-SECURE-BOOT-CUSTOMIZATION-20230317.PDF \u21a9</p> </li> </ol>"},{"location":"service/secure_boot/troubleshooting/","title":"Troubleshooting","text":""},{"location":"service/secure_boot/troubleshooting/#troubleshooting","title":"Troubleshooting","text":""},{"location":"service/secure_boot/troubleshooting/#could-not-insert-zfs-key-was-rejected-by-service","title":"Could not insert 'zfs': Key was rejected by service","text":"<p>Secure boot enabled systems require the MOK (Machine Owner's Key) for signed DKMS modules to be loaded into the kernel, otherwise errors like the following will occur:</p> <p>/sbin/modprobe zfs</p> <p>modprobe: ERROR: could not insert 'zfs': Key was rejected by service</p> <p>Certificates must be added to secure boot certificate store before enabling secure boot; intentionally requires physical presence (or pre-existing keys to be installed during bare-metal turn-up via firmware/BIOS).</p> <p>mokutil manages this process and generates changes for MOK Manager (loaded by the secure boot shim) to process on next reboot.</p>"},{"location":"service/secure_boot/troubleshooting/#security-policy-violation","title":"Security Policy Violation","text":"<p>Microsoft changed secure boot shim and disabled previously allowed shims used in older installers.</p> <p>Verifying shim SBAT data failed: Security Policy Violation Something has gone seriously wrong: SBAT self-check failed: Security Policy Violation</p> <p>Disable secure boot, disable SBAT policy, and install updated shims.</p> <ol> <li>Disable secure boot.</li> <li>Boot live cd.</li> <li> <p>install mokutil and delete SBAT policy.</p> <pre><code>mokutil --set-sbat-policy delete</code></pre> </li> <li> <p>Reboot.</p> </li> <li>Update and re-enable secure boot.</li> </ol>"},{"location":"service/secure_boot/troubleshooting/#reference","title":"Reference<sup>1</sup><sup>2</sup><sup>3</sup><sup>4</sup>","text":"<ol> <li> <p>https://mjg59.dreamwidth.org/70348.html \u21a9</p> </li> <li> <p>https://old.reddit.com/r/linuxquestions/comments/1euuha4/please_help_error_message_verifying_shim_sbat/ \u21a9</p> </li> <li> <p>https://en.opensuse.org/openSUSE:UEFI#Reset_SBAT_string_for_booting_to_old_shim_in_old_Leap_image \u21a9</p> </li> <li> <p>https://forums.linuxmint.com/viewtopic.php?t=427297 \u21a9</p> </li> </ol>"},{"location":"service/ssh/","title":"SSH Client","text":""},{"location":"service/ssh/#ssh-client","title":"SSH Client","text":""},{"location":"service/ssh/#create-certificates","title":"Create Certificates","text":"<p>Use a Yubikey GPG Key (Linux) or Yubikey GPG Key (Windows).</p> <p>Alternatively use a strong password on keys that is not your login password.</p>"},{"location":"service/ssh/#generate-4096-bit-rsa-certificates-add-user-to-ssh-group","title":"Generate 4096 bit RSA certificates &amp; add user to SSH group","text":"<pre><code># Always use a strong password that is not a login password.\nssh-keygen -b 4096 -t rsa -f /home/{USER}/.ssh/{KEY_NAME}\n\n# Add public key to any authorized_keys on any host to enable login.\n# This is the published GPG identity for Yubikeys.\ncat /home/{USER}/.ssh/{KEY_NAME}.pub &gt;&gt; home/{USER}/.ssh/authorized_keys\n\nchmod 0600 /home/{USER}/.ssh/*\nchmod 0640 /home/{USER}/.ssh/*.pub\naddgroup {USER} _ssh</code></pre> <p>Note</p> <p>The private key {KEY_NAME} needs to be used to SSH into this host. Copy the public key {KEY_NAME}.pub to the authorized_keys on other hosts to be able to login to those hosts.</p>"},{"location":"service/ssh/#importing-rsa-keys-for-puttywinscp-windows","title":"Importing RSA Keys for Putty/WinSCP (Windows)","text":"<ol> <li>Copy RSA private key to windows computer.</li> <li>\u2318 + r \u2794 puttygen \u2794 Conversions \u2794 Import Key (Select Private Key)</li> <li>Rename Key Comment to user@server.</li> <li>Save private key in a .ppk file to local machine.</li> <li>Delete RSA keys (use sdelete64).</li> <li>Update public key in authorized_keys file with comment about key being    used.</li> </ol>"},{"location":"service/ssh/#restricting-ssh-tunneling","title":"Restricting SSH Tunneling","text":"<p>Restrict what local ports and IP's can be accessed via SSH tunneling.</p> <p>~/.ssh/authorized_keys</p> <p>0600 {USER}:{USER}</p> <pre><code># All on one line, comma separated with the public key cert afterwards.\nno-X11-forwarding,permitopen=\"localhost:80\",permitopen=\"localhost:4243\",permitopen=\"10.10.10.10:32400\" {PUBKEY}\n# no-port-forwarding: Disable all port forwarding.\n# no-X11-forwarding: Disable X11 forwarding.\n# no-agent-forwarding: Disable agent forwarding.\n# permitopen: Explicitly allow port to be opened.\n#\n# Disable X11 forwarding but allow ports 80, 4243, 32400 to be forwarded.</code></pre>"},{"location":"service/ssh/#forward-ports-through-ssh-connection","title":"Forward ports through SSH connection","text":"<p>Useful for accessing services inside another network. May be specified multiple times.</p> <pre><code># -L 1000:10.10.10.10:8888 - client: localhost:1000 -&gt; host: 10.10.10.10:8888\nssl -L {LOCAL_PORT}:{INTERNAL_HOST}:{INTERNAL_PORT} user@example -p {PORT}</code></pre>"},{"location":"service/ssh/#ssh-host-configuration","title":"SSH Host Configuration","text":"<p>Setup SSH to automatically select correct options when using hosts/shortcuts.</p> <p>~/.ssh/config</p> <p>0600 {USER}:{USER}</p> <pre><code># Autoselect github keys\nHost *.github.com github.com\n  User {GITHUB_USERNAME}\n  HostName *.github.com github.com\n  Port 443\n  PreferredAuthentications publickey\n  IdentityFile ~/.ssh/github\n\nHost {CUSTOM_NAME}\n  HostName {IP_OR_DNS}\n  User {AUTH_USER}\n  IdentityFile ~/.ssh/{CERT}\n  BatchMode yes\n  CheckHostIP no\n  PasswordAuthentication no\n  KbdInteractiveAuthentication no\n  PreferredAuthentications publickey\n  StrictHostKeyChecking no\n  Port {PORT}</code></pre>"},{"location":"service/ssh/troubleshooting/","title":"Troubleshooting","text":""},{"location":"service/ssh/troubleshooting/#troubleshooting","title":"Troubleshooting","text":""},{"location":"service/ssh/troubleshooting/#ssh-pubkey-authentication-with-locked-accounts-does-not-work","title":"SSH pubkey authentication with locked accounts does not work","text":"<p>Locked accounts cannot SSH pubkey auth.  SSH now distinguishes between ! and * password locking.</p> <p>*: Lock password - allow SSH pubkey auth.</p> <p>!: Lock password - deny SSH pubkey auth.</p> <p>Any other means to lock the password will result in SSH pubkey failures.</p> <p>Danger</p> <p>Do NOT set UsePam=yes as this leads to security vulnerabilities.</p>"},{"location":"service/ssh/troubleshooting/#debian-ssh-group-no-longer-works","title":"Debian ssh group no longer works","text":""},{"location":"service/ssh/troubleshooting/#ssh-group-now-_ssh","title":"ssh group now _ssh","text":"<p>ssh group migrated to _ssh in Trixie.</p> <p>ssh group must be manually managed if used with existing users and groups, or migrate users to _ssh.</p>"},{"location":"service/ssh/troubleshooting/#enable-debug-mode","title":"Enable Debug Mode","text":"<p>Print verbose messages to /var/log/syslog to help in debugging issues.</p> <p>/etc/default/ssh</p> <p>0644 root:root</p> <pre><code>SSHD_OPTS=-ddd</code></pre> <pre><code>systemctl daemon-reload\nservice ssh restart</code></pre> <p>Note</p> <p>After a login attempt, the service may need to be restarted to test again.</p> <p>Check `/var/log/syslog for debug information.</p>"},{"location":"service/ssh/troubleshooting/#could-not-open-authorized-keys-permission-denied","title":"Could not open authorized keys: Permission denied","text":"<p>The keyfile could not be accessed. This generally happens when SSHD drops privileges to the user when logging in and the user cannot access the keyfile.</p> <ol> <li>Directory containing keyfile is readable and executable by the user.</li> <li>Keyfile is 0600.</li> </ol>"},{"location":"service/ssh/troubleshooting/#gpg-pinentry-not-redirecting-to-correct-terminal","title":"GPG pinentry not redirecting to correct terminal","text":"<p>GPG connect agent must be informed when on a new terminal.</p> <p>Manually </p><pre><code>gpg-connect-agent updatestartuptty /bye</code></pre><p></p> <p>~/.ssh/config</p> <p>0640 {USER}:{USER}</p> <pre><code>Match host * exec \"gpg-connect-agent updatestartuptty /bye\"</code></pre>"},{"location":"service/ssh/sshd/linux/","title":"Linux","text":""},{"location":"service/ssh/sshd/linux/#linux","title":"Linux","text":""},{"location":"service/ssh/sshd/linux/#require-certificate-and-disable-root-logins","title":"Require Certificate and disable root logins","text":"<p>This will provide a default configuration which only allows non-root public key authenticated users to login.</p> <pre><code>AllowAgentForwarding no\nAllowGroups _ssh\nAuthorizedKeysFile %h/.ssh/authorized_keys\nChallengeResponseAuthentication no\nHostbasedAuthentication no\nPasswordAuthentication no\nPermitEmptyPasswords no\nPermitRootLogin no\nPubkeyAuthentication yes\nRSAAuthentication no\nRhostsRSAAuthentication no\nStreamLocalBindUnlink yes\nUsePrivilegeSeparation yes</code></pre>"},{"location":"service/ssh/sshd/linux/#add-users-to-access-group","title":"Add Users to Access Group","text":"<pre><code>addgroup {USER} _ssh\nsystemctl restart ssh</code></pre>"},{"location":"service/ssh/sshd/linux/#allow-ssh-connections-through-ufw","title":"Allow SSH Connections Through UFW","text":"<p>UFW may be configured by default to block connections, verify this is not the case. The general default is to deny incoming connections, allow outgoing, and enable SSH.</p> <pre><code>ufw status\n\n# Deny incoming connections except SSH, allow outgoing.\nufw default deny incoming\nufw default allow outgoing\nufw allow ssh</code></pre>"},{"location":"service/ssh/sshd/linux/#create-a-port-forwarding-only-user","title":"Create a Port Forwarding Only User","text":"<p>Useful to forward services without providing shell a login.</p> <pre><code>adduser --disabled-password --home /etc/ssh/port-forwards-only --shell /bin/false port-forwards-only\naddgroup port-forwards-only ssh\nmkdir /etc/ssh/port-forwards-only\nchmod 0700 /etc/ssh/port-forwards-only\nchown port-forwards-only:port-forwards-only /etc/ssh/port-forwards-only\nssh-keygen -b 4096 -t rsa -f /etc/ssh/port-forwards-only/port-forwards-only\ncat /etc/ssh/port-forwards-only/port-forwards-only.pub &gt;&gt; /etc/ssh/port-forwards-only/authorized_keys</code></pre>"},{"location":"service/ssh/sshd/linux/#verify-restrictions","title":"Verify Restrictions","text":"<p>Attempt to login with a shell as well as port forwarding working.</p> <pre><code># Only port forwarding should work (-N). Interactive logins with and without\n# cert should fail.\nssh -vvv -N -L 5901:{SERVER}:5900 -i ~/.ssh/port-forwards-only port-forwards-only@{SERVER}\nssh -vvv -i ~/.ssh/port-forwarding-only port-forwards-only@{SERVER}\nssh -vvv -i port-forwards-only@{SERVER}</code></pre>"},{"location":"service/ssh/sshd/windows/","title":"Windows","text":""},{"location":"service/ssh/sshd/windows/#windows","title":"Windows","text":""},{"location":"service/ssh/sshd/windows/#enable-sshd","title":"Enable SSHD","text":"<p>\u2318 + r \u2794 ms-settings:optionalfeatures \u2794 OpenSSH \u2794 Install</p> <p>\u2318 \u2794 services.msc \u2794 OpenSSH SSH Server</p> <ul> <li>Startup type: {AUTOMATIC}</li> </ul> <p>Allow SSH through Windows Firewall </p><pre><code># Run as administrator.\nNew-NetFirewallRule -Name sshd -DisplayName 'OpenSSH Server (sshd)' -Enabled True -Direction Inbound -Protocol TCP -Action Allow -LocalPort 22</code></pre><p></p>"},{"location":"service/ssh/sshd/windows/#set-up-publickey-authentication","title":"Set up publickey authentication","text":"<p>Grant SSHD service read permissions to .ssh directory. </p><pre><code>mkdir c:\\Users\\{USER}\\.ssh\n\nicacls c:\\users\\{USER}\\.ssh /grant \"NT Service\\sshd:R\" /T</code></pre><p></p>"},{"location":"service/traefik/","title":"Traefik","text":""},{"location":"service/traefik/#traefik","title":"Traefik","text":"<p>Application Proxy.</p> <p>Migrated to ansible collection</p> <p>Use r_pufky.srv.traefik</p> <p>Tip</p> <ul> <li>All defined routes are required to have a router, optionally   middleware, and a backend service.</li> <li>Using @file instructs Traefik to locate router/middleware/service   definitions in local files.</li> <li>Items defined in web and webs are applied globally to all routers   that use that entrypoint. Middleware is layered with additional router   definitions.</li> <li>Examples use separate dynamic configuration files but it may be more   beneficial in complex configurations to group definitions together by   functionality (e.g. dynamic/media.yml or dynamic/hypervisor.yml).</li> </ul>"},{"location":"service/traefik/#concepts","title":"Concepts","text":""},{"location":"service/traefik/#install-configuration-traefikyml","title":"Install Configuration (traefik.yml)","text":"<p>Contains all parameters that require a restart of Traefik. This is typically stored in traefik.yml.</p>"},{"location":"service/traefik/#routing-configuration-dynamic","title":"Routing Configuration (dynamic)","text":"<p>Contains all parameters that do not require a service restart and are reloaded on file changes. This is typically stored in a dynamic directory.</p> <p>Examples here use file providers for non-docker/kubernetes installs. There are plenty of non-file examples.</p>"},{"location":"service/traefik/#routers","title":"Routers","text":"<p>Define how incoming connections through entrypoints are directed to backend services, optionally applying middleware as well as connection requirements.</p> <p>HTTP Routing</p> <p>TCP Routing</p> <p>UDP Routing</p>"},{"location":"service/traefik/#middleware","title":"Middleware","text":"<p>Note</p> <p>Traefik uses middlewares in configuration but middleware in documentation.</p> <p>Manipulates incoming connection requests before sending to the backend service or before responding to the client. UDP does not have middleware - Traefik does maintain state to response to the correct clients - backend services must manage this themselves.</p> <p>HTTP Middleware</p> <p>TCP Middleware</p> <p>Middleware chained together using effectively grouping middleware in a group to apply consistently across many routers.</p>"},{"location":"service/traefik/#service","title":"Service","text":"<p>Defines how incoming connections are distributed to backend services. All services are load-balanced, even if there is only one backend.</p> <p>HTTP Service</p> <p>TCP Service</p> <p>UDP Service</p>"},{"location":"service/traefik/#reference","title":"Reference<sup>1</sup><sup>2</sup>","text":"<ol> <li> <p>https://traefik.io/traefik \u21a9</p> </li> <li> <p>https://github.com/Haxxnet/Compose-Examples/blob/main/examples/traefik/traefik.yml \u21a9</p> </li> </ol>"},{"location":"service/traefik/basic_auth_dashboard/","title":"Basic Auth Dashboard","text":""},{"location":"service/traefik/basic_auth_dashboard/#basic-auth-dashboard","title":"Basic Auth Dashboard","text":"<p>Force API/Dashboard to be served with Basic Auth on local networks only.</p> <p>/etc/traefik/traefik.yml</p> <p>0640 traefik:traefik </p><pre><code>---\nlog:\n  level: 'DEBUG'\n  format: 'json'\n\naccessLog:\n  format: 'json'\n\napi:\n  dashboard: true\n  disableDashboardAd: true\n  # Enabling insecure will automatically serve the dashboard on :8080.\n  insecure: false\n  debug: true\n\n# Skip TLS verification for backend servers.\nserversTransport:\n  insecureSkipVerify: true\n\n# Redirect all HTTP to HTTPS.\nentryPoints:\n  web:\n    address: ':80'\n    http:\n      redirections:\n        entryPoint:\n          to: 'webs'\n          scheme: 'https'\n          permanent: true\n  webs:\n    address: ':443'\n    asDefault: true\n    http:\n      # Without parameters auto create self-signed certificate.\n      tls: {}\n\n      # Only apply global middleware here. If there are various services\n      # with different requirements - it is better to explicitly define\n      # each middlewares section on each router - allowing for flexible\n      # deployments (e.g. passthrough connections to backends like mail).\n      middlewares:\n        # Leaving basic_auth_users@file off would require **each**\n        # router to explicitly enable it or be unauthenticated.\n        - 'basic_auth_users@file'\n\n# Dynamically load all other configuration.\nproviders:\n  file:\n    directory: '/etc/traefik/dynamic'\n    watch: true</code></pre><p></p> <p>/etc/traefik/dynamic/routers.yml</p> <p>0640 traefik:traefik </p><pre><code>---\nhttp:\n  routers:\n    basic_auth_dashboard:\n      # Require basic auth over HTTPS on local network only.\n      #\n      # Both /api and /dashboard are required to serve the dashboard.\n      #\n      # api@internal uses dashboard@internal to serve.\n      rule: 'Host(`{TRAEFIK_IP}`) &amp;&amp; ClientIP(`{CLIENT_CIDR}`) &amp;&amp; (PathPrefix(`/api`) || PathPrefix(`/dashboard`))'\n      tls: true\n      entryPoints:\n        - 'webs'\n      service: 'api@internal'</code></pre><p></p> <p>/etc/traefik/dynamic/middleware.yml</p> <p>0640 traefik:traefik </p><pre><code>---\n# Basic authentication users.\n#\n# Create user/pass with brypt hash:\n#\n#   htpasswd -nB {USER}\n#\nhttp:\n  middlewares:\n    basic_auth_users:\n      basicAuth:\n        users:\n          - 'TestUser:$2y$05$kXi9l8LVD3CzwRJpeJ6LwOZzujE/24XppeM.xm0xyT7mWFaBqPK9q'</code></pre><p></p>"},{"location":"service/traefik/error_pages/","title":"Error Pages","text":""},{"location":"service/traefik/error_pages/#error-pages","title":"Error Pages","text":"<p>Return custom error pages for all service responses and Traefik errors.</p>"},{"location":"service/traefik/error_pages/#serving-error-pages","title":"Serving Error Pages","text":"<p>Use NGINX or a custom server locally on the Traefik proxy to serve error pages only. tarampampam/error-pages provide excellent templates.</p> <p>Install NGINX and create a static location for error pages.</p> <p>/etc/nginx/nginx.conf</p> <p>0644 root:root </p><pre><code>user nginx;\nworker_processes auto;\npid /run/nginx.pid;\n\nevents {\n  worker_connections 1024;\n}\n\n# Do not log (Traefik will log) - default to 500 error page.\nhttp {\n  include /etc/nginx/mime.types;\n  access_log off;\n  error_log /dev/null crit;\n  sendfile on;\n  tcp_nopush on;\n  keepalive_timeout 65;  # Reuse Traefik connections if multiple hits.\n  gzip on;\n  default_type application/octet-stream;\n  server {\n    listen 8008;\n    server_name localhost;\n    location / {\n        root /usr/share/nginx;\n        index 500.html 500.htm;\n    }\n  }\n}</code></pre><p></p>"},{"location":"service/traefik/error_pages/#routing-error-pages","title":"Routing Error Pages","text":"<p>/etc/traefik/traefik.yml</p> <p>0640 traefik:traefik </p><pre><code>---\nlog:\n  level: 'DEBUG'\n  format: 'json'\naccessLog:\n  format: 'json'\napi:\n  dashboard: true\n  disableDashboardAd: true\n  insecure: false\n  debug: true\nserversTransport:\n  insecureSkipVerify: true\nentryPoints:\n  web:\n    address: ':80'\n    http:\n      redirections:\n        entryPoint:\n          to: 'webs'\n          scheme: 'https'\n          permanent: true\n  webs:\n    address: ':443'\n    asDefault: true\n    http:\n      tls: {}\n      middlewares:\n        - 'basic_auth_users@file'\n        # Apply error pages to all routed connections.\n        - 'default_error_page@file'\n\nproviders:\n  file:\n    directory: '/etc/traefik/dynamic'\n    watch: true</code></pre><p></p> <p>Warning</p> <p>Highly recommend enabling geoblock and rate limiting when responding to ALL URLs requested.</p> <p>/etc/traefik/dynamic/routers.yml</p> <p>0640 traefik:traefik </p><pre><code>---\nhttp:\n  routers:\n    default_error_page:\n      # Use custom error pages for all errors.\n      #\n      # Using priority 1 ensures that this is the lowest priority rule for\n      # any router, effectively creating a fallback route for all services\n      # to return an error page.\n\n      # Response to ALL URLs requested, not just defined ones.\n      rule: 'HostRegexp(`^.+$`)'\n\n      # Only send custom error pages for requests setting 'host' headers.\n      # rule: 'HostRegexp(`{host:.+}`)'\n\n      priority: 1\n      entryPoints:\n        - 'webs'\n      service: 'default_error_page'</code></pre><p></p> <p>/etc/traefik/dynamic/middleware.yml</p> <p>0640 traefik:traefik </p><pre><code>---\nhttp:\n  middlewares:\n    # Redirect all error status results to NGINX error pages.\n    default_error_page:\n      errors:\n        status: '400-599'\n        service: 'default_error_page'\n        query: '/{status}.html'</code></pre><p></p> <p>/etc/traefik/dynamic/services.yml</p> <p>0640 traefik:traefik </p><pre><code>http:\n  services:\n    # Define NGINX as backend service to handle error pages.\n    default_error_page:\n      loadbalancer:\n        servers:\n          - url: 'http://localhost:8008'</code></pre><p></p>"},{"location":"service/traefik/odic/","title":"OIDC","text":""},{"location":"service/traefik/odic/#oidc","title":"OIDC","text":"<p>Open Identity Connect provides open authentication for users in the form of JWT claims without needing to handle passwords directly.</p> <p>Authentication (authn) is not Authorization (authz)</p> <p>This proves who the user is but not what they should have access to. Any valid user will successfully login to any proxied site.</p> <p>Additional middleware or per backend configuration needs to authorize those authenticated users to access that data.</p> <p>OIDC does not require 2FA authentication</p> <p>Users who do not have security keys / passkeys / SMS enabled on their OIDC account will still be able to provide valid authentication with only a password that meets the minimum provider OIDC requirements.</p> <p>Using Google Identity Platform can force 2FA but requires paying for the service on each domain.</p> <p>This provides the identity of entity making the client request but it does not prove who they are - 2FA should be used for that.</p> <p>mTLS Highly Recommended</p> <p>Consider using Mutual TLS (mTLS) as an additional layer of security in which both client and server validate each other.</p>"},{"location":"service/traefik/odic/#traefik-oauth","title":"Traefik Oauth","text":"<p>Google Oauth is free.</p>"},{"location":"service/traefik/odic/#create-google-cloud-project","title":"Create Google Cloud Project","text":"<p>console.cloud.google.com \u2794 ctrl + o \u2794 New project</p> <ul> <li>Project name: Traefik Forward Auth</li> <li>Location: No organization</li> </ul>"},{"location":"service/traefik/odic/#configure-oauth-consent-screen","title":"Configure Oauth Consent Screen","text":"<p>console.cloud.google.com \u2794 ctrl + o \u2794 Traefik Forward Auth \u2794 APIs &amp; Services \u2794 Oauth consent screen \u2794 Get started</p> <ul> <li>App Information:<ul> <li>App name: Traefik Auth</li> <li>User support email: {GMAIL}</li> </ul> </li> <li>Audience:<ul> <li>External: \u2714</li> </ul> </li> <li>Contact Information: {GMAIL}  # Notifications about project changes.</li> <li>Finish:<ul> <li>I agree to the Google API Services User Data Policy: \u2714</li> </ul> </li> </ul>"},{"location":"service/traefik/odic/#add-authorized-domains-and-publish-oauth","title":"Add Authorized Domains and Publish Oauth","text":"<p>No restricted scopes or test users are required to be defined. User will be filtered with Traefik plugins.</p> <p>console.cloud.google.com \u2794 ctrl + o \u2794 Traefik Forward Auth \u2794 APIs &amp; Services \u2794 Oauth consent screen \u2794 Branding</p> <ul> <li>Authorized domains: {DOMAIN}</li> </ul> <p>Be sure to save changes.</p> <p>console.cloud.google.com \u2794 ctrl + o \u2794 Traefik Forward Auth \u2794 APIs &amp; Services \u2794 Oauth consent screen \u2794 Audience</p> <ul> <li>Testing: Publish App</li> </ul>"},{"location":"service/traefik/odic/#create-oauth-credentials-for-traefik-service","title":"Create Oauth credentials for Traefik Service","text":"<p>Creates a Traefik web application client ID used for requesting OIDC authentication of a user.</p> <p>console.cloud.google.com \u2794 ctrl + o \u2794 Traefik Forward Auth \u2794 APIs &amp; Services \u2794 Credentials \u2794 Create credentials \u2794 OAuth client ID</p> <ul> <li>Application type: Web application</li> <li>Name: Traefik Oauth</li> <li>authorized redirect URIs:<ul> <li>https://example.com/oauth2/callback</li> <li>https://{SUBDOMAIN}.example.com/oauth2/callback</li> </ul> </li> </ul> <p>Create a redirect URI for all domains and subdomains - Google Oauth2.0 does not support wildcards.</p> <p>Download corresponding JSON file.</p> <p>Note Client ID and Client secret for next step.</p>"},{"location":"service/traefik/odic/#whitelist-authenticated-gmail-users","title":"Whitelist Authenticated gmail users","text":"<p>/etc/traefik/traefik.yml</p> <p>0640 traefik:traefik </p><pre><code>---\nlog:\n  level: 'DEBUG'\n  format: 'json'\naccessLog:\n  format: 'json'\napi:\n  dashboard: true\n  disableDashboardAd: true\n  insecure: false\n  debug: true\nserversTransport:\n  insecureSkipVerify: true\nentryPoints:\n  web:\n    address: ':80'\n    http:\n      redirections:\n        entryPoint:\n          to: 'webs'\n          scheme: 'https'\n          permanent: true\n  webs:\n    address: ':443'\n    asDefault: true\n    http:\n      tls:\n        certResolver: 'lets_encrypt'\n        domains:\n          - main: 'example.com'\n            sans: '*.example.com'\n      middlewares:\n        - 'google_email_whitelist@file'  # Use ODIC to whitelist users.\n        - 'default_error_page@file'\n        - 'geoblock_cn_ru@file'\n\ncertificatesResolvers:\n  lets_encrypt:\n    acme:\n      email: 'contact@example.com'\n      storage: '/var/lib/traefik/acme.json'\n      caServer: 'https://acme-v02.api.letsencrypt.org/directory'\n      dnsChallenge:\n        provider: 'gcloud'\n        resolvers:\n          - 'ns-cloud-e1.googledomains.com.'\n          - 'ns-cloud-e2.googledomains.com.'\n          - 'ns-cloud-e3.googledomains.com.'\n          - 'ns-cloud-e4.googledomains.com.'\n        propagation:\n          delayBeforeChecks: '120s'\n          disableChecks: true\n\nproviders:\n  file:\n    directory: '/etc/traefik/dynamic'\n    watch: true\n\nexperimental:\n  plugins:\n    geoblock:\n      moduleName: 'github.com/PascalMinder/geoblock'\n      version: 'v0.3.3'\n    traefikoidc:\n      moduleName: 'github.com/lukaszraczylo/traefikoidc'\n      version: 'v0.7.10'</code></pre><p></p> <p>See Auth0 audience guide for token validation.</p> <p>/etc/traefik/dynamic/middleware.yml</p> <p>0640 traefik:traefik </p><pre><code>---\nhttp:\n  middlewares:\n    # Only allow authenticated Google users.\n    google_email_whitelist:\n      plugin:\n        traefikoidc:\n          providerURL: 'https://accounts.google.com'\n          clientID: '{CLIENT_ID}'\n          clientSecret: '{CLIENT_SECRET}'\n          # Generate random key with: openssl rand -hex 16\n          sessionEncryptionKey: '{RANDOM_KEY}'\n\n          # When sharing services between multiple subdomains a shared\n          # cookie domain is required to prevent CSRF token missing in\n          # session errors. Reduces security posture.\n          cookieDomain: '.example.com'\n\n          # Redirect URI used in configuration.\n          callbackURL: '/oauth2/callback'\n          logoutURL: '/oauth2/logout'\n\n          # Require HTTPS for redirect URI's.\n          forceHTTPS: true\n\n          # Reject sessions with audience mis-match.\n          strictAudienceValidation: true\n\n          # Opaque (non-JWT) detection and inspection.\n          allowOpaqueTokens: true\n          requireTokenIntrospection: true\n\n          # Force re-auth every hour.\n          sessionMaxAge: 3600\n\n          scopes:\n            - roles  # Appended to defaults: openid, profile, email, roles\n\n          # Only Authenticated users below will be allowed.\n          allowedUsers:\n            - '{USER}@gmail.com'</code></pre><p></p>"},{"location":"service/traefik/odic/#reference","title":"Reference<sup>1</sup><sup>2</sup>","text":"<ol> <li> <p>https://www.simplehomelab.com/google-oauth-traefik-forward-auth-2024/ \u21a9</p> </li> <li> <p>https://github.com/lukaszraczylo/traefikoidc \u21a9</p> </li> </ol>"},{"location":"service/traefik/plugins/","title":"Plugins","text":""},{"location":"service/traefik/plugins/#plugins","title":"Plugins","text":"<p>Traefik may expand base capabilities through plugins.</p> <p>Warning</p> <p>Be sure to carefully look at plugins before installing, including source code. Many plugins are copied and slightly modified for specific use cases. In most cases the plugin with the most stars is the one to use.</p> <p>https://plugins.traefik.io/plugins</p> <p>Tip</p> <p>Plugins must always be defined in the install configuration. Each plugin beyond enablement requires different setup.</p> <p>/etc/traefik/traefik.yml</p> <p>0640 traefik:traefik </p><pre><code>---\nlog:\n  level: 'DEBUG'\n  format: 'json'\naccessLog:\n  format: 'json'\napi:\n  dashboard: true\n  disableDashboardAd: true\n  insecure: false\n  debug: true\nserversTransport:\n  insecureSkipVerify: true\nentryPoints:\n  web:\n    address: ':80'\n    http:\n      redirections:\n        entryPoint:\n          to: 'webs'\n          scheme: 'https'\n          permanent: true\n  webs:\n    address: ':443'\n    asDefault: true\n    http:\n      tls: {}\n      middlewares:\n        - 'basic_auth_users@file'\n        - 'default_error_page@file'\n        # Block Russia and China IP address at entrypoint.\n        - 'geoblock_cn_ru@file'\nproviders:\n  file:\n    directory: '/etc/traefik/dynamic'\n    watch: true\n\nexperimental:\n  plugins:\n    # Enable IP blocking by country.\n    geoblock:\n      moduleName: 'github.com/PascalMinder/geoblock'\n      version: 'v0.3.3'</code></pre><p></p> <p>/etc/traefik/dynamic/middleware.yml</p> <p>0640 traefik:traefik </p><pre><code>---\nhttp:\n  middlewares:\n    geoblock_cn_ru:\n      plugin:\n        geoblock:\n          silentStartUp: false\n          allowLocalRequests: true\n          logLocalRequests: false\n          logAllowedRequests: false\n          logApiRequests: false\n          api: 'https://get.geojs.io/v1/ip/country/{ip}'\n          apiTimeoutMs: 750\n          cacheSize: 15\n          forceMonthlyUpdate: false\n          allowUnknownCountries: false\n          unknownCountryApiResponse: \"nil\"\n          blackListMode: true\n          addCountryHeader: false\n          countries:\n            - 'RU'\n            - 'CN'</code></pre><p></p>"},{"location":"service/traefik/rate_limiting/","title":"Rate Limiting","text":""},{"location":"service/traefik/rate_limiting/#rate-limiting","title":"Rate Limiting","text":"<p>Rate limit traffic through Traefik.</p> <p>/etc/traefik/traefik.yml</p> <p>0640 traefik:traefik </p><pre><code>---\nlog:\n  level: 'DEBUG'\n  format: 'json'\naccessLog:\n  format: 'json'\napi:\n  dashboard: true\n  disableDashboardAd: true\n  insecure: false\n  debug: true\nserversTransport:\n  insecureSkipVerify: true\nentryPoints:\n  web:\n    address: ':80'\n    http:\n      redirections:\n        entryPoint:\n          to: 'webs'\n          scheme: 'https'\n          permanent: true\n  webs:\n    address: ':443'\n    asDefault: true\n    http:\n      tls: {}\n      middlewares:\n        # See comment in middlewares for chaining.\n        # - 'basic_geoblock_errorpages'\n\n        # Rate limiting applied here will apply to ALL traffic through this\n        # entrypoint. Instead rate limit on the router.\n        # - 'global_rate_limit@file'\n        - 'basic_auth_users@file'\n        - 'default_error_page@file'\nproviders:\n  file:\n    directory: '/etc/traefik/dynamic'\n    watch: true</code></pre><p></p> <p>/etc/traefik/dynamic/routers.yml</p> <p>0640 traefik:traefik </p><pre><code>---\nhttp:\n  routers:\n    # Serve all URLs requested with a global rate limit.\n    default_error_page:\n      rule: 'HostRegexp(`(.*?)`)'\n      priority: 1\n      entryPoints:\n        - 'webs'\n      middlewares:\n        # See comment in middlewares for chaining.\n        # - 'basic_geoblock_errorpages'\n        - 'global_rate_limit_error_page'\n      service: 'default_error_page'</code></pre><p></p> <p>/etc/traefik/dynamic/middleware.yml</p> <p>0640 traefik:traefik </p><pre><code>---\nhttp:\n  middlewares:\n    # A middleware chain creates a 'group' of middleware to apply to a\n    # given entryPoint or router.\n    basic_geoblock_errorpages:\n      chain:\n        middlewares:\n          - 'basic_auth_users'  # @file only needed if not in this file.\n          - 'default_error_page'\n          - 'global_rate_limit_error_page'\n\n    global_rate_limit_error_page:\n      # Global rate limit for error pages (100r/s, burst to 200r/s).\n      rateLimit:\n        average: 100\n        period: '1s'\n        burst: 200</code></pre><p></p>"},{"location":"service/traefik/troubleshooting/","title":"Troubleshooting","text":""},{"location":"service/traefik/troubleshooting/#troubleshooting","title":"Troubleshooting","text":""},{"location":"service/traefik/troubleshooting/#oidc-device_id-and-device_name-are-required-for-private-ip","title":"OIDC device_id and device_name are required for private IP","text":"<p>OIDC requires HTTPS with validate certificates. Internal IP's do not have these.</p> <pre><code>\ndevice_id and device_name are required for private IP: https://{IP}/oauth2/callback Learn more about this error\nIf you are a developer of Traefik Auth ...\nError 400: invalid_request</code></pre> <p>Disable OIDC middleware if not using DNS names and certificates.</p> <p>Or create separate routers specifically handling Internal IP's - however these must be able to provide user identity to those backends.</p>"},{"location":"service/traefik/troubleshooting/#invalid-state-parameter-csrf-mismatch","title":"Invalid state parameter (CSRF mismatch)","text":"<p>Authentication cookies cannot be shared between subdomains by default.</p> <pre><code>Authentication Error\n\nInvalid state parameter (CSRF mismatch)</code></pre> <p>Explicitly enable a common cookie domain for sharing logins between subdomains and services. Increase exposure as now any login on a subdomain will not re-authenticate user when changing subdomains.</p> <p>/etc/traefik/dynamic/middleware.yml</p> <p>0640 traefik:traefik </p><pre><code>---\nhttp:\n  middlewares:\n    {NAME}:\n      plugin:\n        traefikoidc:\n          cookieDomain: '.example.com'</code></pre><p></p>"},{"location":"service/traefik/acme/","title":"ACME Certificates","text":""},{"location":"service/traefik/acme/#acme-certificates","title":"ACME Certificates","text":"<p>DNS-01 Challenge with Google Cloud DNS and Traefik.</p> <p>Traefik uses LEGO internally to configure certificates. Certificates will be auto provisioned based on configured routers and base domains.</p> <p>Warning</p> <p>Traefik must be able to directly query authoritative DNS servers to validate record change before issuing a ACME certificate request. Otherwise \"Waiting for DNS record propagation\" will run until it times out.</p> <p>Disable destination/source/captive DNS for proxy host or disable propagation check and delay the required SLA time for DNS record update.</p>"},{"location":"service/traefik/acme/#create-google-cloud-service-account","title":"Create Google Cloud Service Account","text":"<p>Create service account with DNS administrator privileges.</p> <p>console.cloud.google.com \u2794 ctrl + o \u2794 {PROJECT} \u2794 APIs &amp; Services \u2794 Credentials \u2794 Create credentials \u2794 Service account</p> <ul> <li>Create service account:<ul> <li>Service account name: traefik acme</li> <li>Service account ID: {AUTO_GENERATED}</li> <li>Service account description: Traefik DNS-01 ACME Challenges</li> </ul> </li> <li>Permissions: DNS Administrator</li> <li>Principals with access: None</li> </ul> <p>Generate JSON keys</p> <p>console.cloud.google.com \u2794 ctrl + o \u2794 {PROJECT} \u2794 IAM &amp; Admin \u2794 Service accounts \u2794 traefik acme \u2794 \u22ee \u2794 Manage keys</p> <ul> <li>Add key \u2794 Create new key: JSON</li> </ul> <p>Download JSON key as traefik_acme.json.</p>"},{"location":"service/traefik/acme/#add-lego-environment-variables-to-service","title":"Add LEGO environment variables to service","text":"<p>Tip</p> <p>This can be done through r_pufky.srv.traefik with:</p> <pre><code>traefik_srv_env:\n  - var: 'GCE_PROJECT'\n    value: '{PROJECT_ID}'\n  - var: 'GCE_SERVICE_ACCOUNT_FILE'\n    value: '/etc/traefik/traefik_acme.json'</code></pre> <p>/etc/systemd/system/traefik.service</p> <p>0644 root:root </p><pre><code>[service]\n...\nEnvironment=\"GCE_PROJECT={PROJECT_ID}\"\nEnvironment=\"GCE_SERVICE_ACCOUNT_FILE=/etc/traefik/traefik_acme.json\"\n...</code></pre><p></p>"},{"location":"service/traefik/acme/#configure-dns-01-certificate-challenge-with-google-cloud-dns","title":"Configure DNS-01 Certificate challenge with Google Cloud DNS","text":"<p>/etc/traefik/traefik.yml</p> <p>0640 traefik:traefik </p><pre><code>---\nlog:\n  level: 'DEBUG'\n  format: 'json'\naccessLog:\n  format: 'json'\napi:\n  dashboard: true\n  disableDashboardAd: true\n  insecure: false\n  debug: true\nserversTransport:\n  insecureSkipVerify: true\nentryPoints:\n  web:\n    address: ':80'\n    http:\n      redirections:\n        entryPoint:\n          to: 'webs'\n          scheme: 'https'\n          permanent: true\n  webs:\n    address: ':443'\n    asDefault: true\n    http:\n      # Use Let's Encrypt with DNS-01 Challenges.\n      tls:\n        certResolver: 'lets_encrypt'\n      domains:\n      - main: 'example.com'  # Main domain.\n        sans: '*.example.com'  # Wildcard certificates.\n      middlewares:\n        - 'global_rate_limit@file'\n        - 'basic_auth_users@file'\n        - 'default_error_page@file'\nproviders:\n  file:\n    directory: '/etc/traefik/dynamic'\n    watch: true\n\n# Use gcloud DNS with LEGO for ACME certificates.\ncertificatesResolvers:\n  lets_encrypt:\n    acme:\n      email: 'contact@example.com'\n      storage: '/var/lib/traefik/acme_staging.json'  # For staging certs.\n      # Initial configuration with staging server.\n      # Only 50 certificates may be issued in a week.\n      # caServer: 'https://acme-v02.api.letsencrypt.org/directory'\n      caServer: 'https://acme-staging-v02.api.letsencrypt.org/directory'\n      # LEGO environment configured in traefik_srv_env.\n      dnsChallenge:\n        provider: 'gcloud'\n        # Set to DNS authoritative name servers for your domain.\n        # Found in Cloud DNS \u2794 Registrar Setup\n        resolvers:\n          - 'ns-cloud-e1.googledomains.com.'\n          - 'ns-cloud-e2.googledomains.com.'\n          - 'ns-cloud-e3.googledomains.com.'\n          - 'ns-cloud-e4.googledomains.com.'\n        propagation:\n          delayBeforeChecks: '120s'  # 120 is SLA for gcloud DNS update.\n          # Only disable if caching or captive DNS upstream servers\n          # interfere with proxy host resolving DNS updates for ACME\n          # challenges.\n          disableChecks: true</code></pre><p></p>"},{"location":"service/traefik/acme/#validate-configuration","title":"Validate Configuration","text":"<p>Start Traefik and search logs.</p> <p>Google cloud DNS console may be checked for _acme-challenge.{DOMAIN} change which indicates that the service account works correctly.</p> <p>journalctl -u traefik</p> <pre><code>[INFO] acme: Registering account for contact@example.com\"}\n\"message\":\"Using DNS Challenge provider: gcloud\"}\n[INFO] [example.com, *.example.com] acme: Obtaining bundled SAN certificate\"}\n[INFO] [*.example.com] AuthURL: https://acme-staging-v02.api.letsencrypt.org/acme/authz/243572763/20286930863\"}\n[INFO] [example.com] AuthURL: https://acme-staging-v02.api.letsencrypt.org/acme/authz/243572763/20286930873\"}\n[INFO] [*.example.com] acme: use dns-01 solver\"}\n[INFO] [example.com] acme: Could not find solver for: tls-alpn-01\"}\n[INFO] [example.com] acme: Could not find solver for: http-01\"}\n[INFO] [example.com] acme: use dns-01 solver\"}\n[INFO] [*.example.com] acme: Preparing to solve DNS-01\"}\n[INFO] [*.example.com] acme: Trying to solve DNS-01\"}\n[INFO] [*.example.com] acme: Checking DNS record propagation. [nameservers=ns-cloud-e1.googledomains.com.:53,ns-cloud-e2.googledomains.com.:53,ns-cloud-e3.googledomains.com.:53,ns-cloud-e4.googledomains.com.:53]\"}\n[INFO] Wait for propagation [timeout: 3m0s, interval: 5s]\"}\n[INFO] [*.example.com] The server validated our request\"}</code></pre>"},{"location":"service/traefik/acme/#set-live-certificates","title":"Set Live Certificates","text":"<p>Once confirmed swap to the live certificate server.</p> <p>/etc/traefik/traefik.yml</p> <p>0640 traefik:traefik </p><pre><code>certificatesResolvers:\n  lets_encrypt:\n    acme:\n      email: 'contact@example.com'\n      storage: '/var/lib/traefik/acme.json'  # For live certs.\n      # Live cert server.\n      caServer: 'https://acme-v02.api.letsencrypt.org/directory'\n      dnsChallenge:\n        provider: 'gcloud'\n        resolvers:\n          - 'ns-cloud-e1.googledomains.com.'\n          - 'ns-cloud-e2.googledomains.com.'\n          - 'ns-cloud-e3.googledomains.com.'\n          - 'ns-cloud-e4.googledomains.com.'\n        propagation:\n          delayBeforeChecks: '120s'\n          disableChecks: true</code></pre><p></p> <pre><code>systemctl restart traefik</code></pre>"},{"location":"service/traefik/acme/#reference","title":"Reference<sup>1</sup><sup>2</sup><sup>3</sup><sup>4</sup><sup>5</sup><sup>6</sup>","text":"<ol> <li> <p>https://doc.traefik.io/traefik/reference/install-configuration/tls/certificate-resolvers/acme \u21a9</p> </li> <li> <p>https://old.reddit.com/r/Actualfixes/comments/wgdd1n/fix_traefik_dns_certificate_time_limit_exceeded \u21a9</p> </li> <li> <p>https://medium.com/@svenvanginkel/traefik-letsencrypt-dns01-challenge-with-ovhcloud-52f2a2c6d08a \u21a9</p> </li> <li> <p>https://betatim.github.io/posts/traefik-config-bare-metal \u21a9</p> </li> <li> <p>https://old.reddit.com/user/germanpickles/comments/1i07bw9/enable_mtls_for_traefik \u21a9</p> </li> <li> <p>https://github.com/traefik/traefik/pull/10981 \u21a9</p> </li> </ol>"},{"location":"service/traefik/acme/behind_traefik/","title":"Behind Traefik","text":""},{"location":"service/traefik/acme/behind_traefik/#behind-traefik","title":"Behind Traefik","text":"<p>Traefik will intercept and block ACME certificate resolvers behind it unless explicitly enabled.</p> <p>Here Be Dragons</p> <p>Requires pushing TLS enforcement from the entrypoint to each router. All routers must ensure TLS is enforced if required.</p>"},{"location":"service/traefik/acme/behind_traefik/#http-01","title":"HTTP-01","text":"<p>Enables host and prefix matching to direct ACME challenges to the correct backend to validate challenges.</p> <p>Highly Recommended</p> <p>Use DNS-01 challenges for Traefik configuration and HTTP-01 challenges for backend service ACME challenges.</p> <p>HTTP-01 challenges may be used for Traefik with some additional configuration.</p> <p>/etc/traefik/traefik.yml</p> <p>0644 traefik:traefik </p><pre><code>log:\n  level: 'DEBUG'\n  format: 'json'\naccessLog:\n  format: 'json'\napi:\n  dashboard: true\n  disableDashboardAd: true\n  insecure: false\n  debug: true\nserversTransport:\n  insecureSkipVerify: true\n\nentryPoints:\n  # Disable HTTP redirection - HTTP may be redirected to HTTPS after ACME\n  # challenge using priorities and broad router rule matching.\n  web:\n    address: ':80'\n\n  # Move TLS requirements to routers.\n  webs:\n    address: ':443'\n    asDefault: true\n\nproviders:\n  file:\n    directory: '/etc/traefik/dynamic'\n    watch: true\n\ncertificatesResolvers:\n  lets_encrypt:\n    acme:\n      email: 'contact@example.com'\n      storage: '/var/lib/traefik/acme_staging.json'\n      caServer: 'https://acme-staging-v02.api.letsencrypt.org/directory'\n      dnsChallenge:\n        provider: 'gcloud'\n        resolvers:\n          - 'ns-cloud-e1.googledomains.com.'\n          - 'ns-cloud-e2.googledomains.com.'\n          - 'ns-cloud-e3.googledomains.com.'\n          - 'ns-cloud-e4.googledomains.com.'\n        propagation:\n          delayBeforeChecks: '120s'\n          disableChecks: true</code></pre><p></p> <p>/etc/traefik/dynamic.yml</p> <p>0644 traefik:traefik </p><pre><code>http:\n  routers:\n    # Match ACME challenge prefix as well as hostnames. Route requests to\n    # backend service expecting the ACME HTTP-01 challenge.\n    mail_http01:\n      rule: 'PathPrefix(`/.well-known/acme-challenge/`) &amp;&amp; (Host(`mail.example.com`) || Host(`autoconfig.example.com`) || Host(`mta-sts.example.com`))'\n      entryPoints:\n        - 'web'\n      priority: 1000\n      service: 'mail_http01_service'\n\n    # Another service using HTTPS with certificates obtained with DNS-01\n    # challenge from Traefik.\n    mail_webmail:\n      rule: 'Host(`mail.example.com`) &amp;&amp; PathPrefix(`/webmail`)'\n      entryPoints:\n        - 'webs'\n      tls:\n        certResolver: 'lets_encrypt'\n        domains:\n          - main: 'example.com'\n            sans: '*.example.com'\n      middlewares:\n        - 'redirect_to_https'\n      service: 'mail_webmail_service'\n\n  middlewares:\n    redirect_to_https:\n      redirectScheme:\n        scheme: 'https'\n        permanent: true\n\n  services:\n    # Backend service hanlding ACME HTTP-01 challenges for\n    # {mail,autoconfig,mta-sts}.example.com.\n    mail_http01_service:\n      loadBalancer:\n        servers:\n          - url: 'http://10.5.5.240:80'\n\n    mail_webmail_service:\n      loadbalancer:\n        servers:\n          - url: 'https://10.5.5.240/webmail'</code></pre><p></p>"},{"location":"service/traefik/acme/behind_traefik/#tls-apln-01","title":"TLS-APLN-01","text":"<p>Not Recommended</p> <p>TLS-APLN-01 challenges require TCP passthrough over TLS connections. As TLS must be terminated (decrypted) to introspect hostnames, only * can be used to match and route incoming requests to backend services. TCP is evaluated before HTTP and therefore can easily break or redirect unexpected (or all) traffic to this backend.</p> <p>/etc/traefik/traefik.yml</p> <p>0644 traefik:traefik </p><pre><code>log:\n  level: 'DEBUG'\n  format: 'json'\naccessLog:\n  format: 'json'\napi:\n  dashboard: true\n  disableDashboardAd: true\n  insecure: false\n  debug: true\nserversTransport:\n  insecureSkipVerify: true\n\nentryPoints:\n  # Disable HTTP redirection - HTTP may be redirected to HTTPS after ACME\n  # challenge using priorities and broad router rule matching.\n  web:\n    address: ':80'\n\n  # Move TLS requirements to routers.\n  webs:\n    address: ':443'\n    asDefault: true\n\nproviders:\n  file:\n    directory: '/etc/traefik/dynamic'\n    watch: true\n\ncertificatesResolvers:\n  lets_encrypt:\n    acme:\n      email: 'contact@example.com'\n      storage: '/var/lib/traefik/acme_staging.json'\n      caServer: 'https://acme-staging-v02.api.letsencrypt.org/directory'\n      dnsChallenge:\n        provider: 'gcloud'\n        resolvers:\n          - 'ns-cloud-e1.googledomains.com.'\n          - 'ns-cloud-e2.googledomains.com.'\n          - 'ns-cloud-e3.googledomains.com.'\n          - 'ns-cloud-e4.googledomains.com.'\n        propagation:\n          delayBeforeChecks: '120s'\n          disableChecks: true</code></pre><p></p> <p>/etc/traefik/traefik.yml</p> <p>0644 traefik:traefik </p><pre><code>tcp:\n  routers:\n    # Send all traffic to backend.\n    mail_apln_challenge:\n      rule: 'HostSNI(`*`)'\n      entryPoints:\n        - 'webs'\n      # Forward packet without modification.\n      tls:\n        passthrough: true\n      service: 'mail_alpn_service'\n\n  services:\n    mail_alpn_service:\n      loadbalancer:\n        servers:\n          - address: '10.5.5.240:443'</code></pre><p></p>"},{"location":"service/traefik/acme/behind_traefik/#reference","title":"Reference<sup>1</sup><sup>2</sup>","text":"<ol> <li> <p>https://github.com/traefik/traefik/issues/8992 \u21a9</p> </li> <li> <p>https://github.com/traefik/traefik/issues/10684 \u21a9</p> </li> </ol>"},{"location":"service/wireguard/","title":"Wireguard","text":""},{"location":"service/wireguard/#wireguard","title":"Wireguard","text":"<p>Modern state-of-the-art VPN designed to be simpler and faster that IPsec and openVPN.</p> <p>Migrated to ansible collection</p> <p>Use r_pufky.deb.wireguard.</p> <p>Only the server endpoint needs to be exposed publicly. Clients can globally roam as long as they have working Internet connections and can send UDP traffic to the given port.</p>"},{"location":"service/wireguard/#key-generation","title":"Key Generation","text":"<p>Warning</p> <p>The private key will enable anyone to impersonate that client on the VPN.</p> <p>Public/Private keys need to be generated for each machine using wireguard. A bare bones utility is provided. Generated keys are not OS specific.</p> <p>/usr/local/bin/wggen</p> <p>0755 root:root</p> <pre><code>#!/bin/bash\n# Generate wireguard keys.\nWG=/usr/bin/wg\nTEE=/usr/bin/tee\n\nif [ -z \"$1\" ]; then\n    echo \"Requires name for output files.\"\n    exit 1\nelse\n    name=$1\nfi\n\n${WG} genkey | ${TEE} ${1}.key | ${WG} pubkey &gt; ${1}.pub\nchmod 0400 ${1}.{key,pub}</code></pre>"},{"location":"service/wireguard/#examples","title":"Examples","text":"Point to Point ExampleVPN Example <p>This setup enables a private network connection to the server, preventing other clients on that network from communicating to other clients. DNS and any network access not directly addressed to the private network will egress through the client's standard network stack.</p> <p>This creates a /24 network that all machines use, while only allowing point to point communications from each client to the server.</p> <p>Server</p> <p>/etc/wireguard/server.conf</p> <p>0600 root:root</p> <pre><code>[Interface]\nAddress = 172.31.255.254/24\nSaveConfig = False\nListenPort = 51820\nPrivateKey = {SERVER PRIVATE KEY}\n\n# Client #1\n[Peer]\nPublicKey = {CLIENT PUBLIC KEY}\nAllowedIPs = 172.31.255.250/32</code></pre> <pre><code># Bring up the tunnel for testing.\nsystemctl enable wg-quick@server</code></pre> <p>Clients</p> <p>Warning</p> <p>Windows clients do not use the SaveConfig option. Remove this line if configuring a Windows client.</p> <p>/etc/wireguard/client.conf</p> <p>0600 root:root</p> <pre><code>[Interface]\nAddress = 172.31.255.250/24\nPrivateKey = {CLIENT PRIVATE KEY}\nSaveConfig = False\n\n# Wireguard server\n[Peer]\nPublicKey = {SERVER PUBLIC KEY}\nEndPoint = {SERVER PUBLIC IP}:51820\nAllowedIPs = 172.31.255.254/32</code></pre> <pre><code># Bring up the tunnel for testing.\nsystemctl enable wg-quick@client</code></pre> <p>Testing </p><pre><code># Show server network status and ping a client.\nwg\nping 172.31.255.250\n\n# Show client network status and ping server. Pinging other clients should fail.\nwg\nping 172.31.255.254\nping 172.31.255.100</code></pre><p></p> <p>Behaves like a traditional VPN network. All traffic and DNS lookups are routed through the connection to be resolved in the VPN server location.</p> <p>Server </p><pre><code># Enable IP traffic forwarding on iptables.\necho 1 &gt; /proc/sys/net/ipv4/ip_forward\necho 1 &gt; /proc/sys/net/ipv6/ip_forward</code></pre><p></p> <p>/etc/sysctl.conf</p> <p>0644 root:root</p> <pre><code>net.ipv4.ip_forward = 1\nnet.ipv6.conf.all.forwarding = 1</code></pre> <p>/etc/wireguard/server.conf</p> <p>0600 root:root</p> <pre><code>[Interface]\nAddress = 172.31.255.254/24\nSaveConfig = False\nListenPort = 51820\nPrivateKey = {SERVER PRIVATE KEY}\n# Automatically adjust iptables rules to allow forwarded traffic when VPN up.\nPostUp = iptables -A FORWARD -i {WIREGUARD TUNNEL} -j ACCEPT; iptables -t nat -A POSTROUTING -o {INTERFACE} -j MASQUERADE; ip6tables -A FORWARD -i {WIREGUARD TUNNEL} -j ACCEPT; ip6tables -t nat -A POSTROUTING -o {INTERFACE} -j MASQUERADE\nPostDown = iptables -D FORWARD -i {WIREGUARD TUNNEL} -j ACCEPT; iptables -t nat -D POSTROUTING -o {INTERFACE} -j MASQUERADE; ip6tables -D FORWARD -i {WIREGUARD TUNNEL} -j ACCEPT; ip6tables -t nat -D POSTROUTING -o {INTERFACE} -j MASQUERADE\n\n# Client #1\n[Peer]\nPublicKey = {CLIENT PUBLIC KEY}\nAllowedIPs = 172.31.255.250/32</code></pre> <pre><code># Bring up the tunnel for testing.\nsystemctl enable wg-quick@server</code></pre> <p>Client</p> <p>Tip</p> <p>Set a custom DNS server if needed. DNS is resolved at the VPN server.</p> <p>/etc/wireguard/client.conf</p> <p>0600 root:root</p> <pre><code># Route all traffic through VPN connection.\n[Interface]\nAddress = 172.31.255.250/24\nPrivateKey = {CLIENT PRIVATE KEY}\nDNS = 1.1.1.1,1.1.2.2\nSaveConfig = False\n\n# Wireguard server\n[Peer]\nPublicKey = {SERVER PUBLIC KEY}\nEndPoint = {SERVER PUBLIC IP}:51820\nAllowedIPs = 0.0.0.0/0</code></pre> <pre><code># Bring up the tunnel for testing.\nsystemctl enable wg-quick@vpn-client</code></pre> <p>Testing</p> <p>From the client access the Internet and verify that your data is routed through the VPN server.</p> <p>A quick test can be verifying different IP's from https://www.whatismyip.com.</p>"},{"location":"service/wireguard/#initramfs","title":"InitRAMFS","text":"<p>Enable wireguard during boot process allowing for remote unlocks anywhere in the world.</p> <p>Migrated to ansible collection</p> <p>Use r_pufky.deb.wireguard.</p> <p>This enables the used of Dropbear and related unlock utilities over a wireguard network before a system has booted.</p>"},{"location":"service/wireguard/#install","title":"Install","text":"<p>Install Wireguard first, then install the latest package from https://github.com/r-pufky/wireguard-initramfs:</p> <pre><code>wget https://github.com/r-pufky/wireguard-initramfs/archive/refs/tags/2025-03-02.tar.gz\ntar xvf 2025-03-02.tar.gz\ncd wireguard-initramfs-2025-03-02\nmake install</code></pre>"},{"location":"service/wireguard/#configure","title":"Configure","text":"<p>/etc/wireguard/initramfs.conf</p> <p>0600 root:root </p><pre><code>[Interface]\nAddress = 172.31.255.10/32\nPrivateKey = XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n\n[Peer]\nPublicKey = gyW39I9bAiOBXyhL8LWw9qwiTZgMmtAbsWtLUv8uKTc=\nAllowedIPs = 172.31.255.254/32\nPresharedKey = XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\nPersistentKeepalive = 25\nEndpoint = {SERVER INTERFACE IP}:51820</code></pre><p></p> <p>/etc/wireguard/initramfs</p> <p>0644 root:root </p><pre><code>ADAPTER=/etc/wireguard/initramfs.conf\n\n# Enable wg-quick for adapter management?\nENABLE_QUICK=\n\n# URL to send a web request to set the local datetime.\n#\n# Raspberry Pi's should enable this feature for wireguard-initramfs to work.\n#\n# Skipped if blank.\nDATETIME_URL=\n\n# Persist (do not down) interface after initramfs exits? Any value enables.\nPERSISTENT=\n\n# Enable debug logging (will expose key material)? Any value enables.\nDEBUG=</code></pre><p></p> <p>Note</p> <p>Most systems do not encrypt /boot so private key material is exposed and considered compromised/untrusted. Boot wireguard network should be different &amp; untrusted, versus the network used after booting. Always restrict ports and access on the wireguard server.</p> <pre><code># Add wireguard to initramfs.\nupdate-initramfs -u\nupdate-grub\nreboot</code></pre>"},{"location":"service/wireguard/#dropbear-remote-unlock","title":"Dropbear Remote Unlock","text":"<p>Unlock an encrypted root filesystem remotely on boot over wireguard.</p> <p>Ensure that both Dropbear and Wireguard are setup and working correctly. Then set dropbear to only listen over wireguard network:</p> <p>/etc/dropbear-initramfs/config</p> <p>0644 root:root </p><pre><code>DROPBEAR_OPTIONS='... -p 172.31.255.10:22 ...'</code></pre><p></p> <pre><code># Update dropbear config in initramfs.\nupdate-initramfs -u\nupdate-grub\nreboot</code></pre> <ul> <li>The boot wireguard network should be separate from your normal wireguard   network. Protect the server endpoint and restrict all ports not needed.</li> <li>The boot and running wireguard networks should have different keys.</li> <li>Set UFW on the host as well for further protection.</li> </ul>"},{"location":"service/wireguard/troubleshooting/","title":"Troubleshooting","text":""},{"location":"service/wireguard/troubleshooting/#troubleshooting","title":"Troubleshooting","text":""},{"location":"service/wireguard/troubleshooting/#debugging","title":"Debugging","text":"<p>Issues with wireguard connections can be debugged by enabling dynamic debug in the kernel.</p> <pre><code># Enable.\necho 'module wireguard +p' | sudo tee /sys/kernel/debug/dynamic_debug/control\ndmesg -wH\n\n# Disable.\necho 'module wireguard -p' | sudo tee /sys/kernel/debug/dynamic_debug/control</code></pre>"},{"location":"service/wireguard/troubleshooting/#ssh-not-working-ufw-allowing-ssh-no-nat","title":"SSH not working, UFW allowing SSH, No NAT","text":"<p>Expresses as pings between clients through the wireguard server work correctly, but SSH'ing fails. UFW on the wireguard server is enabled and allowing SSH traffic. Disabling UFW allows SSH connections to happen.</p> <p>Traffic needs to be tagged in IP tables to allow wireguard to wireguard traffic to be forwarded; otherwise this is not tagged as inbound traffic to the wireguard server in UFW and subsequently blocked.</p> /etc/wireguard/server.conf <p>0600 root:root</p> <pre><code>iptables -A FORWARD -i {INTERFACE} -o {INTERFACE} -m conntrack --ctstate NEW -j ACCEPT</code></pre>"},{"location":"service/wireguard/os/linux/","title":"Linux","text":""},{"location":"service/wireguard/os/linux/#linux","title":"Linux","text":"<p>All modern linux distributions support wireguard with 5.6+ Kernels.</p> ManjaroDebianUbuntu <pre><code>pamac install wireguard-dkms wireguard-tools wireguard-ui</code></pre> <pre><code>apt install wireguard</code></pre> <pre><code>apt install wireguard</code></pre>"},{"location":"service/wireguard/os/linux/#autostart-tunnel-as-service","title":"Autostart Tunnel as Service","text":"<p>:caption: Start tunnel on boot. </p><pre><code>systemctl enable wg-quick@{TUNNEL}\n\n# Start tunnel on demand.\nsystemctl status/stop/start/restart wg-quick@{TUNNEL}</code></pre><p></p>"},{"location":"service/wireguard/os/windows/","title":"Windows","text":""},{"location":"service/wireguard/os/windows/#windows","title":"Windows","text":""},{"location":"service/wireguard/os/windows/#setup","title":"Setup","text":"<p>Download latest Windows Installer.</p> <pre><code># Install\nwinget install --id=WireGuard.WireGuard -e\n\n# Silent install\nStart-Process msiexec.exe -ArgumentList '/q', '/I', 'wireguard-amd64-0.1.0.msi' -Wait -NoNewWindow -PassThru | Out-Null\nStart-Process 'C:\\Program Files\\WireGuard\\wireguard.exe' -ArgumentList '/uninstallmanagerservice' -Wait -NoNewWindow -PassThru | Out-Null</code></pre>"},{"location":"service/wireguard/os/windows/#add-pre-configured-tunnel","title":"Add Pre-configured Tunnel","text":"<p>Pre-configured tunnels may be added as a separate service.</p> <p>The service is set to automatic (delayed) as this will guarantee the service starting if the network is not available when the service first starts. This mainly happens due to a very large hosts file or network being unavailable at boot.</p> <pre><code># Install my-tunnel.conf as a startup tunnel (powershell as admin).\n\nStart-Process 'C:\\Program Files\\WireGuard\\wireguard.exe' -ArgumentList '/installtunnelservice', 'my-tunnel.conf' -Wait -NoNewWindow -PassThru | Out-Null\nStart-Process sc.exe -ArgumentList 'config', 'WireGuardTunnel$my-tunnel', 'start= delayed-auto' -Wait -NoNewWindow -PassThru | Out-Null\nStart-Service -Name WireGuardTunnel$my-tunnel -ErrorAction SilentlyContinue</code></pre>"},{"location":"service/zfs/","title":"ZFS","text":""},{"location":"service/zfs/#zfs","title":"ZFS","text":"<p>ZFS (Zettabyte FileSystem) storage pool. See ZFS Tutorial.</p>"},{"location":"service/zfs/#install","title":"Install","text":"<pre><code>apt install zfsutils-linux\n\n# Install RAM FS tools if ZFS is to be used for root filesystem.\napt install zfs-initramfs</code></pre>"},{"location":"service/zfs/#creating-new-zfs-pool","title":"Creating New ZFS Pool","text":"<p>Warning</p> <p>Do not encrypt the root pool or mount it. Encrypt and mount datasets instead. See Encryption.</p> <p>Best practice from years of ZFS use are:</p> <ul> <li>Use an unencrypted ZFS pool (encrypt datasets).</li> <li>Create datasets to handle specific data needs/types/etc. Keep massive files   in one dataset (e.g. videos), versus one for running services.</li> <li>Set dataset options based on those needs (encryption, compression, etc). This   isolates master encryption keys and makes data management easy years later.</li> <li>Set mountpoints immutable <code>chattr +i {MOUNTPOINT}</code> when dataset is not   mounted. This prevents writing to those mountpoints when the pool/dataset is   not mounted or unlocked.</li> </ul>"},{"location":"service/zfs/#determine-disks-to-add-to-zfs-pool","title":"Determine disks to add to ZFS pool","text":"<pre><code>lsblk\nls -l /dev/disk/by-id</code></pre>"},{"location":"service/zfs/#create-zfs-pool","title":"Create ZFS pool","text":"<pre><code># ZFS will handle the partitioning of raw disks automatically. There is no need\n# to explicitly partition your disks beforehand.\nzpool create -o autoexpand=on -o ashift=12 -O mountpoint=none {POOL} raidz2 /dev/disk/by-id/wwn-*\nzpool list\nzpool status {POOL}\nzdb -C {POOL}</code></pre> <ul> <li>autoexpand=on enables auto-expanding of ZFS pool when new disks are   added.</li> <li>ashift=12 enables 4K sectors All &gt; 2011 drives should have 4K   sectors. This cannot be changed once set in the pool, and will lead to   severe performance degradation if mis-matched for FS/drives. Cannot   hotswap/replace 512 with 4K drives in pool.</li> <li>-O mountpoint=none the unencrypted pool will not be mounted - mount   datasets instead.</li> <li>raidz2 preferred for 6+ disk arrays. raidz for &lt;6.</li> <li>www-* replace with bash expansion to match drives to use. Can specify   multiple block devices explicitly.</li> <li>Ensure ashift=12 is enabled with -C option.</li> </ul>"},{"location":"service/zfs/#create-zfs-dataset","title":"Create ZFS Dataset","text":"<p>Encryption must be enabled at creation</p> <pre><code># Create dataset with pool defaults.\nzfs create {POOL}/{NAME}\n\n# Enable non-default options during creation.\nzfs create -o xattr=sa -o dnodesize=auto {POOL}/{NAME}</code></pre>"},{"location":"service/zfs/#zfs-operations","title":"ZFS Operations","text":"<p>ZFS can be tweaked per dataset based on the data being used. ZFS only applies new settings on newly written data; changing options for pre-existing data requires export/re-import of that data to the dataset.</p>"},{"location":"service/zfs/#increase-write-throughput","title":"Increase Write Throughput","text":"<p>Especially effective for NFSv4 mounts backed by ZFS.</p> <pre><code>zpool add {POOL} log {DEV}</code></pre> <p>ZFS cache drives are mis-understood and are only useful if you run out of memory. Use SLOG (synchronous flush based log for ZIL writes) caching drive backed by an NVME (or any other SSD). This works with NFSv4 to massively improve read and write performance by more that 12x.</p>"},{"location":"service/zfs/#enable-extended-attributes","title":"Enable Extended Attributes","text":"<p>Reduces I/O requests and latency via enabling larger inode allocations for attributes. Enable large dynamic inode sizes (&gt;512B) for all exported datasets.</p> <pre><code># large_dnode is automatically enabled when dnodesize != legacy.\nzfs set xattr=sa dnodesize=auto {POOL}/{DATASET}</code></pre>"},{"location":"service/zfs/#mounting-existing-zfs-pool","title":"Mounting Existing ZFS Pool","text":"<p>Tip</p> <p>Set mountpoint to immutable without the ZFS dataset mounted. This prevents writes when the dataset is not ready: chattr +i {MOUNTPOINT}</p> <pre><code># -f required if pool was not exported.\nzpool import {POOL}  # autodetect and import: 'zpool import -a'\nzpool status {POOL}\nzpool scrub {POOL}\nzfs mount -l -a</code></pre>"},{"location":"service/zfs/#enable-text-compression-and-disable-atime-for-maildir-datasets","title":"Enable text compression and disable atime for Maildir datasets.","text":"<pre><code>zfs set atime=off {POOL}/{DATASET}\nzfs set compression=lz4 {POOL}/{DATASET}</code></pre>"},{"location":"service/zfs/#enable-high-compression-for-backup-datasets","title":"Enable high compression for backup datasets.","text":"<pre><code>zfs set compression=gzip {POOL}/{DATASET}</code></pre>"},{"location":"service/zfs/#check-deduplication-savings","title":"Check Deduplication Savings","text":"<p>Determine how much space would be saved if enabling de-duplication. This is also a good indicator of how much duplicated data there is.</p> <pre><code>zfs -S {POOL}</code></pre>"},{"location":"service/zfs/#setup-monthly-zfs-scrub","title":"Setup Monthly ZFS Scrub","text":"<p>Scrubbing verifies all blocks can be read, and marks then bad if not. This is done while the filesystem is online, but may slightly impact performance.</p> <p>/root/bin/scrub-zpool-monthly</p> <p>0750 root:root</p> <pre><code>#!/bin/bash\n#\n# Scrubs zpool monthly.\n/sbin/zpool scrub {POOL}</code></pre> <pre><code># Add scrub to crontab.\nsudo crontab -e\n\n@weekly /root/bin/scrub-zpool-monthly</code></pre>"},{"location":"service/zfs/encryption/","title":"Encryption","text":""},{"location":"service/zfs/encryption/#encryption","title":"Encryption","text":"<p>Best practice is to encrypt all datasets but not the pool. Encryption works by generating a master encryption key for the dataset (which the user does not access). Password or keyfiles are used to unlock the master encryption key.</p> <p>By isolating data to smaller datasets, exposure of the master key is constrained. See ZFS Native Encryption for detailed CLI usage with examples.</p>"},{"location":"service/zfs/encryption/#do-not-encrypt-zfs-pool","title":"Do NOT Encrypt ZFS Pool","text":"<p>Do not encrypt root ZFS pool Encrypting the pool will result in difficulty later on when migrating and managing the pool:</p> <ul> <li>Datasets on the pool can still be encrypted regardless. Store data in   datasets and not on the root pool. Do not mount the root pool.</li> <li>Pool will mount on boot (encrypted datasets are not unless specifically   automated).</li> <li>All contents of the root pool need to be removed to change encryption.   This is quite literally days-to-weeks even for modest 6-disk (100T) pools.</li> <li>Metadata on datasets is unencrypted even with encryption. Encrypting the   root drive offers no additional protection or data leakage from dataset   metadata.</li> <li>Master key scope is reduced. Using a password or keyfile to unlock ZFS only   unlocks the master key, it does not change it. By creating separate   datasets (and not encrypting the entire pool), a different underlying master   key is used for each, limiting breach scope.</li> </ul>"},{"location":"service/zfs/encryption/#encrypt-a-dataset","title":"Encrypt a Dataset","text":"<p>Warning</p> <p>Pools created before ZoL 0.8.0 (pool versions &lt;= 28) must be upgraded before encryption is supported.</p> <pre><code># Upgrade ZFS pool to latest version.\nzpool upgrade -v\nzpool upgrade -a</code></pre> <p>Danger</p> <p>Always confirm key works before loading data.</p> <p>This means: unmount, unload encryption key, and remount before proceeding.</p> <p>This checks you and confirms you are using the password intended for the dataset; preventing data loss on a missing key/password.</p> <pre><code># Create encrypted dataset on ZFS pool using 1 million pbkdf2 iterations.\nzfs create -o encryption=aes-256-gcm -o keyformat=passphrase -o atime=off -o keylocation=prompt -o pbkdf2iters=1000000 -o xattr=sa -o dnodesize=auto  -o mountpoint=/d/media {POOL}/media</code></pre>"},{"location":"service/zfs/encryption/#mount-encrypted-dataset","title":"Mount Encrypted Dataset","text":"<p>Tip</p> <p>Set mountpoint to immutable without the ZFS dataset mounted. This prevents writes when the dataset is not ready: chattr +i {MOUNTPOINT}</p> <pre><code>zfs mount -l {POOL}/{DATASET}\nzfs mount -l -a</code></pre> <p>Once a key is loaded unmounting and remounting will not require re-entry of the password or file.</p>"},{"location":"service/zfs/encryption/#unload-encryption-key","title":"Unload Encryption KEy","text":"<pre><code># Use after unmounting to remove the key from memory.\nzfs unload-key {POOL}/{DATASET}</code></pre>"},{"location":"service/zfs/encryption/#preload-dataset-encryption-key","title":"Preload Dataset Encryption Key","text":"<pre><code>zfs load-key {POOL/DATASET}  # Preload one key.\nzfs load-key -a  # Preload all keys.</code></pre>"},{"location":"service/zfs/encryption/#change-encryption-keysmethod","title":"Change Encryption Keys/Method","text":"<p>Danger</p> <p>Always confirm key works before loading data. Do not overwrite or delete the old key until the new key is in place.</p> <p>This means: unmount, unload encryption key, and remount before proceeding.</p> <p>This checks you and confirms you are using the password intended for the dataset; preventing data loss on a missing key/password.</p> <p>Change password, keyfile, or swap between the two methods. This does not change the user-inaccessible master key (to do that you must create a new dataset).</p> <p>Always use full path for key. Ideally store on removable USB key for booting where the mounted path will always be known. Otherwise store on encrypted boot drive. Use a password if key would be stored on an unencrypted disk.</p> <pre><code># Change password for dataset.\nzfs change-key -l -o keyformat=passphrase -o keylocation=prompt -o pbkdf2iters=1000000 {POOL}/{DATASET}\n\n# Use keyfile for encryption key.\ndd if=/dev/urandom of=/root/zfs.key bs=1 count=32\nzfs change-key -l -o keyformat=raw -o keylocation=file:///root/zfs.key {POOL}/{DATASET}</code></pre>"},{"location":"service/zfs/encryption/#reference","title":"Reference<sup>1</sup><sup>2</sup>","text":"<ol> <li> <p>https://arstechnica.com/gadgets/2021/06/a-quick-start-guide-to-openzfs-native-encryption \u21a9</p> </li> <li> <p>https://blog.heckel.io/2017/01/08/zfs-encryption-openzfs-zfs-on-linux \u21a9</p> </li> </ol>"},{"location":"service/zfs/replacing_disks/","title":"Replacing Disks","text":""},{"location":"service/zfs/replacing_disks/#replacing-disks","title":"Replacing Disks","text":"<p>Management of underlying block devices for ZFS.</p> <p>ZFS will automatically partition the raw disk if it is not currently partitioned. Only the root block device for disk needs to be known. Preference is to use the WWN name (world-wide unique name) for the disk, which will be consistent across systems. This is in /dev/disk/by-id/wwn-*.</p> <p>Tip</p> <p>When issuing ZFS commands against devices in the pool, you must use those ID's.</p> <p>When issuing ZFS commands with devices outside the pool, you must use the full path, preferably with the WWN name.</p>"},{"location":"service/zfs/replacing_disks/#offline-replacement-bad-disk","title":"Offline Replacement Bad Disk","text":"<p>For non-server grade hardware where the server must be shutdown and disks physically swapped. This also applies in cases where there is no additional space and a drive must be removed to be replaced.</p> <p>Determine the bad disk based on the status returned. This disk ID may be the WWN or the full path to the disk. If it is the WWN, determine the block device. Identify the drive serial number for easy hardware swapping when off.</p>"},{"location":"service/zfs/replacing_disks/#identify-block-devices-to-minimize-downtime","title":"Identify block devices to minimize downtime","text":"<pre><code>zpool status {POOL}\nls -l /dev/disk/by-id/{BAD DISK}\nsmartctl -i /dev/disk/by-id/{BAD DISK}\n\n# Identify the ZFS GUID for the bad disk\nzdb\n\n# The ZFS GUID would be 13942365352362146142\nzdb\n&gt; ...\n&gt; children[1]:\n&gt;     type: 'disk'\n&gt;     id: 1\n&gt;     guid: 13942365352362146142\n&gt;     path: '/dev/disk/by-id/wwn-0xXXXXXXXXXXXXXXXX-part1'\n&gt;     whole_disk: 0\n&gt;     DTL: 403\n&gt;     create_txg: 4\n&gt;     com.delphix:vdev_zap_leaf: 131</code></pre>"},{"location":"service/zfs/replacing_disks/#offline-the-bad-disk-in-the-pool","title":"Offline the bad disk in the pool","text":"<pre><code>zpool status {POOL}\nzpool offline {POOL} {BAD DISK}\nshutdown -h now\n# Replace the physical disk with the new disk and boot.</code></pre>"},{"location":"service/zfs/replacing_disks/#find-the-new-disk-to-add-to-zfs-pool","title":"Find the new disk to add to ZFS pool","text":"<p>This will initiate a disk replacement, partitioning the new disk if needed and start the re-silvering process.</p> <pre><code>lsblk\nsmartctl -i /dev/disk/by-id/{NEW DISK}\n\n# Replace the old disk using the ZFS GUID and the new disk WWN name\nzpool replace {POOL} {BAD DISK GUID} /dev/disk/by-id/{NEW DISK WWN}</code></pre> <p>Immediately after this command ZFS will scan the pool. </p><pre><code>zpool status\n&gt;   pool: tank\n&gt;  state: DEGRADED\n&gt; status: One or more devices is currently being resilvered.  The pool will\n&gt;         continue to function, possibly in a degraded state.\n&gt; action: Wait for the resilver to complete.\n&gt;   scan: resilver in progress since Tue Sep 21 11:08:12 2021\n&gt;         4.15T scanned at 26.4G/s, 3.55G issued at 22.6M/s, 45.7T total\n&gt;         0B resilvered, 0.01% done, 24 days 13:33:50 to go\n&gt; config:\n&gt;\n&gt;         NAME                                STATE     READ WRITE CKSUM\n&gt;         hundo                               DEGRADED     0     0     0\n&gt;           raidz2-0                          DEGRADED     0     0     0\n&gt;             wwn-0xXXXXXXXXXXXXXXXX-part1    ONLINE       0     0     0\n&gt;             wwn-0xXXXXXXXXXXXXXXXX-part1    ONLINE       0     0     0\n&gt;             replacing-2                     DEGRADED     0     0     0\n&gt;               wwn-0xXXXXXXXXXXXXXXXX-part1  OFFLINE      0     0     0\n&gt;               wwn-0xXXXXXXXXXXXXXXXX        ONLINE       0     0     0\n&gt;             wwn-0xXXXXXXXXXXXXXXXX-part1    ONLINE       0     0     0\n&gt;             wwn-0xXXXXXXXXXXXXXXXX-part1    ONLINE       0     0     0\n&gt;             wwn-0xXXXXXXXXXXXXXXXX-part1    ONLINE       0     0     0</code></pre><p></p> <p>After the initial scan, re-silvering should kickoff. </p><pre><code>zpool status\n&gt;   pool: tank\n&gt;  state: DEGRADED\n&gt; status: One or more devices is currently being resilvered.  The pool will\n&gt;         continue to function, possibly in a degraded state.\n&gt; action: Wait for the resilver to complete.\n&gt;   scan: resilver in progress since Tue Sep 21 11:08:12 2021\n&gt;         9.07T scanned at 10.1G/s, 570G issued at 636M/s, 45.7T total\n&gt;         93.7G resilvered, 1.22% done, 20:40:40 to go\n&gt; config:\n&gt;\n&gt;         NAME                                STATE     READ WRITE CKSUM\n&gt;         hundo                               DEGRADED     0     0     0\n&gt;           raidz2-0                          DEGRADED     0     0     0\n&gt;             wwn-0xXXXXXXXXXXXXXXXX-part1    ONLINE       0     0     0\n&gt;             wwn-0xXXXXXXXXXXXXXXXX-part1    ONLINE       0     0     0\n&gt;             replacing-2                     DEGRADED     0     0     0\n&gt;               wwn-0xXXXXXXXXXXXXXXXX-part1  OFFLINE      0     0     0\n&gt;               wwn-0xXXXXXXXXXXXXXXXX        ONLINE       0     0     0  (resilvering)\n&gt;             wwn-0xXXXXXXXXXXXXXXXX-part1    ONLINE       0     0     0\n&gt;             wwn-0xXXXXXXXXXXXXXXXX-part1    ONLINE       0     0     0\n&gt;             wwn-0xXXXXXXXXXXXXXXXX-part1    ONLINE       0     0     0</code></pre><p></p>"},{"location":"service/zfs/replacing_disks/#hot-swap-bad-disk","title":"Hot-swap Bad Disk","text":"<p>Hot-swap disks if your hardware supports it.</p> <p>In-place replacement with no disk device ID change. </p><pre><code>zpool scrub {POOL}\nzpool status {POOL}\nlsblk\nzpool offline {POOL} {BAD DISK}\n{REPLACE DISK}  # Physically hot-swap disk.\nzpool online {POOL} {NEW DISK}\nzpool replace {POOL} {NEW DISK}\nzpool status {POOL}</code></pre><p></p> <p>Replacement with new disk device ID. </p><pre><code>{ADD NEW DISK}\nzpool scrub {POOL}\nzpool status {POOL}\nlsblk\nzpool replace {POOL} {BAD DISK} {NEW DISK}\nzpool status {POOL}\n{REMOVE BAD DISK}</code></pre><p></p>"},{"location":"service/zfs/replacing_disks/#upgrade-with-larger-disks","title":"Upgrade with Larger Disks","text":"<p>Capacity will automatically be expanded (autoexpand=on) when minimum disk upgrade requirements have been met.</p> <p>Warning</p> <p>Data destructive. Verify the correct drive is selected.</p> <p>Upgrade process for each disk in pool. </p><pre><code>zpool scrub {POOL}\nzpool status {POOL}\nlsblk\nzpool replace {POOL} {OLD DISK} {BIGGER DISK}\nzpool status {POOL}</code></pre><p></p> <p>Repeat for each disk. If constrained by hardware the old disk can be off-lined the new disk physically changed, and then replaced. </p><pre><code>zpool offline {POOL} {OLD DISK}\n{REPLACE DISK}\nzpool replace {POOL} {NEW DISK}</code></pre><p></p>"},{"location":"service/zfs/replacing_disks/#combination-of-raw-disks-and-partitions-in-pool","title":"Combination of Raw Disks and Partitions in Pool","text":"<p>This is normal; though unnerving if used to traditional disk management. ZFS manages all disk hardware and - depending on how the pool was created, when disks were added, removed, or replaced - you may end up with some devices showing partitions versus raw disks. This is OK. The zpool listing is just the ID used to represent the disk.</p> <p>Using zdb on the pool will show the details of the underlying hardware. Raw disks will show a mapping to -part1 if automatically created as well as a reference to the underlying block device.</p> <p>Show the underlying hardware configuration for a ZFS pool. </p><pre><code>zdb\n&gt;   ...\n&gt; children[2]:\n&gt;     type: 'disk'\n&gt;     id: 2\n&gt;     guid: 149i73844241267554311\n&gt;     path: '/dev/disk/by-id/wwn-0xXXXXXXXXXXXXXXXX-part1'\n&gt;     devid: 'ata-WDC_XXXXXXXXX-XXXXXXX_XXXXXXXX-part1'\n&gt;     phys_path: 'pci-0000:01:00.1-ata-5.0'\n&gt;     whole_disk: 1\n&gt;     DTL: 272\n&gt;     create_txg: 4\n&gt;     com.delphix:vdev_zap_leaf: 262</code></pre><p></p> <p>This may also be confirmed by checking the block device itself. ZFS formatted drives will have two partitions (part1, part9). </p><pre><code>ls -l /dev/disk/by-id/{DISK}*\n&gt; lrwxrwxrwx 1 root:root  9 Sep 22 09:37 /dev/disk/by-id/wwn-0xXXXXXXXXXXXXXXXX -&gt; ../../sde\n&gt; lrwxrwxrwx 1 root:root 10 Sep 22 09:37 /dev/disk/by-id/wwn-0xXXXXXXXXXXXXXXXX-part1 -&gt; ../../sde1\n&gt; lrwxrwxrwx 1 root:root 10 Sep 22 09:37 /dev/disk/by-id/wwn-0xXXXXXXXXXXXXXXXX-part9 -&gt; ../../sde9</code></pre><p></p>"},{"location":"service/zfs/sync_backup/","title":"Sync / Backup","text":""},{"location":"service/zfs/sync_backup/#sync-backup","title":"Sync / Backup","text":"<p>ZFS send &amp; receive allows for a powerful synchronization and backup mechanism. It should be used instead of typical rsync linux methods. ZFS will send only block level changes with typically a lower throughput, while rsync sends entire files with higher throughput.</p> <p>rsync tends to be faster for the initial sync, but in the long run loses to ZFS due to efficiency gains across multiple TBs.</p> <p>Snapshotting creates a point-in-time state for a given ZFS dataset; as the system is Copy On Write (COW), this enables any snapshot to be deleted at any time without data loss (as long as the dataset/pool is not deleted), as well as snapshots essentially being 'free' until more data is written to the dataset. Syncing snapshot remotely requires a reference snapshot and the snapshot to sync to.</p>"},{"location":"service/zfs/sync_backup/#syncing-datasets","title":"Syncing Datasets","text":"<p>Dataset may be synced to remote ZFS pools as a method for backup. These are basic tools for sync'ing datasets. See Automation to backup and manage snapshots automatically.</p> <p>Note</p> <p>It is important to use the RAW flags for encrypted datasets to be transferred. Encrypted datasets do not need to mounted. Blocks are transferred encrypted, meaning the remote machine does not need the key to sync the data, but will require the key to mount and read/write the data.</p> <p>The remote rollback to the latest snapshot ensures the new snapshot is transferred correctly, otherwise a synchronization error will occur.</p> <p>Create the initial snapshot for the local system. </p><pre><code>zfs snapshot tank/example@YYYYMMDD\n\n# Send the ZFS snapshot to the remote machine\nzfs send -R -w -I tank/example@YYYYMMDD | ssh remote_host sudo zfs receive -F -u -v tank2/example</code></pre><p></p>"},{"location":"service/zfs/sync_backup/#automation","title":"Automation","text":"<p>Migrated to ansible collection</p> <p>Use r_pufky.deb.zfs.</p> <p>Or clone the repository: https://github.com/r-pufky/zincrsend. Read comments in the script to setup correct sync.</p>"},{"location":"service/zfs/sync_backup/#removing-old-snapshots","title":"Removing Old Snapshots","text":"<p>Snapshots can be sorted by creation time and deleted based on the number to keep.</p> <pre><code>zfs_latest=`/usr/sbin/zfs list -H -t snapshot -o name -S creation | grep ^tank/example@ | head -2`\nzfs_delete=`/usr/sbin/zfs list -H -t snapshot -o name -S creation | grep ^tank/example@`\n\n# Remove latest snapshots from all set.\nfor keep_snap in ${zfs_latest[@]}; do\n  zfs_delete=( \"${zfs_delete[@]/${keep_snap}}\" );\ndone\n\n# Destroy old snapshots\nfor snap in ${zfs_delete[@]}; do\n  /usr/sbin/zfs destroy ${snap}\ndone</code></pre>"},{"location":"service/zfs/sync_backup/#references","title":"References<sup>1</sup><sup>2</sup><sup>3</sup>","text":"<ol> <li> <p>https://ubuntu.com/tutorials/using-zfs-snapshots-clones#2-using-snapshots \u21a9</p> </li> <li> <p>https://askubuntu.com/questions/764416/send-zfs-snapshot-to-remote-machine \u21a9</p> </li> <li> <p>https://docs.oracle.com/cd/E19253-01/819-5461/gbchx/index.html \u21a9</p> </li> </ol>"}]}